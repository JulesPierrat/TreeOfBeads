Id,Code,Name,Description,Category0,GIST,Geographic Information Science and Technology,Geographic Information Science and Technology,NONE1,AM,Analytical Methods,This knowledge area encompasses a wide variety of operations whose objective is to derive analytical results from geospatial data. Data analysis seeks to understand both first-order (environmental) effects and second-order (interaction) effects. Approaches that are both data-driven (exploration of geospatial data) and model-driven (testing hypotheses and creating models) are included. Data driven techniques derive summary descriptions of data - evoke insights about characteristics of data - contribute to the development of research hypotheses - and lead to the derivation of analytical results. The goal of model driven analysis is to create and test geospatial process models. In general - model-driven analysis is an advanced knowledge area where previous experience with exploratory spatial data analysis would constitute a desired prerequisite. Visual tools for data analysis are covered in Knowledge Area: Cartography and Visualization (CV) and many of the fundamental principles required to ground data analysis techniques are introduced in Knowledge Area: Conceptual Foundations (CF). Image processing techniques are considered in Knowledge Area: Geospatial Data (GD). All of the methods described in this knowledge area are more or less sensitive to data error and uncertainty as covered in Unit GC8 Uncertainty and Unit GD6 Data quality. Mastery of the educational objectives outlined in this knowledge area requires knowledge and skills in mathematics - statistics - and computer programming.,NONE2,AM1-2,Analytical approaches,Analytical capabilities of a GIS make use of spatial and non-spatial (attribute) data to answer questions and solve problems that are of spatial relevance. We now make a distinction between analysis (or analytical operations) and analytical models (often referred to as “modelling”). And by analysis we actually mean only a subset of what is usually implied by the term: we do not specifically deal with advanced statistical analysis (such as cluster detection or geostatistics).\r\rAnalysis of spatial data can be defined as computing new information to provide new insights from existing spatial data. Consider an example from the domain of road construction. In mountainous areas - this is a complex engineering task with many cost factors - including the number of tunnels and bridges to be constructed - the total length of the tarmac - and the volume of rock and soil to be moved. GISs can help to compute such costs on the basis of an up-to-date digital elevation model and a soil map. The exact nature of the analysis will depend on the application requirements - but computations and analytical functions can operate on both spatial and non-spatial data.,NONE3,AM1,Foundations of analytical methods,Geospatial data analysis has foundations in many different disciplines. As a result - there are many different schools of thought or analytical approaches including spatial analysis - spatial modeling - geostatistics - spatial econometrics - spatial statistics - qualitative analysis - map algebra - and network analysis. This unit compares and contrasts these approaches.,NONE4,AM10-1,Problems of large spatial databases,Difficulties in dealing with large spatial databases - especially those arising from spatial heterogeneity and data quality issues.,NONE5,AM10-2,Data mining approaches,Data mining knows a variety of approaches - such as cluster analysis - analytical reasoning - association - prediction - etc.,NONE6,AM10-3,Knowledge discovery,Knowledge discovery involves the identification of useful patterns in spatial databases using techniques of data mining - trend analysis - etc.,NONE7,AM10,Data mining,Algorithms have been developed to scan and search through extremely large data sets in order to find patterns within the data. These data mining and knowledge discovery techniques have been expanded to the spatial case. Legal and ethical concerns associated with such practices are considered in Knowledge Areas GS GIS and T and Society and OI Organizational and Institutional Aspects.,NONE8,AM11-1,Networks defined,A network is a connected set of lines representing some geographic phenomenon - typically to do with transportation. The “goods” transported can be almost anything: people - cars and other vehicles along a road network - commercial goods along a logistic network - phone calls along a telephone network - or water pollution along a stream/river network.\r\rDirect vs. Non-directed Networks\rA fundamental characteristic of any network is whether the network lines are considered to be directed or not. Directed networks associate with each line a direction of transportation; undirected networks do not. In the latter - the “goods” can be transported along a line in both directions. We discuss here vector network analysis - and assume that the network is a set of connected line features that intersect only at the lines’ nodes - not at internal vertices. (But we do mention under- and overpasses.)\r\rPlanar vs. Non-Planar Networks\rFor many applications of network analysis - a planar network - i.e. one that can be embedded in a two-dimensional plane - will do the job. Many networks are naturally planar - such as stream/river networks. A large-scale traffic network - on the other hand - is not planar: motorways have multi-level crossings and are constructed with underpasses and overpasses. Planar networks are easier to deal with computationally - as they have simpler topological rules. Not all GISs accommodate non-planar networks - or they can only do so using “tricks”. These tricks may involve the splitting of overpassing lines at the intersection vertex and the creation of four lines from the two original lines. Without further attention - the network will then allow one to make a turn onto another line at this new intersection node - which in reality would be impossible. In some GISs we can allocate a cost for turning at a node—see our discussion on turning costs below—and that cost - in the case of the overpass trick - can be made infinite to ensure it is prohibited. But - as mentioned - this is a work around to fit a non-planar situation into a data layer that presumes planarity. The above is a good illustration of geometry not fully determining the network’s behaviour. Additional application-specific rules are usually required to define what can and cannot happen in the network. Most GISs provide rule-based tools that allow the definition of these extra application rules.,NONE9,AM11-2,Graph theoretic descriptive measures of networks,Identifying and listing all elements does not describe a system in full. There may be many different ways in which elements may be connected or related to each other. The interactions - relationships between elements are essential to describe a system.\r\rRelationships between elements can be described by two types of flows:\rflows of material - and flows of information.\r\rMaterial flows connect elements between which there is an exchange of some substance. This can be some kind of material (water - food - cement - biomass - etc.) - energy (light - heat - electricity - etc.) - money - etc. It is something that can be measured and tracked. Also if an element is a donor of this substance the amount of substance in this element will decrease as a result of the exchange - while at the same time the amount of this substance will increase in the receptor element. There is always a mass - or energy conservation law in place. Nothing appears from nothing - and nothing can disappear to nowhere.\r\rThe second type of exchange is with an information flow. In this case element A gets information from element B. Element B at the same time may have no information about element A. Even when element A gets information about B - B does not lose anything. Information can be about the state of an element - about the quantity that it contains - about its presence or absence - etc. Information flows can be used to describe rules and policies. Information flows can modify the rates of flow between elements - they can switch certain processes and interactions on and off. But the process through which policies - interventions and norms for action are established - and could for example define the values of such information flows - are themselves the result of social interaction between relevant stakeholders from public - private or civil society.\r\rThe simplest is to acknowledge the existence of a relationship between certain elements - like this is done in a graph. In a graph a node presents an element and a link between any two nodes shows that these two elements are related. However there is no evidence of the direction of the relationship: we do not distinguish between the element x influencing element y or vice versa. This relationship can be further specified by an oriented graph that shows the direction of the relationship between elements. An element can be also connected to itself - to show that its behaviour depends on its state. We can further detail the description by identifying whether element x has a positive or negative effect on element y.\r\rWith networks - interesting questions arise that have to do with connectivity and network capacity. These relate to applications such as traffic monitoring and watershed management. With network elements—i.e. the lines that make up the network—extra values are commonly associated - such as distance - quality of the link or the carrying capacity.,NONE10,AM11-3,Least-cost shortest path,Optimal-path finding techniques are used when a least-cost path between two nodes in a network must be found. The two nodes are called origin and destination. The aim is to find a sequence of connected lines to traverse from the origin to the destination at the lowest possible cost.\r\rIn Optimal-path finding - the cost function can be simple: for instance - it can be defined as the total length of all lines of the path. The cost function can also be more elaborate and take into account not only length of the lines but also their capacity - maximum transmission (travel) rate and other line characteristics - for instance to obtain a reasonable approximation of travel time. There can even be cases in which the nodes visited add to the cost of the path as well. These may be called turning costs - which are defined in a separate turning-cost table for each node - indicating the cost of turning at the node when entering from one line and continuing on another. This is illustrated in Figure 1 of the examples.\r\rProblems related to optimal-path finding may require ordered optimal path finding or unordered optimal-path finding. Both have as an extra requirement that a number of additional nodes need to be visited along the path. In ordered optimal-path finding - the sequence in which these extra nodes are visited matters; in unordered optimal-path finding it does not.,NONE11,AM11-4,Flow modeling,There are phenomena  that do not spread in all directions - but move or “flows” along a given - least-cost path - determined by characteristics of local terrain. The typical case arises when we want to determine drainage patterns in a catchment area: rain water “chooses” a way to leave the area. \r\rWe can illustrate the principles involved in this typical case with a simple elevation raster. For each cell in that raster - the steepest downward slope to a neighbour cell is computed and its direction is stored in a new raster. This computation determines the elevation difference between the cell and the neighbour cell and it takes into account cell distance - 1 for neighbour cells in N–S or W–E direction - 2 for cells in a NE–SW or NW–SE direction. From among its eight neighbour cells - it picks the one with the steepest path to it. The directions thus obtained in an output raster are encoded in integer values - which can be called the flow-direction raster. From this raster - the GIS can compute the accumulated flow-count raster - a raster that for each cell indicates how many cells have their water flow into that cell.\r\rCells with a high accumulated flow count represent areas of concentrated flow and may - thus - belong to a stream. By using some appropriately chosen threshold value in a map algebra expression - we may decide whether they do or not. Cells with an accumulated flow count of zero are local topographic highs and can be used to identify ridges.,NONE12,AM11-5,The Classic Transportation Problem,The Classic Transportation Problem considers minimizing the cost of getting an object or subject from origin to destination.,NONE13,AM11-6,Other classic network problems,Classic network problems are examples of networking problems such as the Traveling Salesman Problem and the Chinese Postman Problem that need graph algorithms to be solved.,NONE14,AM11-7,Accessibility modeling,Accessibility is the extend in which it is difficult/easy to reach a location or object.,NONE15,AM11,Network analysis,Network analysis encompasses a wide range of procedures - techniques - and methods that allow for the examination of phenomena that can be modeled in the form of connected sets of edges and vertices. Such sets are termed a network or a graph - and the mathematical basis for network analysis is known as graph theory. Graph theory contains descriptive measures and indices of networks such as connectivity - adjacency - capacity - and flow as well as methods for proving the properties of networks. Networks have long been recognized as an efficient way to model many types of geographic data - including transportation networks - river networks - and utility networks electric - cable - sewer and water - etc. to name just a few. The data structures to support network analysis are covered in [DM4-7] Network models.,NONE16,AM12-1,Operations research modeling and location modeling principles,The modeling of problems in a formal language - working in a solution space and applying constraints.,NONE17,AM12-2,Linear programming,A formal programming method to support operational research in which linear constraints are applied.,NONE18,AM12-3,Integer programming,A formal programming method to support operational research in which variables are constrained to integers.,NONE19,AM12-4,Location-allocation modeling and p-median problems,Location-allocation modeling involves the determination of locations by minimizing the distance between object/subjects in space - such as between customers and facilities.,NONE20,AM12,Optimization and location-allocation modeling,A wide variety of optimization techniques are now solvable within the GIS and T domain. Operations research is a branch of mathematics practiced in the allied fields of business and engineering. New models and software tools allow for the solution of transportation routing - facility location - and a host of other location-allocation modeling problems.,NONE21,AM13-1,Impacts of transformations,The effects such as the loss of data quality and data integrity that are the results of data transformations.,NONE22,AM13-2,Data model and format conversion,A data model is an abstract model that organizes elements of data and standardizes how they relate to one another and to the properties of real-world entities. The term data model can refer to two distinct but closely related concepts. In relation to the field of geoinformation the term data model refers to the set of concepts used in defining such formalizations as entities - attributes - relations - tables which is implemented by a mathematical construct for representing geographic objects or surfaces as data. There are two most frequently used data models - which are vector and raster. For example - the vector data model represents geography as collections of points - lines and polygons and more complex structures crated from these three. The raster data model represent geography as cell matrices that store numeric values. Among these two data models we also stand out data formats in which data sets can be stored. File format is a standard of encoding geographical information into a computer file. There are the following basic file formats for encoding data:\rFor vectors:\r-	Shapefile\r-	Geography Markup Language (GML)\r-	XYZ Point Cloud\r-	GeoJSON\r-	GeoMedia\r-	\rFor rasters:\r-	GeoTIFF\r-	IMG\r-	JPEG2000\r-	Esri grid\rThe GIS projects often require the conversion of the data formats. Data conversion is the process of moving data from one format to another - whether it is from one data model to another or from one data format to another. Data conversion is a complex process which is not only associated with changing the binary format of the file but also requires changing the structure of the data. For example - the GML data format always comes with an UML diagram - which is necessary to convert attributes stored in GML structure for example to a table of contest in a shapefile data format. In a well-managed GIS project it is important to store data in specific data model or data format. It is sometimes dictated by software capabilities and another times by team’s technical capabilities. With large amounts of geographic data used in the project it is more cost-effective to convert the data from one format to another than re-create it.,NONE23,AM13-3,Interpolation,Interpolation is used to create a GIS layer out of point observations on a continuous variable. The reason for doing this could be manifold: for visualization purposes - for making a proper reference with other data - or for making a combination of different layers.,NONE24,AM13-4,Vector-to-raster and raster-to-vector conversions,Any vector data containing point - polyline - polygon can be converted into the raster dataset and vice versa. The vector data can be stored in shapefiles - databases or various others GIS file formats. The raster data are made of pixels or grid calls and can be represented by the discrete - categorical data (e.g. land cover map) or non-discrete - continuous data (e.g. satellite images - surface data). The process of conversion of vector to raster data is called rasterization. The vector to raster conversion requires the following parameters: the field value from the attribute table used to assign values to the output raster - the pixel size for the output raster - the output raster format (i.e. geotiff - img) and optionally the method of assigning values of point - polyline or polygon to the call raster - i.e. maximum length or area - cell centre. The output of the rasterised vector looks like a gridded version of the vector and it depends on the grid cell size. The process of vectorisation refers to the conversion of raster to vector dataset. The raster dataset can be converted to vector point - polyline or polygon. In order to convert raster to vector the following parameters should be provided: attribute field of the input raster dataset which will become an attribute in the output vector class - determining if the output polygon or polyline will be smoothed into simpler shapes or conform to the input raster's cell edges (stair stepping). For each raster pixel or grid cell a point will be created at the centre of the cell. The non-discrete continuous raster data have to converted to the categorical data type before converting to vector data. The conversion of vector to raster and raster to vector degrade the data to some extent causing loss of details - accuracy - and changing the original data.,NONE25,AM13-5,Raster resampling,Raster resampling refers to change of spatial resolution (increasing or decreasing) of the raster dataset. The resampling process calculates the new pixel values from the original digital pixel values in the uncorrected image. There are three common methods for resampling: nearest neighbour - bilinear interpolation - and cubic convolution. The nearest neighbour resampling uses the digital value from the pixel in the original image which is nearest to the new pixel location in the corrected image. This is the fastest interpolation method - which is primarily applied for discrete (categorical) raster data as it does not change the value of the pixel - but may result in some pixel values being duplicated while others are lost. Bilinear interpolation resampling takes a weighted average of four pixels in the original image nearest to the new pixel location. The averaging process alters the original pixel values and creates entirely new digital values in the output image. It is recommended for continuous data and it cause some smoothing of the data. Cubic convolution resampling is based on calculation of a distance weighted average of a block of sixteen pixels from the original image which surround the new output pixel location. As with bilinear interpolation - this method results in completely new pixel values. However - the last two methods both produce images which have a much sharper appearance and avoid the blocky appearance of the nearest neighbour method. The disadvantage of the Cubic method is that its requires more processing time.,NONE26,AM13-6,Coordinate transformations,Users of geoinformation often need transformations from a particular 2D coordinate system to another system. This includes the transformation of polar coordinates into Cartesian map coordinates - or  the change of map projection -  transformation from one 2D Cartesian (x - y) system of a specific map projection into another 2D Cartesian (x′ - y′) system of a defined map projection. This transformation is based on relating the two systems on the basis of a set of selected points whose coordinates are known in both systems - such as ground control points or common points such as corners of houses or road intersections. Image and scanned data are usually transformed by this method. The transformations may be conformal - affine - polynomial or of another type - depending on the geometric errors in the data set. A datum transformation involves the change of the horizontal datum which is often accompanied with a change of map projection.,NONE27,AM13,Representation transformation,GIS is a cyclical rather than a linear system - unlike computer aided drafting (CAD) and computer assisted cartographic systems. Changes in projection - grid systems - data forms - and formats take place during the modeling process for which GIS was designed. Many non-analytical manipulations are necessary to accommodate the analytical power of the GIS. The manipulations of spatial and spatio-temporal data involve two general classes of operation: 1.	Their transformation into formats that facilitate subsequent analysis 2. Generalization and aggregation that affect the accuracy and integrity of the data used for analysis (see [AM14]). Other knowledge areas have identified different forms of data structures - data models - projections - and other forms of geospatial data representation. These differences present both opportunities and challenges for analysis and modeling. The ability to transform one representation to another - in a manner that maintains the integrity of the information as much as possible - can enhance the analysis and visualization of geospatial data. The raster and vector data models are described in [DM3] Tesselation data models and [DM4] Vector data model - Feature based modelling - Applications. The principles of coordinate systems - datums - and projections are also considered in Knowledge Area [GD] Geospatial Data,NONE28,AM14-1,Scale and generalization,In the practice of spatial data handling - one often comes across questions like “What is the resolution of the data?” or “At what scale is your data set?” Now that we have moved firmly into the digital age - these questions sometimes defy an easy answer. Map scale can be defined as the ratio between the distance on a printed map and the distance of the same stretch in the terrain.\r\rA 1:50 -000 scale map means that 1 cm on the map represents 50 -000 cm (i.e. 500 m) in the terrain. “Large-scale” means that the ratio is relatively large - so typically it means there is much detail to see - as on a 1:1000 printed map. “Small-scale” - in contrast - means a small ratio - hence less detail - as on a 1:2 -500 -000 printed map.\rDigital spatial data - as stored in a GIS - are essentially without scale: scale is a ratio notion associated with visual output - such as a map or on-screen display - not with the data that was used to produce the map or display. When digital spatial data sets have been collected with a specific map-making purpose in mind - and all maps have been designed to use one single map scale - for instance 1:25 -000 - we may assume that the data carries the characteristic of “a 1:25 -000 digital data set.”\r\rThere is a relationship between the effectiveness of a map for a given purpose and the map’s scale. The Public Works department of a city council cannot use a 1:250 -000 map for replacing broken sewer pipes - and the map of Figure 1 cannot be reproduced at scale 1:10 -000.\r\rMaps that show much detail of a small area are called large-scale maps. Scale indications on maps can be given verbally - such as “one-inch-to the- mile” - or as a representative fraction like 1:200 -000 -000 (1 cm on the map equals 200 -000 -000 cm (or 2000 km) in reality) - or by a graphic representation such as the scale bar. The advantage of using scale bars in digital environments is that its length also changes when the map is zoomed in - or enlarged - before printing. Sometimes it is necessary to convert maps from one scale to another - which may lead to problems of cartographic generalization.\r\rSpatial and temporal scales can not only be attached to processes - but also to observations. An example is given below - which summarizes the spatial and temporal scales of a few well-known Earth observation systems.\r\rScales of RS observations\rSensor              Spatial scale	  Temporal scale\rMeteosat	  Hemisphere	  15 minutes\rNOAA-AVHRR	  3000 km	  daily\rLandsat TM	  180 km	          16 days\rSpot	          60 km	          26 days (pointable),NONE29,AM14-2,Approaches to point - line - and area generalization,Techniques that support the generalisation of map content when changing to smaller map scales. These include line simplification - object selection - etc.,NONE30,AM14-3,Classification and transformation of attribute measurement levels,Classification is a technique for purposely removing detail from an input data set in the hope of revealing important patterns (of spatial distribution). In the process - we produce an output data set - so that the input set can be left intact. This output set is produced by assigning a characteristic value to each element in the input set - which is usually a collection of spatial features that could be raster cells or points - lines or polygons. If the number of characteristic values in the output set is small in comparison to the size of the input set - we have classified the input set.\r\rThe input data set may - itself - have been the result of a classification. In such cases we refer to the output data set as a reclassification. For example - we may have a soil map that shows different soil type units and we would like to show the suitability of units for a specific crop. In this case - it is better to assign to the soil units an attribute of suitability for the crop. Since different soil types may have the same crop suitability - a classification may merge soil units of different type into the same category of crop suitability.\r\rIn classification of vector data - there are two possible results. In the first - the input features may become the output features in a new data layer - with an additional category assigned. In other words - nothing changes with respect to the spatial extents of the original features. Figure a of Examples illustrates this first type of output. A second type of output is obtained when adjacent features of the same category are merged into one bigger feature. Such a post-processing function is called spatial merging - aggregation or dissolving. An illustration of this second type is found in Figure b of Examples. Observe that this type of merging is only an option in vector data - as merging cells in an output raster on the basis of a classification makes little sense. Vector data classification can be performed on point sets - line sets or polygon sets; the optional merge phase only makes sense for lines and polygons.\r\rUser-controlled classifications require a classification table or user interaction. GIS software can also perform automatic classification - in which a user only specifies the number of classes in the output data set. The system automatically determines the class break points. The two main techniques of determining break points being used are the equal interval technique and the equal frequency technique.\r\rEqual Interval Technique\rThe minimum and maximum values vmin and vmax of the classification parameter are determined and the (constant) interval size for each category is calculated as (vmax - vmin) ∕ n - where n is the number of classes chosen by the user. This classification is useful in that it reveals the distribution pattern - as it determines the number of features in each category.\r\rEqual Frequency Technique\rThis technique is also known as quantile classification. The objective is to create categories with roughly equal numbers of features per category. The total number of features is determined first - then - based on the required number of categories - the number of features per category is calculated. The class break points are then determined by counting off the features in order of classification parameter value.,NONE31,AM14,Generalization and aggregation,Generalization addresses the meaningful reduction of the map content during scale reduction. All geospatial data are generalized. Even the most detailed data represent only subsets of reality. Furthermore - data are further generalized for purposes of mapping - visualization - and efficient storage. A variety of generalization techniques have been developed to facilitate this process. All are scale dependent. Aggregation is one form of generalization that transforms large numbers of individual objects into summarized groups. This concept description is concerned with the nature of these procedures and their implications for professional practice. Generalization is an important part of cartography (and is therefore discussed conceptually in CV2 Data considerations) - but is also a transformation common to many GIS procedures.,NONE32,AM2-1,Set theory,Set theory is based on describing collections of members within sets. The Boolean membership function is binary - i.e. an element is either a member of the set (membership is true) or it is not a member of the set (membership is false). Such a membership notion is well-suited to the description of spatial features such as land parcels for which no ambiguity is involved and an individual ground truth sample can be judged to be either correct or incorrect. As Burrough and Frank (1996) note - increasingly - people are beginning to realize that the fundamental axioms of simple binary logic present limits to the way we think about the world. Not only in everyday situations - but also in formalized thought - it is necessary to be able to deal with concepts that are not necessarily true or false - but that operate somewhere in between. Since its original development by Zadeh (1965) - there has been considerable discussion of fuzzy - or continuous - set theory as an approach for handling imprecise spatial data. In GIS - fuzzy set theory appears to have two particular benefits: the ability to handle logical modelling (map overlay) operations on inexact data; and the possibility of using a variety of natural language expressions to qualify uncertainty. Unlike Boolean sets - fuzzy or continuous sets have a membership function - which can assign to a member any value between 0 and 1.,NONE33,AM2-2,Structured Query Language (SQL) and attribute queries,The most common operator for defining queries in a relational database is the language SQL - which stands for Structured Query Language.\r\rA spatial DBMS provides support for geographic coordinate systems and transformations. It will also provide storage of the relationships between features - including the creation and storage of topological relationships. As a result - one is able to use functions for “spatial query” (exploring spatial relationships). To illustrate - a spatial query using SQL to find all the Thai restaurants within 2 km of a given hotel would look like:\r\rSELECT R.Name\rFROM Restaurants AS R -\rHotels as H\rWHERE R.Type = Thai AND\rH.name = Hilton AND\rIntersect(R.Geometry - Buffer(H.Geometry - 2))\r\rThe Intersect command creates a spatial join between restaurants and hotels. The Geometry column carries the spatial data. It is likely that in the near future all spatial data will be stored directly in spatial databases.,NONE34,AM2-3,Spatial queries,When exploring a spatial data set - the first thing one usually wants to do is select certain features - to (temporarily) restrict the exploration. Such selections can be made on geometric/spatial grounds or on the basis of attribute data associated with the spatial features. \r\rSelection conditions on attribute values can be combined using logical connectives such as AND - OR and NOT. Other techniques of selecting features can also usually be combined. Any set of selected features can be used as the input for a subsequent selection procedure. This means - for instance - that we can select all medical clinics first - then identify roads within 200 m of them - then select from those only the major roads - then select the nearest clinics to these remaining roads as the ones that should receive our financial support for maintenance. In this way - we are combining various techniques of selection.\r\rInteractive Spatial Selection\rIn interactive spatial selection - one defines the selection condition by pointing at or drawing spatial objects on the screen display - after having indicated the spatial data layer(s) from which to select features. The interactively defined objects are called the selection objects; they can be points - lines - or polygons. The GIS then selects the features in the indicated data layer(s) that overlap (i.e. intersect - meet - contain - or are contained in;) with the selection objects. These become the selected objects.\rInteractive spatial selection answers questions like “What is at …?”\r\rA spatial DBMS provides support for geographic coordinate systems and transformations. It will also provide storage of the relationships between features - including the creation and storage of topological relationships. As a result - one is able to use functions for “spatial query” (exploring spatial relationships). To illustrate - a spatial query using SQL to find all the Thai restaurants within 2 km of a given hotel would look like:\r\rSELECT R.Name\rFROM Restaurants AS R -\rHotels as H\rWHERE R.Type = Thai AND\rH.name = Hilton AND\rIntersect(R.Geometry - Buffer(H.Geometry - 2))\r\rThe Intersect command creates a spatial join between restaurants and hotels. The Geometry column carries the spatial data. It is likely that in the near future all spatial data will be stored directly in spatial databases.,NONE35,AM2,Query operations and query languages,Attribute and spatial query operations are core functionality in any GIS and they are often considered to be the most basic form of analysis.,NONE36,AM3-1,Distances and lengths,In a 2D polar coordinate system points can be described with coordinates. Another way of defining a point in a plane is by using polar coordinates. This is the distance d from the origin to the point concerned and the angle α between a fixed (or zero) direction and the direction to the point. The angle α is called azimuth or bearing and is measured in a clockwise direction. It is given in angular units while the distance d is expressed in length units. \r\rDistance also plays a role in computations on networks - comprising a different set of analytical functions in GISs. Here - the network may consist of roads - public transport routes - high-voltage power lines - or other forms of transportation infrastructure. Analysis of networks may entail shortest path computations (in terms of distance or travel time) between two points in a network for routing purposes. Other forms are to find all points reachable within a given distance or duration from a start point for allocation purposes - or determination of the capacity of the network for transportation between an indicated source location and sink location.\r\rIn raster images - the distance function applied is the Pythagorean distance between the cell centres. The distance from a non-target cell to the target is the minimal distance one can find between that non-target cell and any target cell.,NONE37,AM3-2,Direction,In a 2D polar coordinate system points can be described with coordinates. Another way of defining a point in a plane is by using polar coordinates. This is the distance d from the origin to the point concerned and the angle α between a fixed (or zero) direction and the direction to the point. The angle α is called azimuth or bearing and is measured in a clockwise direction. It is given in angular units while the distance d is expressed in length units.\r\rBearings are always related to a fixed direction (initial bearing) or a datum line. In principle - this reference line can be chosen freely. Three different - widely used fixed directions are: True North - Grid North and Magnetic North. The corresponding bearings are true (or geodetic) bearings - grid bearings and magnetic (or compass) bearings - respectively.\r\rIn raster images - direction is determined by the orientation of the neighboring pixels.,NONE38,AM3-3,Shape,The representation of geographic objects is most naturally supported with vectors. After all - objects are identified by the parameters of location - shape - size and orientation - and many of these parameters can be expressed in terms of vectors. We can define features within the topological space that are easy to handle and that can be used as representations of geographic objects. These features are called simplices as they are the simplest geometric shapes of some dimension: point (0-simplex) - line segment (1-simplex) - triangle (2-simplex) - and tetrahedron (3-simplex). When we combine various simplices into a single feature - we obtain a simplicial complex. When area objects are stored using a vector approach - the usual technique is to apply a boundary model. This means that each area feature is represented by some arc/node structure that determines a polygon as the area’s boundary. A polygon representation for an area object is another example of a finite approximation of a phenomenon that may have a curvilinear boundary in reality. In images - the shape of objects often helps us to identify them (built-up areas - roads and railroads - agricultural fields - etc.).,NONE39,AM3-4,Area,When area objects are stored using a vector approach - the usual technique is to apply a boundary model. This means that each area feature is represented by some arc/node structure that determines a polygon as the area’s boundary. A polygon representation for an area object is another example of a finite approximation of a phenomenon that may have a curvilinear boundary in reality.\rCommon sense dictates that area features of the same kind are best stored in a single data layer - represented by mutually non-overlapping polygons. This results in an application-determined (i.e. adaptive) partition of space. If the object has a fuzzy boundary - a polygon is an even worse approximation - even though potentially it may be the only one possible. Clearly - we expect additional data to accompany the area data. Such information could be stored in database tables.\r\rA simple but naïve representation of area features would be to list for each polygon the list of lines that describes its boundary. Each line in the list would - as before - be a sequence that starts with a node and ends with one - possibly with vertices in between. As the same line makes up the boundary from the two polygons - this line would be stored twice in the above representation - namely once for each polygon. This is a form of data duplication—known as data redundancy—which is (at least in theory) unnecessary - although it remains a feature of some systems. Another disadvantage of such polygon-by-polygon representations is that if we want to identify the polygons that border the bottom left polygon - we have to do a complicated and time-consuming search analysis comparing the vertex lists of all boundary lines with that of the bottom left polygon. For just a few polygons - this is fine - but in a data set with 5000 polygons - and perhaps a total of 25 -000 boundary lines - this becomes a tedious task - even with the fastest of computers.,NONE40,AM3-5,Proximity and distance decay,Proximity computations are specific neighbourhood functions. They evaluate the characteristics of an area surrounding a feature’s location. A neighbourhood function “scans” the neighbourhood of the given feature(s) - and performs a computation on it (them).\r\rExamples of proximity computations are: (1) Buffer zone generation (or buffering) is one of the best-known neighbourhood functions. It determines a spatial envelope (buffer) around a given feature or features. The buffer created may have a fixed width or a variable width that depends on characteristics of the area. (2) Thiessen Polygon generation.\r\rDistance decay functions describe the effect of the reduced influence when the distance between two locations increases.,NONE41,AM3-6,Adjacency and connectivity,Adjacency is the meet relationship as a topological property of a geographic object in relation ship with another. The adjacency operator identifies those features that share boundaries and - therefore - applies only to line and polygon features.\rThis meet relationship is invariant under a continuous transformation and are referred to as a topological mapping.,NONE42,AM3,Geometric measures,For simple data exploration - GIS offers many basic geometric operations that help in extracting meaning from sets of data or for deriving new data for further analysis. Concepts on which these operations are based are addressed in Domains of geographic information and Relationships.\r\rWe can - for instance - measure angles on a map and use these for navigation in the real world - or for setting out a designed physical infrastructure. Or if - instead of a conformal projection such as UTM - we use an equivalent projection - we can determine the size of a parcel of land from the map—irrespective of where the parcel is on the map and at which elevation it is on the Earth.,NONE43,AM4-1,Reclassification and selection operations,The reclassifications tools are used to change or reclassify the values. Reclassification of vector data involves the attributes of features in the feature attribute table - on the other hand reclassification of raster data involves the grid cell values to produce a new raster data layer. Reclassification can be used for data simplification and measurement scale change. We can adjust the data for more appropriate analysis by grouping the values and changing them. The reclassification tool can also be used to remove specific values from analysis.\rThe Select by location tool lets you select features by how they relate to other features in another layer. Selected features are based on their location. You can select features that are near or overlap the features. Most frequently used methods are intersect - within a distance - within - completely within - contain… Features can be selected in the same or other layers.\rThe Select by attributes tool lets you select features that match the selection criteria. With providing a selection criteria - matching features are selected. We can provide a complex selection criteria.,NONE44,AM4-2,Buffers,Buffer analysis is one form of basic spatial analysis. It takes the vector representation (point - line - or polygon) of a real-world feature - and then creates a buffer zone based on a defined distance from the feature’s border. Thus - the created buffer zone is an area whose boundary always has the same distance to the input vector feature - e.g. the buffer zone for a point feature is a circle. Real-world examples for buffer zones could be protected areas along rivers or around nature conservation areas - or represent a simple proximity analysis. In the latter case - the buffer analysis is usually the first step of the analysis - followed by an overlay of the buffer zone with the target features to find those target features within the buffer zone - and thus within a certain distance of the original feature. Usually - the buffer zone extends outwards from the feature - but polygons can also have inner buffer zones. If the buffer zones from multiple features overlap - the analyst can decide to leave the individual boundaries of the buffer zones intact - or to dissolve them - i.e. merging the overlapping buffer zones into one larger buffer zone. The size of the buffer zone - i.e. the distance of its boundary from the original feature’s boundary - can be based on an uniform numerical value and associated spatial unit - but often - it is based on an attribute value (numerical or class) of the feature. Conceptually - buffering using raster representations of real-world features is similar a proximity analysis with a regular grid of square polygons: Departing from raster cells that form the area to be buffered - all raster cells that fall within the designated distance (overlay) from the buffer zone. With buffer analysis being a basic analytical operation - practically every GIS and many other analysis tools provide this functionality.,NONE45,AM4-3,Overlay,Overlay functions is one of the most frequently used functions in a GIS application. They combine two (or more) spatial data layers - comparing them position by position and treating areas of overlap - and of non-overlap - in distinct ways.\r\rStandard overlay operators take two input data layers and assume that they are georeferenced in the same system and that they overlap in the study area. If either of these requirements is not met - the use of an overlay operator is pointless. The principle of spatial overlay is to compare the characteristics of the same location in both data layers and to produce a result for each location in the output data layer. The specific result to produce is determined by the user. It might involve a calculation or some other logical function to be applied to every area or location. With raster data - as we shall see - these comparisons are carried out between pairs of cells - one from each input raster. With vector data - the same principle of comparing locations applies but the underlying computations rely on determining the spatial intersections of features from each input layer.\r\rVector overlay operators are useful but geometrically complicated - and this sometimes results in poor operator performance. Raster overlays do not suffer from this disadvantage - as most of them perform their computations cell by cell - and thus they are fast. GISs that support raster processing - as most do - usually have a language to express operations on rasters. These languages are generally referred to as map algebra or - sometimes - raster calculus. They allow a GIS to compute new rasters from existing ones - using a range of functions and operators. Unfortunately - not all implementations of map algebra offer the same functionality.,NONE46,AM4-4,Neighborhood analysis,Neighbourhood functions evaluate the characteristics of an area surrounding a feature’s location. A neighbourhood function “scans” the neighbourhood of the given feature(s) - and performs a computation on it (them). Examples of proximity computations are: (1) Buffer zone generation (or buffering) is one of the best-known neighbourhood functions. It determines a spatial envelope (buffer) around a given feature or features. The buffer created may have a fixed width or a variable width that depends on characteristics of the area. (2) Thiessen Polygon generation. For raster images: (3) Computation of diffusion (4) Flow computation.\r\rFor instance - our target might be a medical clinic. Its neighbourhood could be defined as:\r\ran area within a radius of 2 km distance as the crow flies; or\ran area within 2 km travelling distance; or\rall roads within 500 m travelling distance; or\rall other clinics within 10 minutes travelling time;\rall residential areas for which the clinic is the closest clinic.\r\rFinally - in the third step we indicate what it is we want to discover about the phenomena that exist or occur in the neighbourhood. This might simply be its spatial extent - but it might also be statistical information such as:\r\rhow many people live in the area;\rwhat is their average household income;\rare any high-risk industries located in the neighbourhood.\r\rThese are typical questions in an urban setting. When our interest is more in natural phenomena - different examples of locations - neighbourhoods and neighbourhood characteristics arise.\r\rThe principle in this case is to find out the characteristics of the vicinity - here called neighbourhood - of a location. After all - many suitability questions - for instance - depend not only on what is at a location but also on what is near the location. Thus - the GIS must allow us “to look around locally”. To perform neighbourhood analysis - we must:\r\r1. state which target locations are of interest to us and define their spatial extent;\r2. define how to determine the neighbourhood for each target; and\r3. define which characteristic(s) must be computed for each neighbourhood. \r\rSince raster data are the more commonly used in this case - neighbourhood characteristics often are obtained via statistical summary functions that compute values such as the average - minimum - maximum and standard deviation of the cells in the identified neighbourhood.\r\rTo select target locations - one can use the selection techniques. To obtain characteristics from an eventually-to-be identified neighbourhood - the same techniques apply. So what remains to be discussed here is the proper determination of a neighbourhood. One way of determining a neighbourhood around a target location is by making use of the geometric distance function. Geometric distance does not take into account direction - but certain phenomena can only be studied by doing so. Think of the spreading of pollution by rivers - groundwater flow or prevailing weather systems.\r\rDiffusion functions are based on the assumption that the phenomenon in question spreads in all directions - though not necessarily equally easily in each direction. Hence it uses local terrain characteristics to compute local resistances to diffusion.,NONE47,AM4-5,Map algebra,GISs that support raster processing - as most do - usually have a language to express operations on rasters. These languages are generally referred to as map algebra or - sometimes - raster calculus. They allow a GIS to compute new rasters from existing ones - using a range of functions and operators. Unfortunately - not all implementations of map algebra offer the same functionality. The discussion below is to a large extent based on general terminology; it attempts to illustrate the key operations using a logical - structured language. Again - the syntax often varies among different GIS software packages.\r\rWhen producing a new raster we must provide a name for it - and define how it is to be computed. This is done in an assignment statement of the following format:\r\rOutput raster name := Map algebra expression.\r\rThe expression on the right is evaluated by the GIS - and the raster in which it results is then stored under the name on the left. The expression may contain references to existing rasters - operators and functions; the format is made clear in each case. The raster names and constants that are used in the expression are called its operands. When the expression is evaluated - the GIS will perform the calculation on a pixel-by-pixel basis - starting from the first pixel in the first row and continuing through to the last pixel in the last row. In map algebra - there is a wide range of operators and functions available.\r\rArithmetic operators\rVarious arithmetic operators are supported. The standard ones are multiplication (×) - division (/) - subtraction (-) and addition (+). Obviously - these arithmetic operators should only be used on appropriate data values - and - for instance - not on classification values. Other arithmetic operators may include modulo division (MOD) and integer division (DIV). Modulo division returns the remainder of division: for instance - 10 MOD 3 will return 1 as 10 - 3 × 3 = 1. Similarly - 10 DIV 3 will return 3.\r\rOther operators are goniometric: sine (sin) - cosine (cos) - tangent (tan); and their inverse functions asin - acos - and atan - which return radian angles as real values.  The assignment\r\rC1 := A + 10\r\rwill add a constant factor of 10 to all cell values of raster A and store the result as output raster C1. The assignment\r\rC2 := A + B\r\rwill add the values of A and B cell by cell - and store the result as raster C2. Finally - the assignment\r\rC3 := (A - B) ∕ (A + B) × 100\r\rwill create output raster C3 - as the result of the subtraction (cell by cell - as usual) of B cell values from A cell values - divided by their sum. The result is multiplied by 100. This expression - when carried out on AVHRR channel 1 (red) and AVHRR channel 2 (near infrared) of NOAA satellite imagery - is known as the NDVI (Normalized Difference Vegetation Index). It has proven to be a good indicator of the presence of green vegetation.\r\rComparison and logical operators\r\rMap algebra also allows the comparison of rasters cell by cell. To this end - we may use the standard comparison operators (< - ⇐ - = - >= - > and <>).\r\rA simple raster comparison assignment is\r\rC := A <> B.\r\rIt will store truth values—either true or false—in the output raster C. A cell value in C will be true if the cell’s value in A differs from that cell’s value in B. It will be false if they are the same. Logical connectives are also supported in many raster calculi. We have already seen the connectives of AND  - OR and NOT in raster overlay operators. Another connective that is commonly offered in map algebra is exclusive OR (XOR). The expression a XOR b is true only if either a or b is true - but not both.\r\rConditional expressions\rThe comparison and logical operators produce rasters with the truth values true and false. In practice - we often need a conditional expression together with them that allows us to test whether a condition is fulfilled. The general format is:\r\rOutput raster := CON(condition - then expression - else expression).\r\rHere - condition stands for the condition tested - then the expression is evaluated if condition holds - and else the expression is evaluated if it does not hold. This means that an expression such as CON(A = “forest” - 10 - 0) will evaluate to 10 for each cell in the output raster where the same cell in A is classified as forest. For each cell where this is not true - the else expression is evaluated - resulting in 0.\r\rOverlays using a decision table\rConditional expressions are powerful tools in cases where multiple criteria must be taken into account. A small example may illustrate this. Consider a suitability study in which a land use classification and a geological classification must be used.  Domain expertise dictates that some combinations of land use and geology result in suitable areas - whereas other combinations do not. In our example - forests on alluvial terrain and grassland on shale are considered suitable combinations - while any others are not.\r\rWe could produce an output raster with a map algebra expression - such as\r\rSuitability := CON((Landuse = “Forest” AND Geology = “Alluvial”)\rOR (Landuse = “Grass” AND Geology = “Shale”) -\r“Suitable” - “Unsuitable”)\r\rand consider ourselves lucky that there are only two “suitable” cases. In practice - many more cases must usually be covered and - then - writing up a complex CON expression is not an easy task.\r\rTo this end - some GISs accommodate setting up a separate decision table that will guide the raster overlay process. This extra table carries domain expertise and dictates which combinations of input raster-cell values will produce which output raster-cell value. This gives us a raster overlay operator using a decision table. The GIS will have supporting functions to generate the additional table from the input rasters and to enter appropriate values in the table.,NONE48,AM4,Basic analytical operations,This small set of analytical operations is so commonly applied to a broad range of problems that their inclusion in software products is often used to determine if that product is a true GIS. Concepts on which these operations are based are addressed in Domains of geographic information and Relationships.,NONE49,AM5-1,Point pattern analysis,Point pattern analysis refers to the detection of patterns in a group of objects or subjects located in space. This may support the analysis of clusters in accidents - crime - etc.,NONE50,AM5-2,Kernels and density estimation,The probability density function is a method with which the probability density can be estimated for points in a raster space.,NONE51,AM5-3,Spatial cluster analysis,Spatial cluster analysis is the grouping of similar spatial objects into classes (clusters) in such a way that the objects within the cluster are highly similar compared to the objects outside of the cluster. Spatial clustering forms an important part of spatial data mining (Han et al. - 2001; Miller et al. - 2009). A wealth of spatial clustering tools are currently available with immense application potential.  \r\rIn earth observation studies - spatial cluster techniques are often applied to identify zones with similar land covers by using earth observation data as input. An example of such a technique is the K-means classifier (Han et al. - 2001; Miller et al. - 2009). This unsupervised classification technique makes several clusters (e.g. land use classes) of which each pixel is assigned to the cluster with the nearest mean (Han et al. - 2001). The amount of clusters can be freely defined by the user just as the input metrics to perform the classification.  A drawback of the K-means classifier is the need to specify the amount of output clusters. Density Based Spatial Clustering (DBSC) overcomes this issue since it automatically defines the optimal amount of clusters (Miller et al. - 2009). In this type of clustering technique - dense regions of objects (proximate objects) are clustered and separated from regions with low density (noise) (Han et al. - 2001; Liu et al. - 2012). Finally - another frequently applied spatial clustering technique is the hierarchical agglomerative clustering. This technique makes use of a dendrogram to decompose the data into clusters. The agglomerative approach is a bottom-up approach in which all objects are first grouped in a distinct cluster and while moving upward in the tree - pairs of clusters are merged based on some metrics (e.g. spatial proximity) (Han et al. - 2001). \r\rSpatial cluster techniques have many advantages when dealing with big datasets which is often the case when working with earth observation data. Its simplicity to use and the fast increase of cloud computing power makes from it powerful techniques to extract spatial patterns out of the data. It allows to translate raw earth observation data into a more user-friendly data product by showing the spatial patterns of the data.,NONE52,AM5-4,Spatial interaction,Spatial interaction models describe the flow of people and goods in a geographical space - in which parameters such as friction and distance play a role.,NONE53,AM5-5,Analyzing multidimensional attributes,Multidimensional attributes can be analyzed through multidimensional scaling and principle component analysis.,NONE54,AM5-7,Multi-criteria evaluation,Multi-criteria evaluation is an important aspect of decision support operations - which appear in process models. Process models in the Earth sciences describe the evolution of geo(bio)physical surface properties in time - independently from remote sensing observations. Examples of such process models on various time scales are - for instance - numerical weather prediction models (NWPs) - vegetation growth models - hydrological models - oceanographic models and climate models.\r\rObservation models and process models can supplement each other to enhance the quality of the interpretation of remote sensing data and to fill gaps in time that occur when observations are not possible owing to clouds or some other cause. Interactions are possible between observation models and process models with EO data and existing geographic information (GIS and ground measurements - supplemented with decision-support systems (DSSs)).\r\rThe process model provides information to the decision-support system - which supports management actions aimed at controlling/mitigating the process - based on an multi-criteria evaluation. A good example of this is a water management system - in which one might decide to allocate water for irrigation if the observed vegetation appears to suffer from drought stress.,REMOTE SENSING55,AM5-8,Spatial process models,Process models in the Earth sciences describe the evolution of geo(bio)physical surface properties in time - independently from remote sensing observations. Examples of such process models on various time scales are - for instance - numerical weather prediction models (NWPs) - vegetation growth models - hydrological models - oceanographic models and climate models.\rProcess models in the geosciences usually rely on regular observations at many locations spread over a large area. Traditionally - these observations were mostly made in the field with a variety of instruments. Remote sensing techniques have tremendously increased the capability of spatial sampling and the consistency of the surface parameters measured. RS instruments are mostly sensitive to many physical properties of the surface - some of these may not belong to the set of properties that the user is interested in. Exceptions to this are the mapping of sea-surface temperature - laser altimetry and gravimetry - which are measurements of direct geophysical interest. In the majority of cases - however - there are only indirect relationships between what is observed with the instrument and the physical object properties of interest. In these cases - the use of observation models becomes an attractive option - since these models describe the relationships between all object properties relevant for the observation and the observed remote sensing data.,REMOTE SENSING56,AM5,Basic analytical methods,Building on the basic geometric measures and analytical operations found in most GIS products - a broad range of additional analytical methods form the fundamental GIS toolkit.,NONE57,AM6-2,Interpolation of surfaces,In rasters we use interpolation to determine the value of a pixel - based on its surrounding pixels. The main raster-based interpolation methods are nearest neighbour - bilinear - and bicubic interpolation. To determine the value of the centre pixel (bold) - in nearest neighbour interpolation the value of the nearest original pixel is assigned - i.e. the value of the black pixel in this example. Note that the respective pixel centres - marked by small crosses - are always used for this process. In bilinear interpolation - a linear weighted average is calculated for the four nearest pixels in the original image. In bicubic interpolation a cubic weighted average of the values of 16 surrounding pixels (the black and all grey pixels) is calculated. Note that some software uses the terms “bilinear convolution” and “cubic convolution” instead of the terms introduced above.,NONE58,AM6-3,Surface features,Continuous fields have a number of characteristics not shared by discrete fields. Since the field changes continuously - we can talk of slope angle - slope aspect and concavity/convexity of the slope.\r\rThese notions are not applicable to discrete fields. The discussions in this subsection use terrain elevation as the prototype example of a continuous field - but all aspects discussed are equally applicable to other types of continuous fields. Nonetheless - we regularly refer to the continuous field representation as a DEM - to conform with the most common situation.,NONE59,AM6-4,Intervisibility,A viewshed is the area that can be “seen” (i.e. it is in the direct line-of-sight) from a specified target location. (Inter) visibility analysis can determine the area visible from a scenic lookout or the area that can be reached by a radar antenna - as well as assess how effectively a road or quarry will be hidden from view.,NONE60,AM6-5,Friction surfaces,Firction surfaces contain information on how difficult/easy it is for a phenomenon to move from one location on the surface to another.,NONE61,AM6,Analysis of surfaces,There is a wide range of phenomena that can be studied using a set of techniques and tools that are designed to help understand the characteristics of continuous surface data. Applications of these techniques using terrain data include overland transport - flow - and siting tasks - but similar analyses can be conducted using non-tangible surfaces such as those of temperature - pressure and population density.\r\rThere are numerous examples that require more advanced computations on continuous field representations - such as:\r\rSlope angle calculation - the calculation of the slope steepness - expressed as an angle in degrees or percentages - for any or all locations.\r\rCalculating slope aspect - the calculation of the aspect (or orientation) of the slope in degrees (between 0 and 360∘) - for any or all locations.\r\rSlope convexity/concavity calculation - defined as the change of the slope (negative when the slope is concave and positive when the slope is convex)—can be calculated as the second derivative of the field.\r\rSlope length calculation - with the use of neighbourhood operations - it is possible to calculate for each cell the nearest distance to a watershed boundary (the upslope length) and to the nearest stream (the downslope length). This information is useful for hydrological modelling.\r\rHillshading is used to portray relief difference and terrain morphology of hilly and mountainous areas. The application of a special filter to a DEM produces hillshading. The colour tones in a hillshading raster represent the amount of reflected light at each location - depending on its orientation relative to the illumination source. This illumination source is usually chosen to be to the northwest at an angle of 45∘ above the horizon.\r\rThree-dimensional map display - with GIS software - three-dimensional views of a DEM can be constructed in which the location of the viewer - the angle under which he or she is looking - the zoom angle - and the amplification factor of relief exaggeration can be specified. Three-dimensional views can be constructed using only a predefined mesh - covering the surface - or using other rasters (e.g. a hillshading raster) or images (e.g. satellite images) that are draped over the DEM.\r\rDetermination of change in elevation through time - the cut-and-fill volume of soil to be removed or to be brought in to make a site ready for construction can be computed by overlaying the DEM of the site before the work begins with the DEM of the expected modified topography. It is also possible to determine landslide effects by comparing DEMs of before and after a landslide event.\r\rAutomatic catchment delineation - catchment boundaries or drainage lines can be automatically generated from a good quality DEM with the use of neighbourhood functions. The system will determine the lowest point in the DEM - which is considered to be the outlet of the catchment. From there - it will repeatedly search for the neighbouring pixels with the highest altitude. This process is repeated until the highest location (i.e. the cell with the highest value) is found; the path followed determines the catchment boundary. For delineating the drainage network - the process is reversed. Then the system will work from the watershed downwards - each time looking for the lowest neighbouring cells - which determines the direction of water flow (Flow Computation).\r\rDynamic modelling - apart from the applications mentioned above - DEMs are increasingly used in GIS-based dynamic modelling - such as the computation of surface run-off and erosion - groundwater flow - the delineation of areas affected by pollution - the computation of areas that will be covered by processes such as flows of debris and lava. An example is (Diffusion).\r\rVisibility analysis - a viewshed is the area that can be “seen” (i.e. it is in the direct line-of-sight) from a specified target location. Visibility analysis can determine the area visible from a scenic lookout or the area that can be reached by a radar antenna - as well as assess how effectively a road or quarry will be hidden from view.,NONE62,AM7-1,Graphical methods,Statistical analysis techniques based on visual interpretation through histograms - scatterplots - etc.,NONE63,AM7-2,Stochastic processes,Environmental variables have become increasing available with the advent of GIS. These are mostly continuous in space and time. Collecting denser environmental data in discrete space and time domains are rather cost effective and time consuming.  However - when the data at each spatial or time index are considered  as outcomes of a random variable - stochastic processes become enviable useful to build models and predict the outcomes at locations where data were never collected.  The meaningful assumptions include stationarity of the mean and the covariance to ascertain an expression for spatial dependency/autocorrelation. With a stationary process (i.e. constant mean) - simple and ordinary kriging is used. Other variants like kriging with external drift - universal kriging and regression kriging also alleviate the challenge of non-stationary mean. These methods are also applicable when temporal indexes rather than spatial indexes are of interest.,NONE64,AM7-3,The spatial weights matrix,Spatial weight matrix is the popular numerical quantification of spatial dependency or spatial neighborhoods. The weight matrix should summarize information about the spatial connectivity structure of the spatial entities/features; either polygons - points - or lines. This is required for the computation of spatial dependency indices such the Moran’s index - and for spatial regression models such as the conditional autoregressive (CAR) - spatial lag - and spatial error models. The connectivity information can be defined based on adjacency/contiguity or distance between pairs of spatial entities. There are other forms; they could be based on population densities between observation pairs. The simplest spatial weigh matrix is the binary adjacency spatial weight matrix with elements w_ij - such that w_ij=1 if spatial units i and j are neighbors - otherwise w_ij=0. A popular alternative is the inverse distance weight matrix with elements  w_ij=1⁄d^α  - where d is the distance between pairs of spatial units and α is any positive number greater than zero. By convention - w_ii=0 since spatial unit cannot have a spillover within itself.,NONE65,AM7-4,Global measures of spatial association,Spatial autocorrelation evaluates how things which are closer in space tend to have similar attributes. This is a common phenomenon in environmental variables which are continuous in space. For instance - temperature - soil moisture content - air quality and rainfall are all continuous in space. This idea is based on Tobler’s law of geography: “everything is related to everything but near things are more related”. Global measures of spatial association estimates the overall index of spatial autocorrelation - also called spatial clustering. Thus - it measures whether clustering is apparent throughout the study region but do not identify the location of clusters. Common global measures include the Moran’s Index and Geary’s C.  These have increasing applications in domains like environmental science - agriculture - epidemiology - climate studies etc.,NONE66,AM7-5,Local measures of spatial association,Unlike global measures of spatial association -  local measure of spatial association identifies the locations of clusters. Typical measures include the local indicator for spatial autocorrelation (LISA) or the local Moran’s index whose summation is proportional to the global Moran’s index. The spatial scan statistics has also been the commonly used method to detect local clusters.,NONE67,AM7-6,Outliers,An outlier is an unexpected value that differs significantly from other observations. Definition of an outlier is not absolute and the concept itself is precisely defined only by selection of appropriate criteria in concrete statistical observations. When considering outliers - it is important to determine whether the value of the outlier is incorrect data or it is otherwise outstanding - but correct data. If we consider outliers in the case when they base on sample surveys - another assessment is necessary. Namely - the assessment of whether an outlier is representative or not. \rThe box plot is a useful graphical display for examining the outliers. Using median - lower and upper quartiles - extreme values are identified in the tails of the distribution. The value beyond inner fence on either side is considered a mild outlier. The value beyond an outer fence is considered an extreme outlier. Histograms also emphasize the existence of outliers. The histogram depends on how we design the classes - so we can get different histograms for the same data. Graphical and quantitative checks are obligatory if the histogram shows possible outliers. Outliers can also be examined by calculating the correlation between two datasets (Pearson correlation coefficient - Spearman rank correlation coefficient…). Scatter plots reveals a basic linear relationship with a pattern. An outliner is defined as a data point that deviates from other values. Outliers can also be examined by local outlier factor - which is based on a concept of a local density. Points with substantially lower density than their neighbours are considered as outliers.,NONE68,AM7-7,Bayesian methods,Bayesian method of modelling stems from the Bayes theorem and derived using conditional probabilities. Its advantage lies in its ability to include prior knowledge of unknown parameters to ascertain their uncertainties. Thus - the prior parameters are updated by the data likelihood to obtain the posteriors. The challenge of Bayesian modelling has been the integration of the denominator which always resulted into improper integrals. This actually prolonged its wide applications. With the advent of high performance computers - solution to such integrals are easily solved using Markov chain Monte Carlo simulations. The advent robust approximation methods through integrated nested Laplace approximations (INLA) has even made parameter estimation faster; thus making Bayesian methods interesting and better. Unlike frequentist approaches - Bayesian methods can present estimates of parameters as densities from which their uncertainties and credible intervals can be estimated. They have now found wide applications in divers areas like environmental modelling - climate modeling - agriculture - epidemiology and many other domains that requires modeling.,NONE69,AM7,Spatial statistics,Traditional statistical methods are used to describe the central tendency - dispersion - and other characteristics of data but are not always suited to use with spatial data for which specialized techniques are often required. The field of spatial statistical analysis forms the backbone for the testing of hypotheses about the nature of spatial pattern - dependency - and heterogeneity. The techniques are widely used in both exploratory and confirmatory spatial analysis in many different fields.,NONE70,AM8-1,Spatial sampling for statistical analysis,Sampling is needed to limit the observations for statistical analysis. In raster image analysis - various sampling schemes have been proposed for selecting pixels to test. Choices to be made relate to the design of the sampling strategy - the number of samples required - and the area of the samples. Recommended sampling strategies in the context of land cover data are simple random sampling or stratified random sampling. The number of samples may be related to two factors in accuracy assessment: (1) the number of samples that must be taken in order to reject a data set as being inaccurate; or (2) the number of samples required to determine the true accuracy - within some error bounds - of a data set. Sampling theory is used to determine the number of samples required. The number of samples must be traded-off against the area covered by a sample unit. A sample unit can be a point but it could also be an area of some size; it can be a single raster element but may also include surrounding raster elements. Among other considerations - the “optimal” sample-area size depends on the heterogeneity of the class.,NONE71,AM8-3,Variogram modeling,A variogram is a tool used to describe the spatial continuity of data points. Different kinds of variograms are used - such as experimental variogram and semi-variogram.,NONE72,AM8-4,Principles of kriging,Predicting an observation in the presence of spatially dependent observations is termed Kriging - named after the first practitioner of these procedures - the South African mining engineer Daan Krige - who did much of his early empirical work in the Witwatersrand gold mines.,NONE73,AM8-5,Kriging variants,With a stationary stochastic process (i.e. constant mean) - simple and ordinary kriging is used for interpolation. Other variants like kriging with external drift - universal kriging and regression kriging also alleviate the challenge of non-stationary mean. Other variants are \rco-kriging log-normal kriging - disjunctive kriging - indicator kriging - factorial kriging and universal kriging.,NONE74,AM8,Geostatistics,Geostatistics are a variety of techniques used to analyze continuous data e.g. - rainfall - elevation - air pollution. The fundamental structure of geostatistics is based on the concept of semi-variograms and their use for spatial prediction kriging. Sampling methods are also discussed in Unit GD9 Field data collection. \rGeostatistics is a subdiscipline of spatial statistics developed to estimate the value of a continuous spatial process at unknown locations by using the information of the value of these process at known locations. Furthermore - it aims to quantify the uncertainty related to the prediction (Calder et al. - 2009; Emmanouil - 2019). In order to do such predictions - geostatistics entails some statistical methods which use as starting point the assumption of a random component that can define the spatiotemporal variability. These methods are developed to infer the parameters that can describe the spatiotemporal patterns of the input variables (e.g. soil moisture) so that finally these variables at unsampled locations can be estimated (interpolated) (Emmanouil - 2019). Geostatistical methods are strongly related with classic interpolation methods but differ by its use of random variables that allow to given an uncertainty indication associated with the prediction of variables in space and time. \r\rIn environmental research geostatistical techniques are often applied to infer (interpolate) variables at such unobserved locations by using information from known locations. One of such geostatistical techniques is Kriging - which is a geostatistical method that predicts variables by using spatial interpolation. This spatial interpolation is done by establishing a semivariogram that defines the spatial relationship between the variables of interest in function of the distance. Because of this - the Kriging technique can also give an indication on the variance or accuracy of the prediction (Calder et al. - 2009); Van der Meer - 2012). On the other hand - cokriging is another important geostatistical technique and differs from Kriging by using the cross-correlation between variables to generate local estimates (Van der Meer - 2012). In earth observation studies - cokriging can be applied to better predict sparsely based data on the ground (e.g. biomass) by using the cross-correlation of this variable with a more continuously sampled satellite metric like NDVI. Furthermore - these techniques can also be used to enhance satellite image information - filling missing pixels or even downscale the information to a higher resolution (Van der Meer - 2012).,NONE75,AM9-1,Principles of spatial econometrics,Spatial econometrics uses spatial stochastic models to determine autocorrelation between interacting agents. The techniques involved are regression - the use of a spatial weights matrix - least squares - etc.,NONE76,AM9-2,Spatial autoregressive models,A spatial autoregressive (SAR) model describes the prediction of the behaviour of a random process.,NONE77,AM9-3,Spatial filtering,In producing optimal images for interpretation - spatial filtering is applied. Filtering is usually carried out for a single band. Filters - algorithms - can be used to enhance images by - for example - reducing noise (“smoothing an image”) or sharpening a blurred image. Filter operations are also used to extract features from images - e.g. edges and lines - and to automatically recognize patterns and detect objects. There are two broad categories of filters: linear and non-linear filters.\r\rLinear filters calculate the new value of a pixel as a linear combination of the given values of the pixel and those of neighbouring pixels. A simple example of the use of a linear smoothing filter is when the average of the pixel values in a 3×3 pixel neighbourhood is computed and that average is used as the new value of the central pixel in the neighbourhood.,NONE78,AM9-4,Spatial expansion and Geographically Weighted Regression GWR,Geographically Weighted Regression (GWR) makes use of local subsets of observations to perform estimates.,NONE79,AM9,Spatial regression and econometrics,Many problems of the social sciences can be expressed in terms of spatial regression analysis. The development of spatial autoregressive models and the estimation of their parameters is the focus for the field of spatial econometrics.,NONE80,CF,Conceptual Foundations,The GIScience perspective is grounded in spatial thinking. The aim of this knowledge area is to recognize - identify - and appreciate the explicit spatial - spatio-temporal and semantic components of the geographic environment at an ontological and epistemological level in preparation for modeling the environment with geographic data and analysis. To do this - one must understand the nature of space and time as a context for geographic phenomena.This knowledge area covers the ways in which views of the geographic environment depend on philosophical viewpoints - physics - human cognition - society - and the task at hand. This knowledge area also requires an understanding of the fundamental principles in the discipline of geography - the 'language' of spatial tasks. On a more advanced level - this area incorporates mathematical and graphical models that formalize these concepts - such as set theory - algebra - and semantic nets. Because of its wide range of foundational principles - this knowledge area forms a basis for the other knowledge areas. Wise design and use of geospatial technologies requires an understanding of the nature of geographic information - the social and philosophical context of geographic information - and the principles of geography. This knowledge area is especially closely tied to Knowledge Areas Data Modeling (DM) and Design Aspects (DA) - as generic data models and application designs need to be grounded in sound conceptual models. The foundations of geographic information have developed over several decades. Philosophical and scientific views on the nature of space and time have evolved since the ancient Greeks. Early papers during the Quantitative Revolution - such as Berry (1964) - began to formalize the structure of information used in geographic inquiry.The fundamental data structures and algorithms comprising the GIS software developed in the 1960`s and 1970`s were based on implicit 'common-sense' conceptual models of geographic information. During the 1980`s - several researchers questioned these underlying assumptions. Some were refuted - other confirmed - and many extended. However - the most rapid pace of development in this area was during the 1990`s with the rise of GIScience as a distinct discipline - and the many cooperative initiatives it comprised.The new millennium has seen some of these foundational principles incorporated into commercial software - thus making theoretical knowledge even more important for practitioners. It is expected that the concepts in this knowledge area will be learned gradually. An introductory course may cover only a few topics in a cursory manner - an intermediate course on data modeling or data analysis may consider several theoretical topics of practical application - and a number of graduate courses could cover each topic in a research-oriented environment. Discussion of this knowledge area includes several terms that can have multiple meanings. For the purposes of this document - two in particular require definition: Geographic: Almost any subject or discourse involving earthly phenomena - studied from a spatial perspective at a medium scale (sub-astronomical and super-architectural). Phenomenon: Any subject of geographic discourse that is perceived to be external to the individual - including entities - events - processes - social constructs - and the like.,NONE81,CF1-1,Metaphysics and ontology,Metaphysics involve the meaning things and concepts. Ontologies provide a way to share the semantics of concepts in some area of interest and is all about common the understanding of essential concepts - e.g. - what is meant by a geometric object and its attributes.,NONE82,CF1-1b,What is Geographic Information Science and Technology,Brief history of GIScience as related to the history of GISystems; Definitions of GIS&T; Sub-domains of GIS&T (i.e. - Geographic Information Science - Geospatial Technology - and Applications of GIS&T),NONE83,CF1-2,Epistemology,The branch of philosophy concerned with knowledge.,NONE84,CF1-2b,Contributions to GIS and T by key allied fields,GIS&T draws upon insights and methods from key allied fields: Geography - Cartography - Computer and information science - Engineering - Mathematics and Statistics - Philosophy - Cognitive Science - Linguistics,NONE85,CF1-3,Philosophical perspectives,The questions and methodologies in major philosophical movements relating to the nature of space - time - geographic phenomena and human interaction with it.,NONE86,CF1,Philosophical foundations,Many branches of philosophy are relevant to an understanding of geographic information - especially metaphysics and epistemology. Philosophical theories are deeply engaged in the study of knowledge - space - time - geographic phenomena and human interaction with them. These theories influence the development of geographic ontologies and the structuring - analysis - and interpretation of geographic information. It is - therefore - crucial for professionals to understand these principles in order to bridge (rather than eliminate) the differences and work together. Philosophical perspectives on GIS practice are covered in Unit GS7 Critical GIS.,NONE87,CF1b,Introduction to Geographic Information Science and Technology,Unit CF1 introduces the broad domain refered to as Geographic Information Science & Technology (GIS&T) and its sub-domains (i.e. - Geographic Information Science - Geospatial Technology - and Applications of GIS&T). It outlines the history of Geographic Information Science as related to the history of GISystems - as well as the contributions to this multidisciplinary domain by key allied fields - such as geography - cartography - computer and information science - engineering - mathematics - philosophy - cognitive science - and linguistics.,NONE88,CF2-1,Perception and cognition of geographic phenomena,The study on how humans perceive spatial information.,NONE89,CF2-1b,Philosophy of being,Metaphysics and Ontology - Formal ontology - Ontological distinctions (e.g. - continuants vs. occurrents - universals vs. particulars) - The problem of universals and relevant theories (realism - nominalism - conceptualism) - Ontologies of the geographic domain - Philosophical theories relating to the nature of space - time - geographic phenomena and human interaction with them,NONE90,CF2-2,From concepts to data,The ways in which conceptual views of in the human mind make it into formal descriptions of information and into artefacts in databases and GIS.,NONE91,CF2-2b,Philosophy of knowledge,Epistemology; Theories on what constitutes knowledge; The notions of model and representation in science; The influences of epistemology on GIS practices,NONE92,CF2-3,Geography as a foundation for GIS,Principles of geography to explain the spatial occurrences of spatial entities in Geographic Information Systems.,NONE93,CF2-4,Place and landscape,Space and place are concepts that are not the same. Including concepts like landscape - it is not always obvious how to portray them unambiguously in GIS.,NONE94,CF2-6,Cultural influences,The ways in which the elements of culture (e.g. - language - religion - education - traditions) may influence the understanding and use of geographic information.,NONE95,CF2-7,Political influences,The influences of political ideologies (e.g. - Marxism - Capitalism - conservative liberal) on the understanding of geographic information.,NONE96,CF2,Cognitive and social foundations,Geographic information is observed - comprehended - organized - used in human processes - with both personal and social influences. Therefore - sound models of geographic information should be grounded on a sound understanding of human perception - cognition - memory - and behavior - as well as human institutions.,NONE97,CF3-1,Space,A GIS operates under the assumption that the spatial phenomena involved occur in a two- or three-dimensional Euclidean space. Euclidean space can be informally defined as a model of space in which locations are represented by coordinates—(x - y) in 2D and (x - y - z) in 3D space—and distance and direction can defined with geometric formulas. In 2D - this is known as the Euclidean plane. To represent relevant aspects of real-world phenomena inside a GIS - we first need to define what it is we are referring to. We might define a geographic phenomenon as a manifestation of an entity or process of interest that:\r\ritem can be named or described;\ritem can be georeferenced; and\ritem can be assigned a time (interval) at which it is/was present.\r\rRelevance of phenomena for the use of a GIS depends entirely on the objectives of the study at hand. For instance - in water management - relevant objects can be river basins - agro-ecological units - measurements of actual evapotranspiration - meteorological data - ground\-water levels - irrigation levels - water budgets and measurements of total water use. All of these can be named or described - georeferenced and provided with a time interval at which each exists. In multipurpose cadastral administration - the objects of study are different: houses - land parcels - streets of various types - land use forms - sewage canals and other forms of urban infrastructure may all play a role. Again - these can be named or described - georeferenced and assigned a time interval of existence.\r\rNot all relevant information about phenomena has the form of a triplet (description - georeference - time interval). If the georeference is missing - then the object is not positioned in space: an example of this would be a legal document in a cadastral system. It is obviously somewhere - but its position in space is not considered relevant. If the time interval is missing - we might have a phenomenon of interest that exists permanently - i.e.\ the time interval is infinite. If the description is missing - then we have something that exists in space and time - yet cannot be described. Obviously this last issue limits the usefulness of the information.\r\rTypes of geographic phenomena\rThe definition of geographic phenomena attempted above is necessarily abstract and is - therefore - perhaps somewhat difficult to grasp. The main reason is that geographic phenomena come in different “flavours”. Before categorizing such flavours - there are two further observations to be made.\r\rFirst - to represent a phenomenon in a GIS requires us to state what it is and where it is. We must provide a description—or at least a name—on the one hand - and a georeference on the other hand. We will ignore temporal issues for the moment and come back to these in Temporal dimension and Spatial-temporal data model - the reason being that current GISs do not provide much automatic support for time-dependent data. This topic must - therefore - be considered as an example of advanced GIS use. Second - some phenomena are manifest throughout a study area - while others only occur in specific localities. The first type of phenomena we call geographic fields; the second type we call objects.,NONE98,CF3-1b,Cognitive foundations,- Theories of human perception - cognition - and memory and their ability to model spatial knowledge acquisition (e.g. - Marr on vision - Piaget on cognitive development) - Types of mental representations (i.e. - analogue - propositional - procedural) - The role of metaphors and image schemata in our understanding of geographic phenomena and geographic tasks - From concepts to data (i.e. - data - information - knowledge - and wisdom; transformation of a conceptual model of information for a particular task into a data model; limitations of various information stores (the mind - computers) and means (maps - graphics - and text) for representing geographic information) - Difference between real phenomena - conceptual models - and GIS data representations thereof connections with cartography and maps,NONE99,CF3-2b,Linguistic foundations,- Semantics - Meaning (e.g. - the nature of meaning - modes of meaning) - Geospatial semantics - The role of natural language in the conceptualization of geographic phenomena,NONE100,CF3-3b,Social foundations,- The ways in which the elements of culture (e.g. - language - religion - education - traditions) may influence the understanding and use of geographic information - The influences of social theories and political ideologies and actions on human perceptions of space and place - The constraints that political forces place on geospatial applications in public and private sectors,NONE101,CF3-4b,Common-sense geographies,- Common-sense views and laymen knowledge of geographic phenomena that contrast with established theories and technologies of geographic information - The impact of geospatial technologies and the geoweb (e.g. - digital globes) that allow non-geospatial professionals to create - distribute - and map geographic information - The design - procedures - and results of GIS projects to non-GIS audiences (clients - managers - general public) - Difference between applications that can make use of common-sense principles of geography and those that should not,NONE102,CF3,Cognitive - linguistic and social foundations,Geographic information is observed - comprehended - organized - used in human processes - with both personal and social influences. Therefore - sound models of geographic information should be grounded on a sound understanding of human perception - cognition - memory - and behavior - as well as human institutions.,NONE103,CF4-2b,Time,As time is the central concept of the temporal dimension - a brief examination of the nature of time may clarify our thinking when we work with this dimension:\r\rDiscrete and continuous time: Time can be measured along a discrete or continuous scale. Discrete time is composed of discrete elements (seconds - minutes - hours - days - months - or years). For continuous time - no such discrete elements exist: for any two moments in time there is always another moment in between. We can also structure time by events (moments) or periods (intervals). When we represent intervals by a start and an end event - we can derive temporal relationships between events and periods - such as “before” - “overlap” - and “after”.\r\rValid time and transaction time: Valid time (or world time) is the time when an event really happened - or a string of events took place. Transaction time (or database time) is the time when the event was stored in the database or GIS. Note that the time at which we store something in a database is typically (much) later than when the related event took place.\r\rLinear - branching and cyclic time: Time can be considered to be linear - extending from the past to the present (‘now’) - and into the future. This view gives a single time line. For some types of temporal analysis - branching time - in which different time lines from a certain point in time onwards are possible - and cyclic time - in which repeating cycles such as seasons or days of the week are recognized - make more sense and can be useful.\r\rTime granularity: When measuring time - we speak of granularity as the precision of a time value in a GIS or database (e.g. year - month - day - second). Different applications may obviously require different granularity. In cadastral applications - time granularity might well be a day - as the law requires deeds to be date-marked; in geological mapping applications - time granularity is more likely to be in the order of thousands or millions of years.\r\rAbsolute and relative time: Time can be represented as absolute or relative. Absolute time marks a point on the time line where events happen (e.g. “6 July 1999 at 11:15 p.m.”). Relative time is indicated relative to other points in time (e.g. “yesterday” - “last year” - “tomorrow” - which are all relative to “now” - or “two weeks later” - which is relative to some other arbitrary point in time.).,NONE104,CF4-3b,Relationships between space and time,The way we represent relevant components of the real world in our models determines the kinds of questions we can or cannot answer. Besides representing an object or field in 2D or 3D space - the temporal dimension is of a continuous nature. Therefore - in order to represent it in a GIS we have to discretize the time dimension.\r\rSpatio-temporal data models are ways of organizing representations of space and time in a GIS. Several representation techniques have been proposed in the literature. Perhaps the most common of these is the “snapshot state” - which represents a single moment in time of an ongoing natural or man-made process. We may store a series of these “snapshot states” to represent “change” - but we must be aware that this is by no means a comprehensive representation of that process. \r\rIn spatio-temporal analysis we consider changes of spatial and thematic attributes over time. We can keep the spatial domain fixed and look only at the attribute changes over time for a given location in space. We might be interested how land cover has changed for a given location or how land use has changed for a given land parcel over time - provided its boundary has not changed. On the other hand - we can keep the attribute domain fixed and consider the spatial changes over time for a given thematic attribute. In this case - we might want to identify locations that were covered by forest over a given period of time.\r\rFinally - we can assume both the spatial and attribute domains are variable and consider how fields or objects have changed over time. This may lead to notions of object motion - a subject receiving increasing attention in the literature. Applications of moving object research include traffic control - mobile telephony - wildlife tracking - vector-borne disease control and weather forecasting. In these types of applications - the problem of object identity becomes apparent. When does a change or movement cause an object to disappear and become something new? With wildlife this is quite obvious; with weather systems less so. But this should no longer be a surprise: we have already seen that some geographic phenomena can be nicely described as objects - while others are better represented as fields.\r\rMapping time means mapping change. This may be change in a feature’s geometry - in its attributes - or both. Examples of changing geometry are the evolving coastline of the Netherlands - the location of Europe’s national boundaries - or the position of weather fronts. Changes in the ownership of a land parcel - in land use or in road traffic intensity are other examples of changing attributes. Urban growth is a combination of both: urban boundaries expand with growth and simultaneously land use shifts from rural to urban. If maps are to represent events like these - they should be suggestive of such change.\r\rThree temporal cartographic techniques can be distinguished:\r\rSingle Static Map\r\rSpecific graphic variables and symbols are used to indicate change or represent an event. We can apply the visual variable “value” to represent for example the age of built-up areas.\r\rSeries of Static Maps\r\rA single map in the series represents a “snapshot” in time. Together - the maps depict a process of change. Change is perceived by the succession of individual maps depicting the situation in successive snapshots. It could be said that the temporal sequence is represented by a spatial sequence that the user has to follow to perceive the temporal variation. The number of images should be limited since it is difficult for the human eye to follow long series of maps.\r\rAnimated Maps\r\rChange is perceived to evolve in a single image by displaying several snapshots one after the other - just like a video clip of successive frames. The difference from the series of maps is that the variation can be deduced from real “change” seen taking place in the image itself - not from a spatial sequence. For the user of a cartographic animation - it is important to have tools available that allow for interaction while viewing the animation. Seeing an animation play will often leave users with many questions about what they have seen. And just replaying the animation is not sufficient to answer questions like “What was the position of the northern coastline during the 15th century?” Most of the general software packages for viewing animations already offer facilities such as “pause” (to look at a particular frame) and ‘(fast-)forward’ and ‘(fast-)backward’ - or step-by-step display. More options have to be added - such as the possibility to go directly to a certain frame based on a task command like: “Go to 1850”.,NONE105,CF4-4b,Categories,GIS data structures are used to implement the conceptual views of spatial data (vector and raster models). The power of a GIS is dependent on the richness of information contained in the spatial data structures. Vector models are based on points - lines and areas. Raster models are based on grids. Each cell has a value that is used to represent some characteristic of that location. \rLayers are used to display geographic datasets in various digital map environment. A layer stores the path to a source dataset and other layer properties - including symbology. You can use multiple layers on one map and specify its properties. Shapefiles represent spatial character of the object in terms of shape - size and spatial arrangement. Shapefile usually comprise three separate and distinct types of files (main files - index files and database tables). Data base files store additional attributed that can be joined to a shapefiles’ feature. Attribute data types supplement geographic spatial feature with additional information. Spatial data includes information of location and attribute data includes information about other characteristics (what - where and why). A legend is a visual presentation of the symbols that are used on the map with some additional explanations. It includes a sample of each symbol and a short description of the meaning.,NONE106,CF4-5,Properties,An entity obtained by abstracting the real world - having a physical nature (certain composition of material) - being given a descriptive name - and observable; e.g. “house”. An object is a self-contained part of a scene having certain discriminating properties.\r\rThe primitives of vector data sets are the point - (poly)line and polygon. Related geometric measurements are location - length - distance and area size. Some of these are geometric properties of a feature in isolation (location - length - area size); others (distance) require two features to be identified.\r\rIn a GIS - features are represented together with their attributes—geometric and non-geometric—and relationships. The geometry of features is represented with primitives of the respective dimension: a windmill probably as a point; an agricultural field as a polygon. The primitives follow either the vector or the raster approach.\r\rVector data types describe an object through its boundary - thus dividing the space into parts that are occupied by the respective objects. The raster approach subdivides space into (regular) cells - mostly as a square tessellation of two or three dimensions. These cells are called pixels in 2D and voxels in 3D. The data indicate for every cell which real-world feature is covered - provided the cell represents a discrete field. In the case of a continuous field - the cell holds a representative value for that field. The Table below lists advantages and disadvantages of raster and vector representations.\r\rThe storage of a raster is - in principle - straightforward. It is stored in a file as a long list of values - one for each cell - preceded by a small list of extra data (the “file header”) - which specifies how to interpret the long list. The order of the cell values in the list can - but need not necessarily - be left to right - top to bottom. This simple encoding scheme is known as row ordering. The header of the raster will typically specify how many rows and columns the raster has - which encoding scheme was used - and what sort of values are stored for each cell.\r\rData can be of a qualitative or quantitative nature. Qualitative data is also called nominal data - which exists as discrete - named values without a natural order amongst the values. Examples are different languages (e.g. English - Swahili - Dutch) - different soil types (e.g. sand - clay - peat) or different land use categories (e.g. arable land - pasture). In the map - qualitative data are classified according to disciplinary insights - such as a soil classification system represented as basic geographic units: homogeneous areas associated with a single soil type - recognizable by the soil classification.\r\rQuantitative data can be measured - either along an interval or ratio scale. For data measured on an interval scale - the exact distance between values is known - but there is no absolute zero on the scale. Temperature is an example: 40 ◦C is not twice as hot as 20 ◦C - and 0 ◦C is not an absolute zero.\r\rQuantitative data with a ratio scale do have a known absolute zero. An example is income: someone earning $100 earns twice as much as someone with an income of $50. In order to generate maps - quantitative data are often classified into categories according to some mathematical method.\r\rIn between qualitative and quantitative data - one can distinguish ordinal data. These data are measured along a relative scale and are as such based on hierarchy. For instance - one knows that a particular value is “more” than another value - such as “warm” versus “cool”. Another example is a hierarchy of road types: “highway” - “main road” - “secondary road” and “track”. The different types of data are summarized in Table.,NONE107,CF4b,Fundamentals of Geographic Information,Geographic phenomena - geographic information - and geographic tasks are described in terms of space - time - and properties. Different theories exist as to the nature and formal representation of these aspects - including space-like dimensions - sets - and phenomenology. Information in each of these three aspects is measured and reported with respect to one of several frames of reference or domains - including both absolute and relative approaches. Early frameworks such as those of Berry (1964) and Sinton (1978) were influential in setting forth the importance of space - time - and theme in GIS&T. Besides - space - time - and properties - categories are also fundamental in the conceptualization and representation of spatial entities - phenomena - processes - and events. Distinctive features of geographic information such as scale and detail - spatial patterns - spatial integration - and regions are also critical for a complete description of its nature and representation. This unit is closely tied to the creation of data models in Knowledge Area 5: Data Modeling - Storage - and Exploitation.,NONE108,CF5-1b,Discrete entities,Discrete entities can be found as fields or objects.\r\rDiscrete fields divide the study space in mutually exclusive - bounded parts - with all locations in one part having the same field value. Discrete fields are intermediate between continuous fields and geographic objects: discrete fields and objects both use “bounded” features.\r\rDiscrete fields divide the study space in mutually exclusive - bounded parts - with all locations in one part having the same field value. Typical examples are land classifications - for instance - using either geological classes - soil type - land use type - crop type or natural vegetation type. \r\rDiscrete fields are intermediate between continuous fields and geographic objects: discrete fields and objects both use “bounded” features. A discrete field - however - assigns a value to every location in the study area - which is not typically the case for geographic objects. These two types of fields differ in the type of cell values. A discrete field such as land use type will store cell values of the type “integer” and is therefore also called an integer raster. Discrete fields can be easily converted to polygons since it is relatively easy to draw a boundary line around a group of cells with the same value. A continuous raster is also called a “floating point” raster.\r\rGeographic objects.\r\rWhen a geographic phenomenon is not present everywhere in the study area - but somehow “sparsely” populates it - we look at it as a collection of geographic objects. Such objects are usually easily distinguished and named - and their position in space is determined by a combination of one or more of the following parameters:\r\rlocation (where is it?)\rshape (what form does it have?)\rsize (how big is it?)\rorientation (in which direction is it facing?).\r\rHow we want to use the information determines which of these four parameters is required to represent the object. For instance - for geographic objects such as petrol stations all that matters in an in-car navigation system is where they are. Thus - in this particular context - location alone is enough - and shape - size and orientation are irrelevant. For roads - however - some notion of location (where does the road begin and end?) - shape (how many lanes does it have?) - size (how far can one travel on it?) and orientation (in which direction can one travel on it?) seem to be relevant components of information in the same system.,NONE109,CF5-2b,Fields,A geographic field is a geographic phenomenon that has a value “everywhere” in the study area. We can therefore think of a field as a mathematical function f that associates a specific value with any position in the study area. Hence if (x - y) is a position in the study area - then f(x - y) expresses the value of f at location (x - y). Fields can be discrete or continuous.\r\rIn a continuous field - the underlying function is assumed to be “mathematically smooth” - meaning that the field values along any path through the study area do not change abruptly - but only gradually. Good examples of continuous fields are air temperature - barometric pressure - soil salinity and elevation. A continuous field can even be differentiable - meaning that we can determine a measure of change in the field value per unit of distance anywhere and in any direction. For example - if the field is elevation - this measure would be slope - i.e. the change of elevation per metre distance; if the field is soil salinity - it would be salinity gradient - i.e. the change of salinity per metre distance.\r\rDiscrete fields divide the study space in mutually exclusive - bounded parts - with all locations in one part having the same field value. Discrete fields are intermediate between continuous fields and geographic objects: discrete fields and objects both use “bounded” features.\r\rDiscrete fields divide the study space in mutually exclusive - bounded parts - with all locations in one part having the same field value. Discrete fields are intermediate between continuous fields and geographic objects: discrete fields and objects both use “bounded” features.\r\rDiscrete fields divide the study space in mutually exclusive - bounded parts - with all locations in one part having the same field value. Typical examples are land classifications - for instance - using either geological classes - soil type - land use type - crop type or natural vegetation type. \r\rDiscrete fields are intermediate between continuous fields and geographic objects: discrete fields and objects both use “bounded” features. A discrete field - however - assigns a value to every location in the study area - which is not typically the case for geographic objects. These two types of fields differ in the type of cell values. A discrete field such as land use type will store cell values of the type “integer” and is therefore also called an integer raster. Discrete fields can be easily converted to polygons since it is relatively easy to draw a boundary line around a group of cells with the same value. A continuous raster is also called a “floating point” raster.\r\rA field-based model consists of a finite collection of geographic fields: we may be interested in - for example - elevation - barometric pressure - mean annual rainfall and maximum daily evapotranspiration - and would therefore use four different fields to model the relevant phenomena within our study area.,NONE110,CF5-3b,Events and processes,We can structure time by events (moments) or periods (intervals). When we represent intervals by a start and an end event - we can derive temporal relationships between events and periods - such as “before” - “overlap” - and “after”.\rValid time (or world time) is the time when an event really happened - or a string of events took place. Transaction time (or database time) is the time when the event was stored in the database or GIS. Note that the time at which we store something in a database is typically (much) later than when the related event took place.\r\rProcess models in the Earth sciences describe the evolution of geo(bio)physical surface properties in time - independently from remote sensing observations. Examples of such process models on various time scales are - for instance - numerical weather prediction models (NWPs) - vegetation growth models - hydrological models - oceanographic models and climate models.\r\rProcesses on the planet Earth are complex phenomena that are taking place in space and in time - i.e. in four dimensions.\r\rIn many of these processes - differences in one dimension (e.g. height above the geoid) can be disregarded - so that two spatial dimensions and the dimension time remain. Despite this simpliﬁcation - the physical description of the phenomena remains a difﬁcult task. To better understand the processes it often helps if the same geographic region is viewed repeatedly and - if possible - also from different directions and in different wavelength regions. Integration of data from a variety of sources can be a means to retrieving information about processes that would otherwise remain undetected.,REMOTE SENSING111,CF5-4b,Integrated models,Models that integrate the concepts of space - time - and attribute in geographic information.,NONE112,CF5-6,Spatial distribution,Geographic phenomena can be studied as single entities and in relationship with each other and then reveal patters and clusters. How the entities are distributed is subject to statistical and visualisation studies.,NONE113,CF5-7,Region,We can use the topological properties of interiors and boundaries to define relationships between spatial features. Since the properties of interiors and boundaries do not change under topological mapping - we can investigate their possible relations between spatial features. We can define the interior of a region - R - as the largest set of points of R for which we can construct a disc-like environment around it (no matter how small) that also falls completely inside R. The boundary of R is the set of those points belonging to R that do not belong to the interior of R - i.e. one cannot construct a disc-like environment around such points that still belongs to R completely.\r\rLet us consider a spatial region A. It has a boundary and an interior - both seen as (infinite) sets of points - which are denoted by boundary(A) and interior(A) - respectively. We consider all possible combinations of intersections (∩) between the boundary and the interior of A with those of another region - B - and test whether they are the empty set (∅) or not. From these intersection patterns - we can derive eight (mutually exclusive) spatial relationships between two regions. If - for instance - the interiors of A and B do not intersect - but their boundaries do - yet the boundary of one does not intersect the interior of the other - we say that A and B meet.,NONE114,CF5-8,Spatial integration,Integration of data from a variety of sources can be a means to retrieving information about processes that would otherwise remain undetected.\r\rAlthough data integration can be very useful - there are also some requirements that have to be fulfilled for it to be effective:\r\r• geospatial data have to be accurately co-registered in a common grid;\r• time gaps between the various data layers have to be known and accounted for;\r• systematic effects due to the atmosphere - the viewing angle - the Sun angle - etc. - must be corrected for or taken into account.\r\rData can be integrated in an almost infinite number of ways. Results from data integration can - again - be combined with other geospatial data to produce yet other new information - and so on.\r\rData integration also comprises the incorporation of non-spatial information or point data from field measurements. These data have to be associated with precise moments in time and with precise geographic locations - or with some time interval and fuzzy-defined regions. Thus - here the important issue of the representativeness of this information for the associated time interval and geographic area comes into play.\r\rIn general - data integration forces us to consider the uncertainties or inaccuracies of the various data sources available. In some cases - meta-data may contain information about this. When integrating data for some purpose - one has to apply weights to each of them - so that the final result is a balanced compromise in which inaccurate data receive less weight than those with a high degree of certainty.,NONE115,CF5b,Elements of geographic information,The concepts below form the basic elements of common human conceptions of geographic phenomena. Concepts from many units in this knowledge area have been synthesized to create general conceptual models of geographic information. Attempts to resolve the object-field debate have led to attempts to create comprehensive models that bridge these views. Consideration of this unit should also include formal models of these elements in mathematics and other fields. Knowledge Area DM Data Modeling discusses the representation of these elements in digital models.,NONE116,CF6-1,Mereology: structural relationships,Mereology is the study of parts and wholes. In GI this involves how objects are modeled as composites of other objects.,NONE117,CF6-2,Genealogical relationships: lineage - inheritance,Lineage describes the history of a data set. During the processing of data - the derived information inherits artifacts from the dataset(s) of origin. In the case of published maps - some lineage information may be provided as part of its meta-data - in the form of a note on the data sources and procedures used in the compilation of the data. Examples include the date and scale of aerial photography - and the date of field verification. Especially for digital data sets - however - lineage may be defined more formally as:\r\r“that part of the data quality statement that contains information that describes the source of observations or materials - data acquisition and compilation methods - conversions - transformations - analyses and derivations that the data has been subjected to - and the assumptions and criteria applied at any stage of its life (Clarke and Clark - 1995).”\r\rAll of these aspects affect other aspects of quality - for example positional accuracy. Clearly - if no lineage information is available - it is not possible to adequately evaluate the quality of a data set in terms of “fitness for use”.,NONE118,CF6-3,Topological relationships,We can use the topological properties of interiors and boundaries to define relationships between spatial features. Since the properties of interiors and boundaries do not change under topological mapping - we can investigate their possible relations between spatial features. We can define the interior of a region - R - as the largest set of points of R for which we can construct a disc-like environment around it (no matter how small) that also falls completely inside R. The boundary of R is the set of those points belonging to R that do not belong to the interior of R - i.e. one cannot construct a disc-like environment around such points that still belongs to R completely.\r\rLet us consider a spatial region A. It has a boundary and an interior - both seen as (infinite) sets of points - which are denoted by boundary(A) and interior(A) - respectively. We consider all possible combinations of intersections (∩) between the boundary and the interior of A with those of another region - B - and test whether they are the empty set (∅) or not. From these intersection patterns - we can derive eight (mutually exclusive) spatial relationships between two regions. If - for instance - the interiors of A and B do not intersect - but their boundaries do - yet the boundary of one does not intersect the interior of the other - we say that A and B meet. In mathematics - we can therefore define the “meets relationship” using set theory. The eight spatial relationships are disjoint - meets - equals - inside - covered by - contains - covers and overlaps.,NONE119,CF6-4,Metrical relationships: distance and direction,Relationships between spatial features that define their relative position. Spatial autocorrelation is a fundamental principle based on Tobler’s first law of geography - which states that locations that are closer together are more likely to have similar values than locations that are farther apart.,NONE120,CF6,Relationships,Like geography - geographic information not only models phenomena but the relationships between them. This can include relationships between entities - between attributes - between locations. In addition - one of the strengths of geography (and GIS) is its ability to use a spatial perspective to relate disparate subjects - such as climate and economy. Methods for analyzing relationships are discussed in Unit AM4 Modeling relationships and patterns.,NONE121,CF7-1,Vagueness,Vagueness arises from lack of criteria for the applicability of certain linguistic terms. It arises from the lack knowledge about the meanings of terms.,NONE122,CF7-2,Error-based uncertainty,-Uncertainty-related terms - such as error - accuracy - uncertainty - precision - stochastic - probabilistic - deterministic - and random -Difference between uncertainty and vagueness -Dependence of uncertainty on scale and application -Expressions of uncertainty in language -The causes of uncertainty in geospatial data -Stochastic error models for natural phenomena -How the concepts of geographic objects and fields affect the conceptualization of uncertainty -Mathematical models of uncertainty: Probability and statistics,NONE123,CF7,Imperfections in geographic information,Human models (mental - digital - visual - etc.) of the geographic environment are necessarily imperfect. While the mathematical principle of homomorphism (often operationalized as fitness for use) allows for imperfect data to be useful as long as they yield results adequate for the use for which they are intended - imperfections are frequently problematic. Although terminology still varies - two types of imperfection are generally accepted: vagueness (a.k.a. fuzziness - imprecision - and indeterminacy) - which is generally caused by human simplification of a complex - dynamic - ambiguous - subjective world; and uncertainty (or ambiguity) - generally the result of imperfect measurement processes (as discussed in Knowledge Area GD Geospatial Data). Both of these can be manifested in all forms of geographic information - including space - time - attribute - categories - and even existence. Imperfection is also dealt with in Units GD6 Data quality (in the context of measurement) - GC8 Uncertainty and GC9 Fuzzy sets (for the handling and propagation of imperfections) - and CV4 Graphic representation techniques (in the context of visualization).,NONE124,CV,Cartography and Visualization,Geo-data visualisation necessarily includes cartography as the origin of 'mapping' our world. Cartography methods have drastically changed over the few years since the increasing role and sophistication of digital technology applied to geo-information visualisation. It is first worth differentiating between the underlying geo-data that describes real world phenomena and the bits of information that describe the visual presentation of geo-data . Likewise - there are processing tools to collect and handle geo-data - and processing tools especially designed to create and manage geo-data visualisations. \rWhile cartography methods have traditionally produced printed maps (i.e. hard copy) with static scale - orientation - projection - legends (content based) and tied to a period or instant of time. Nowadays geo-data visualisations are interactive by design - meaning that the results are map-based responsive interfaces - highly customisable through dynamic objects to zoom in and out - pan and tilt - change projections and graphic expressions on the fly - as well as dynamically browse the map over time. \rIf the production methods have changed - also the type of authors. Map making in its widest sense is not only a privilege of a few experts but has been democratised in such a way that. everybody is able to make maps using  open data and open source apps and tools for geo-data visualisation.  Therefore -the new roles of open data and new forms of geo-data like geo-social media make usability - intended and ethical considerations key aspects of geo-data visualization design - production and sharing. \rUnder the concept of cartography and visualisation it is included a list of concepts  that together comprise the science and technology of visual representation of geographic data.,NONE125,CV1-1,History and evolution of cartography,The evolution of cartographic representation in the previous centuries followed the most important technological and scientific developments of the time. It was driven by commercial and/or military needs and influenced by the special characteristics of the areas and/or environments  to be mapped. Recent developments are the rise of open data worldwide and widely available internet technology allowing end users to get remote geo-data published elsewhere. In recent years - data and its digital presentation have become central elements of cartography - whereas paper maps have become peripheral.,NONE126,CV1-4,Art and geodata visualisation,Art in cartography means much more than designing aesthetically pleasing maps - whether on paper or digital. Exploring the interaction at large between art and cartography involves rethinking the way we approach spatial expressions and how cultural - social and political dimensions are reflected in maps. This can be clearly observed in historical maps -  in between art and science - ranging from beautiful geographical representations created in the Middle Ages to convey religious messages to the creation of modern maps showing the power of modern empires and nations. This particular relationship between art and maps entails: “developing an inclusive approach of artistic mapping expressions; facilitating and encouraging interaction between cartographers who work with the Art aspects of cartography and artists who produce cartographic artifacts; and developing conceptual elements about the relationships between art and cartography.” Besides ancient paper maps - a sum of factors led digital maps and geospatial visualization - a matter of interest to artists and designers. Thanks to powerful computing systems and with the advancements reached in computer graphics or image processing - or the rise of information visualisation - new forms of representing and visualising geodata have also appeared. Creation of digital maps are still a two-way relationship since artists have explored maps as a medium for expressing their art - and cartographers have approached art to provide more than just the representation of locations and geographic features with the intention to make maps more attractive to their audiences.,NONE127,CV1-5,Historical maps,Historical maps are geographical representations made with the intention to represent spatial facts over time. Historical maps are generally considered valuable documents not just because of their historical value but also because most of them also are artistic representations by themselves. From a cartographical point of view - differentiation between historical maps and actual maps is mainly based on the advances in the history of Cartography - so once one disruptive advance in the map making process appears - maps created with previous techniques (and with some artistic or historical value) are usually considered as historical - such as ancient paper-based maps or old sea maps - for instance. Techniques such as scanning or photography can make ancient maps publicly available by converting hard-copy maps to digital ones. Once an historical map is digitised - the next step is to georeference it - which is the process of specifying and relating points of the digitalised map to actual coordinates in a geographic reference system. Because of its archival value and interest - historical maps are adequately preserved - following specific conditions - by map libraries - map societies or museums. Since digital methods and techniques have been replaced over time by new technological advances - first digitally created maps could be also considered historical - not because of its content - but of the techniques used to produce it.,NONE128,CV1,History and trends,At a certain moment in time people start to create more graphical representations of their surrounding environment. New technologies offered ways to expand these representations to larger geographical extent - higher spatial resolution - finer temporal granularity and larger periods. Technologies even made it possible to include other representations of reality such as social media and data ensembles in geodata visualizations - to the extent to even blend the real world with geodata-based visualization providing an augmented – virtual reality continuum. New forms of geo-data - like geolocated sensors may challenge the way geo-data visualisations are generated - shared and - eventually -  influence decision-making processes. History and trends sketch these developments and future outlook. This concept introduces the main stages and turns in development of cartography - from earliest times to the present - the most important methods in map-making and map-based visualizations.,NONE129,CV2-1,Data sources for mapping,As mapping ( geo-data visualization) is intended to convey a certain message to a certain audience - it is essential to use data sources that allow the intended visualisation result. The data should be of the right degree of detail and its use should not cause copyright problems. The producer quality of each data set should be taken into account - as well as the fitness of the data for the intended use. Aspects: message; data quality,NONE130,CV2-2,Data processing,In the trajectory between raw (geo)data and their user-relevant representation - the necessary data processing includes ways of abstraction by selection - filtering - generalization - transformation and classification of geographical data. In this data processing it is essential to at one hand relate the final symbolisation to the necessities of the intended message - and at the other hand to procedures that introduce as little error as possible.,NONE131,CV2-3,Mathematical base,Map projection is fundamental to representation of spatial data and for combining different datasets. Its choice should serve the presentation type that will convey the intended message to the audience. Many mathematical principles define datum - projections - horizontal and vertical co-ordinate systems - georeferencing- introduced with the focus on visualisation issues Aspects: geodetic concepts; transformations,NONE132,CV2,Data considerations,Geodata - including 3 dimensional geometry - as such can graphically be presented but most of the times the data as such doesn`t meet the presentation criteria. Especially if the dataset has to be presented in combination with other datasets. First all the geodatum - georeference and map projection are crucial but also the role of the geometry. The processing of the geometry and the related attributes may become a crucial step for an adequate presentation. Nowadays the highest precision may be used to define different graphical attributes for different zoom levels. On the other hand geodata visualisation includes also graphical datasets. Such data ensembles - the combination of geodata and graphical data - are the data sources that offer opportunities to other ways of visualisation then the traditional cartographic mapping. Facets: a.	Geospatial location (2D) and position (3D) that data refer to b.	Degree of detail in data origin (acquisition resolution) and in representation ('map' scale) c.	Types of data (e.g. imagery - field measurements - delineated objects),NONE133,CV3-1,Map design fundamentals,The combined impact of graphic design properties (balance - legibility - clarity - visual contrast - figure-ground organization - and hierarchal organization) and the map components (north arrow - scale bar - and legend) should always be carefully evaluated against the needs and the capacities of the audience.,NONE134,CV3-10,Geo-gaming,Geo-gaming is a crossover between gaming elements and location - usually enabled by location based services and  augmented adn/or virtual reality features. Geo-games - also known as “location-based games” or “location-aware games” -  have geodata at its core - since geoinformation constitutes the central element of the game mechanics.  Geo-gaming applications present unique technical challenges to meet the infrastructural and resources demands from the games and location worlds. There are mainly four different types of geo-games: exploration games (to make use of an existing spatial design);  feedback games (to report about players’ experiences in a specific design);  allocation games (to occupy the majority of game location); and configuration games (to occupy specific pattern of game locations). Gamers actively participate by interacting with the environment - therefore gaming scenarios are as  varied as their goals - which include teaching - training - and the developing of spatial thinking skills. Geo-games  offer a myriad of opportunities to developers: non-linear storytelling - physical object integration - a more visceral experience - true social interaction… which bring geo-games to another interaction level. Geo-gaming applications often rely on VGI to allow  gamers adding geolocated information that may crowdsource geo-referenced data useful for other secondary purposes .,NONE135,CV3-2,Symbols and icons,Map symbolization entails a number of variables to produce visual - tactile - haptic - auditory - and dynamic displays. Visual variables (e.g. - size - lightness - shape - hue) and graphic primitives (points - lines - areas) are commonly used in maps to represent various geographic features at all attribute measurement levels (nominal - ordinal - interval - ratio). With those a single geographic feature can be represented by various graphic primitives (e.g. - land surface as a set of elevation points - as contour lines - as hypsometric layers or tints - and as a hillshaded surface). The challenge is to use effective symbols for map features to ease the interpretation of maps.,NONE136,CV3-3,Colour,The selection of colours to use in data representation can be influenced by various factors (e.g. the production workflow - cultural differences - involved devices and media). There are various colour models (e.g. RGB - CMYK - CIE) that describe colours in a way that they can effectively convey visual information (e.g. - qualitative - sequential - diverging - spectral) according to the meaning of the underlying data. The cultural background of the consumer is also relevant when it comes to choose colours that should have real-world connotations or should express psychological concepts (e.g. harmony - concordance - balance). A final important factor is if the consumer has colour limitations,NONE137,CV3-4,Typography,When data representation is conveyed in words (e.g. toponyms - road codes) - written text is often placed in map labels. It is important to decide on the role of the label in the context of the representation type. Algorithms for label placement are relevant - especially when label density is high. Shape and colour of the labels help to signify different types of messages. This is supported by the typographic properties (type font - size - style) of the text in the labels. Finally - it is important to use an authoritative source for the texts,NONE138,CV3-5,Photos and imagery,Imagery can be a source for data acquisition as well as an illustration to abstract data representations. Imagery can be made from the air (from drones to satellites) or from a terrestrial point of view (street-level imagery). Using photos from any source to illustrate stories about geographical subjects contributes as the visual aspect of telling a story. Together with maps and other narrative components - the combination embodies a storytelling medium.,NONE139,CV3-6,Animation,Animation is the process of making the illusion of motion and change by means of the rapid display of a sequence of static images that minimally differ from each other. In the context of maps - the temporal component is added to a map to emphasize and observe the gradual evolution of a certain monitoring phenomenon - such as changes in spatially numerical variables (for example - environment - population - mobility - land use - etc.) with respect to a  static geographic area. Map animations generally consider dynamic time while space is static. Map animation helps to see patterns or trends that emerge as time passes - depicting meteorological or climate events - natural disasters - historical events  and other multivariate data. It is particularly helpful to be  used in educational settings.,NONE140,CV3-7,Sound,Sound or audios can be one of the components of a multimedia data representation. A conventional GIS usually conveys visual information - however the integration of audios in mapping could enrich GIS data to other senses. Sound can increase the amount of information that’s communicated to the user through channels other than visual to address the special needs of people with visual impairments or people who cannot use in certain circumstances their sight - such as a driver who cannot look at a map. Approaches to rendering sound information on a map fall into three broad categories: (1) to sonoficate the whole visual presentation (for simple geometric data) - (2) to augment a visual system with auditory information (allowing multivariate information) and (3) to display information about the surrounding where a user is. By classifying images and creating  additional audio layers that associate each pixel with a specific sound - a GIS can add a new auditory dimension to maps.,NONE141,CV3-8,Storytelling,Maps are valuable because they provide a large amount of detail in a small amount of space - and because of their capacity for telling a story. Telling stories through maps began with describing explored lands in great detail against terra incognita. Today - geographic tools - data - and multimedia on the web expand the ability to communicate stories and inform through maps to a broad audience such as journalists - decision makers and educators. Any person with a smartphone or computer can tell a story - using statics maps - or interactive web maps with text - video - audio - sketches - and photographs. Besides the technical skills to clearly communicate with a map (palette of colours - amount of information displayed…) - other factors such as narrative processes - the storyboard - place - time - and characters play a crucial role. To be informative - it is important that the correct data is displayed - combining different sources of information combined to create an appealing and accurate map.,NONE142,CV3-9,Infographics,Infographics are visual representations of information and data - which can contain charts - diagrams - graphs - tables - maps and lists. The aim of an infographic is to present information that can be absorbed quickly - it is easily understandable and extensively in mass communication - and thus designed with fewer assumptions about the reader's knowledge base than other types of visualizations.  The role of maps in an infographic is based on the potential of maps to condense information and to support a narrative. Infographic maps - altogether with an adequate storytelling -  should find a simple way to explain current complex issues - providing added value to the infographic - and being an effective and efficient way to communicate.,NONE143,CV3,Design principles,This concepts covers basic design principles that are used in mapping and visualization - as well as cartographic design principles specific to the display of geographic data. Both page layout design and data display are addressed.,NONE144,CV4-1,Thematic mapping,A thematic map is a type of map especially designed to show a particular theme connected with a specific geographic area. These maps 'can portray physical - social - political - cultural - economic - sociological - agricultural - or any other aspects of a city - state - region - nation - or continent'. Cartographers use many methods to create thematic maps. Five techniques are especially noted: -Choropleth mapping shows statistical data aggregated over predefined regions -Proportional symbols - showing the relative value of attributes -Isarithmic or Isopleth - also known as contour maps -Dots - to show the location of a phenomenon -Dasymetric - which uses areal symbols to spatially classify volumetric data.,NONE145,CV4-10,Visualization of uncertainty,Conveying uncertainty information is often done through visualization. Uncertainty is often defined - quantified - and expressed using models specific to individual application domains. In visualization however - we are limited in the number of visual channels (3D position - color - texture - opacity - etc.) available for representing the data. Thus - when moving from quantified uncertainty to visualized uncertainty - we often simplify the uncertainty to make it fit into the available visual representations. (After Potter et al. - 2012). The seven challenges as formulated by MacEachren et Al. (2005) are still there to be tackled.,NONE146,CV4-2,Representing terrain,Relief can be represented in a two-dimensional map either through contour lines or through a raster format gridded array of elevations. Contour lines connect points of equal elevation. At regular intervals index contours are marked with elevations so a reader can more easily determine the elevation of surrounding locations. They are the preferred method for analogue topographic maps. The grid approach is used in digital mapping and known as a digital elevation model (DEM) - where each raster cell represents an elevation. Scaling of the cell z value in relation to the x and y value results in terrain exaggeration - which aids visualization of topography.\rDEMs are used for terrain analysis and can be used to obtain derivatives such as slope and aspect. DEMs are obtained by interpolating point elevation observations -  which are historically retrieved from surveyed point data (e.g. GPS locations) - but more recently from LiDAR and/or Structure from Motion point clouds. TIN (triangular irregular network) analysis is commonly used for point data interpolation - in order to derive a continuous elevation surface.,NONE147,CV4-3,Multivariate displays,Multivariate descriptive displays or plots are designed to reveal the relationship among several variables simultaneously. Bivariate and multivariate maps encode two or more data variables concurrently into a single symbolization mechanism. Their purpose is to reveal and communicate relationships between the variables that might not otherwise be apparent via a standard single-variable technique. There are basic characteristics of the relationship among variables - such as the forms of the relationships - the strength of the relationships - and  the dependence of the relationships on external (usually to the pairs of variables being examined) circumstances. Therefore - these multivariate plots or maps are inherently more complex - though offer a novel means of visualizing the nuances that may exist between the mapped variables. As information-dense visual products - they can require considerable effort on behalf of the map reader - though a thoughtfully-designed map and legend can be an interesting opportunity to effectively convey a comparative dimension. Examples of multivariate plots include enhanced 2-D scatter diagrams - 3-D scatter diagrams - contour - level - and surface plots - and high-dimensional data plots,NONE148,CV4-4,Visualization of temporal geographic data,Visualization of change and movement across space and time is of increasing interest to researchers and geospatial practitioners. The visualization process of temporal data has four steps: (1) time values to be visualized - (2) point of view on time - that identifies the characteristics of the temporal values to be visualized - (3) time space: define the displayable space of the time values and (4) point of view on the visualization space - the implementation of the perceptible forms of time. The visualization of spatio-temporal data can be done in many different ways such as multi-panel plots (maps) - time-series plots (graphs) - space-time plots (graphs) - 3D Virtual Reality (Computer generated artificial environment) - animations (production of consecutive images) - and tables. Spatiotemporal data comprises three important components: geographic location - temporal information and the thematic attributes describing a real-life phenomenon.,NONE149,CV4-5,Dynamic and interactive displays,Dynamic and interactive displays refers to a situation where a display with a cartographical data representation changes in real time in response to user's actions,NONE150,CV4-6,Web mapping,Web mapping is the process of designing - implementing - generating and delivering maps on the World Wide Web. Dissemination via the web opens new opportunities: realtime maps - cheaper dissemination - more frequent and cheaper updates - personalized map content - distributed data sources and sharing of geographic information. Technical restrictions cause challenges like low display resolution and limited bandwidth -( in particular with mobile computing devices with small screens and using slow wireless Internet connections) - copyright and security issues - reliability issues and technical complexity. Today's web maps can be interactive and integrate multiple media. So interactivity - usability and multimedia issues also play a role.,NONE151,CV4-7,Virtual and immersive environments,Virtual reality or virtual realities (VR) - also known as immersive multimedia or computer-simulated reality - is a computer technology that replicates an environment - real or imagined - and simulates a user's physical presence and environment in a way that allows the user to interact with it,NONE152,CV4-8,Augmented environments,An Augmented Environment can be experienced through different sets of Augmented Reality (AR) technologies - including mobile displays (tablets and smartphone screens) - computer monitors - or Head-Mounted Displays (HMDs) - among others. AR is a technology that layers computer-generated enhancements atop an existing reality to make it more meaningful through the ability to interact with it. AR offers the integration of digital information and imagery onto the real world in real-time. In order to broaden the vision beyond this definition - AR can be described as systems having the following features: (1) combines real and virtual; (2) interactive in real-time; and (3) registered in 3D - allowing other technologies - such as mobile technologies - monitor-based interfaces - monocular systems to overlay virtual objects on top of the real world. Currently - AR applications use the camera provided by mobile devices to produce a live view of the real world in combination with relevant - context-appropriate information such as text - videos - or pictures.\rThere are lots of applications and systems in the market that provide AR functionality - making it difficult to classify and name them all. Some of them are related to the real physical world and others with the abstract - virtual imagery world. Sometimes it is not easy to figure whether it is an AR - as often AR is defined as Virtual reality (VR) with transparent HMDs. In general - the concept is to mix reality with virtual reality - including information and overlay over the real world through HMDs such as they seem apparent as one environment. The virtual objects can react accordingly with the camera's movement as it is registered concerning the real world - which is also the central issue of AR.,NONE153,CV4-9,Spatialization,Cartographers have recently become involved in extending geographic concepts and cartographic design approaches to the depiction of non-geographic data archives - using so-called spatialized views of information spaces. Spatializations differ from ordinary data visualisation and geovisualisation in that they may be explored as if they represented spatial information. (Fabrikant - S.I. - 2003). As definitions of spatialization can be found: Spatializations are computer visualizations in which nonspatial information is depicted spatially (Montello et al. - 2003). Spatialization is the transformation of high-dimensional data into lower-dimensional - geometric representations on the basis of computational methods and spatial metaphors. (Skupin 2007),NONE154,CV4,Graphic representation techniques,This concept addresses mapping methods and the variations of those methods for specialized mapping and visualization instances - such as thematic mapping - dynamic and interactive mapping - Web mapping - mapping and visualization in virtual and immersive environments - using the map metaphor to display other forms of data (spatialization) - and visualizing uncertainty. Analytical techniques used to derive the data employed in these graphic representations are discussed in Knowledge Area AM Analytical Methods and Unit DN2 Generalization and aggregation.,NONE155,CV5-2,Web map making,Standards for map services were set by OGC and ISO - called WMS and WMTS. Producing map images on the web from a cartographic image in a GIS application is called 'publishing'. Making a web 'map' in the broader sense of constructing data representations for Storytelling or Geo-gaming is still under development. It requires a mix of applying the map Design principles and Graphic presentation techniques - possibly in combination with software scripting.,NONE156,CV5-3,Traditional map making,Traditional 'map' making - as opposed to the mapmaking in neogeography - focuses on reliable and reproducible products - based on expertise of high definition printing in many colours on analogue media of geodetically well-constructed images.,NONE157,CV5-4,Map reproduction,The aspects of reproduction of a data representation depend on the nature of the representation: is it analogue (a paper map - a mock-up) or is it digital? In the case of a paper map - its digitalisation with high fidelity is an essential step. With a source in digital form - reproduction can be a matter of the right printer. Alternatively - the source could be disseminated as a file or as a web service. If representations are dynamic and/or interactive the possibilities depend on the construction of the representation. The ease of dissemination of digital files should not result in copyright breach. Aspects: Digitalization techniques for analogue sources - Printing ( 2D - 3D) - Dissemination ways - Construction of the data representation - User needs specification - Copyright issues,NONE158,CV5,Map production,This concept addresses map production and reproduction - as well as computation issues that relate to those workflows.,NONE159,CV6-1,The power of maps,The potential of maps as a way to show or exert power over the population was early understood by ruling classes. A map expresses a claim by the inclusion or exclusion of map elements and how these elements are visually related and/or depicted on the map. So - the world could be modeled through the careful choice of content arranged graphically at a specific scale and in specific formats. Therefore - maps embody and project the interests of their creators. The “new cartographies”  declare that maps are redefined as socially constructed arguments based upon consistent semiotic codes. Nowadays - the rise of costless - powerful and accessible tools for creating maps - put power on the side of individuals or groups of individuals with few organisation (crowdsourced data collection or VGI) capable of representing their world views. In addition - monitoring people - places or nature - for instance - should also be seen as another way to show the increasing power of maps. Surveillance mechanisms for tracking populations used by rulers - or the use of extended technologies like Google Earth by environmental organisations to track the Amazonian forest - constitute two examples of the particular use of maps to exert control over human beings or to press governments for taking specific actions - respectively.,NONE160,CV6-2,Map reading and interpretation,Maps today help us locate the nearest gas station or ATM on our in-car navigation system - but this use of locating what is near or surrounds a location is not new.  Maps from pre-historic times provided important locational information – what was where and how to get from place to place.  A map can be a relatively simple iconic device - which can be read and interpreted with only a little training. These graphic representations of the real world could be traced in sand or painted on a cave wall and shared through time. Maps even preceded written language and number systems and are found in some format in most cultures through time as a graphical language. Learning to read this language and interpret it without ambiguity is not as simple as first suggested. This complexity has increased as technology has allowed creation of 3D and 4D interactive maps which allow anyone with internet access the ability to investigate different places - topics and times and produce their own map. Today the ability to read and interpret maps is increasingly important as industry - business and government communicates within their organization and the public using maps. Becoming aware of what a “map” shows depends partly on what the senses can register of the representation as a whole. It also depends on recognition of elements in the representation that are meaningful to the observer in the sense that these elements are credible indicators of spatial features. Based on that recognition - the nature of these elements and their spatial pattern might infer thoughts about historic or ongoing processes. This interpretation will be influenced by the expertise and needs of the observer.,NONE161,CV6-3,Usability analysis,Assessment of the usability of a data representation is about how useful it is to users. Therefore it is a test of the success of the representation design - a test of the skills of the 'map' maker and a test for the reliability of the underlying data.,NONE162,CV6-6,Spatial thinking,Spatial thinking is thinking that finds meaning in the shape - size - orientation - location - direction or trajectory - of objects - processes or phenomena - or the relative positions in space of multiple objects - processes or phenomena. Spatial thinking uses the properties of space as a vehicle for structuring problems - for finding answers - and for expressing solutions' Aspects: recognizing spatiality in a collection of things; translation of the collection to a pattern of elements; recognizing structure (relations between the elements in a pattern); recognizing process (or changes over time in patterns or structures),NONE163,CV6-8,Map ethics Legal and privacy issues,Ethics is about the question if behaviour is right or wrong in a social context. In dealing with geodata - a person can do the wrong thing with respect to laws (e.g. disclose secrets - disregard privacy - copyright infringement) or to professional standards (e.g. use bad data - forget about the colour blind - downplay unpleasant details). Aspects: breach of legal standards; breach of professional standards,NONE164,CV6,Usability of maps,Geodata visualisation are always made with a certain purpose. The role and understanding of such graphical representation is an important field of research. Besides theories that underpin evaluation approaches and their findings the visualisation may also be confronting. The more realistic the presentation and especially when it includes human/personal related data the ethical dimension of the visualisation play a major role. Usability of visualisations has also an impact on spatial thinking as has been proved by scholars.,NONE165,DA,Design and Setup of Geographic Information Systems,Proper design of geospatial applications - models - and databases and the validation and verification of design activities are critical components of work in all areas related to GIS&T. Design failures can negate well-intentioned efforts to apply concepts and technology to solve real-world problems. While sharing a number of concerns with general systems analysis - the unique and complex spatial characteristics of geospatial information provide significant additional challenges. The focus of this knowledge area is on the design of applications and databases for a particular need. The design of general-purpose models and tools (e.g. - raster and vector) is covered in Knowledge Area: Data Modeling (DM). In the context of specific implementations - design activities fall into three general classes:\r1. Application Design addresses the development of workflows - procedures - and customized software tools for using geospatial technologies and methods to accomplish both routinary and unique tasks that are inherently geographic.\r2. Analytic Model Design incorporates methods for developing mathematical models - spatial models and data processes. The design of the analytic model is often influenced by decisions that are made about data models and structures.\r3. Database Design concerns the optimal organization of the necessary spatial data in a computer environment in order to efficiently sustain a particular application or enterprise.,NONE166,DA1-1,Requirements gathering and analysis,This concept deals with the importance of having a list of prioritized requirements as a first step to ensure a smooth and successful implementation of a GIS project.. It entails the different methodologies and approaches to ensure a GI system covers all functional and nonfunctional requirements. Requirements are not only derived from business workflows but it is advisable to gather direct input from potential users that will be translated into requirements. However - there is a need to clearly rank the importance of the requirements gathered to ensure the GI system is manageable and in line with the intended use of the GI system - in opposition with the specific interests of a particular user or ambiguous requirements. Therefore - the documentation - traceability and evaluation of requirements after the implementation are as relevant as the initial gathering of requirements to give consistency to the designed system.,NONE167,DA1-2,Methods of process description and documenting,The internal process of documenting a task or a process is about “how” it is implemented and “what” is implemented. Documenting is particularly helpful if a breakdown occurs - such as when an expert working in a task leaves her job or to substitute one task in  a set of interrelated processes by another. Documentation provides consistency for the taskand allows its monitoring - analysis and revision during a project. \rThere are different methods for documenting a task  to transform tacit knowledge into explicit knowledge. Therefore -  the task should be documented  by describing it in video format and using visual tools that allow documentation - or the maintenance of a field diary.\rIn particular cases - the creation of user guides or manuals could be considered a subset of a process description particularly addressed to external users. A user manual should take into account the target users to adapt its content to them.,NONE168,DA1-4,Workflow definition and consideration in GI systems,A workflow is a sequence of operations that altogether perform a complex - sophisticated or repetitive  operation or activity. No matter the workflow type - a workflow is defined in a declarative language - either text-based or visual - and stored in a workflow document to ease sharing and maintenance. In GI systems - a workflow can be seen from distinct perspectives. One of the most well-known GI workflow types is spatial data modelling. A model is specified as a combination of processing tools that manipulate and transform the spatial data required by the model. The  order in which the processing tools - inputs - and outputs are organised in a workflow will determine the results and to what extent the spatial question is addressed. However - workflows in GI systems are not only related to spatial data modelling and transformation. There are cases where certain processes in GI systems should be designed in terms of software and hardware requirements - actors needs - organisational aspects or resource usage and demand. How can people’s work contribute to define the stages of a GI architecture? How much time does a regular user spend working with spatial data? How complex is the process going to be? The definition of this sort of workflows can help - for example - in designing an optimal architecture for a GI system in a particular enterprise configuration. \rWhether the workflow defines specific steps to process spatial data or the stages and details to implement an enterprise GI system - having a clear idea over each stage's inputs and outputs helps GI systems to be organised - consistent and reliable. In summary - high-level workflows like business workflows put together systems - components and actors that are part of a process or operation. They represent an abstract view - focused often on organisational - functional and resources usage aspects. Conversely - low-level workflows refer to a series of executable activities that carry out data transformations - models or spatial data analysis. Examples are code scripts - specified as sequences of commands in a programming language - and graphical workflows through - for example - the Model Builder in GI systems which are enacted by workflow engines.However - workflows in GI systems are not only related to spatial data modelling and transformation. There are cases where certain processes in GI systems should be designed in terms of software and hardware requirements - actors needs - organisational aspects or resource usage and demand. How can people’s work contribute to define the stages of a GI architecture? How much time does a regular user spend working with spatial data? How complex is the process going to be? The definition of this sort of workflows can help for example in designing an optimal architecture in an enterprise configuration for a GI system. \rWhether the workflow defines specific steps to process spatial data or the stages and details to implement an enterprise GI system. Having a clear idea over each stage's inputs and outputs helps GI systems to be organised - consistent and reliable. In summary - high-level workflows like business workflows put together systems - components and actors that are part of a process or operation. They represent an abstract view - focused often on organisational - functional and resources usage aspects. Conversely - low-level workflows refer to a series of executable activities that carry out a complex task - service or model. Examples are code scripts - specified as sequences of commands in a programming language to carry out data transformations and spatial models and spatial data analysis; and graphical workflows through - for example - the Model Builder in GI systems which are enacted by workflow engines.,NONE169,DA1-5,Software design and engineering,Software and information technology are integral to any GI systems or projects - from the storage and handling of spatial data to its analysis - visualization and sharing. Therefore - the use of well-known software design and engineering techniques and methods to develop efficient - reliable - and easy-to-maintain software applications in the GIS realm is more important than ever.   \rAmong the modern software design and engineering techniques - Agile software development methodologies like Scrum stands out. The common rationale of the Agile methods is to split a large software project into many functional pieces of software that help the software engineering team to translate their development efforts into quick prototypes - and eventually reach the final product. Therefore - the constant feedback and validation of the user’s requirements in short - iterative development circles (i.e sprints) are the main advantages of the Scrum methodology.,NONE170,DA1-6,User interface and Usability,User interface and usability of a GIS system,NONE171,DA1-9,Geodesign,Geodesign is a design and planning method along with geospatial modelling and technology - and simulations informed by geographic contexts to facilitate informed decisions and the creation of design proposals. A geo-design process is a problem-based - iterative process bounded by specific (geographic) constraints characterised by a collaborative effort.,NONE172,DA1,System design,This concept encloses a set of activities and workflows to ensure that the implementation of a GIS system in an organization or project is correctly planned and designed according to the particularites - user requirements and current conditions of the project ahead. In general system design is the process to promote successful GIS in an enterprise environment. As a GIS system has a direct influence on the information technology department  (IT) - the system design tells the organizacion how the current infrastructure can or must support the planned GIS.  This process builds a set of specific recommendations on hardware and network needs based on the number of projects that depend on the GIS solucion - as well as the projected business needs and user requirements. \rGIS architects through the system design process need to take into account and identify several conditions: a) infrastructure requirements - b) the network communication capacity - c) hardware and software procurement requirements and - d) software development and data acquisition needs. \rHaving a well-defined and successful GIS deployment is not only a matter of what data or software the organization should acquire. The process of system design aligns identified business requirements (user needs/requirements) derived from business strategies or project aims - goals - and stakeholders (business processes) with identified business information systems infrastructure technology (network and platform) recommendations. \rThe process starts with identifying business needs - including the identification of users locations - required information - data - resources or products. The business needs are generally considered as project workflows that help the GIS architects to identify the expected data traffic and computing demand associated with each transaction - being a transaction the work unit used to translate business requirements into associated server and network loads.\rWithout carrying out a proper system design - a GIS system can lead to  an implementation and deployment failure - deriving in unfulfilled expectations and high costs in terms of human resources and financial matters.,NONE173,DA2-1,Project management,Project management includes the planning - organization - coordination - execution - monitoring - controlling  and closing of the activities and resources - human and economic - for the timely achievement of clearly defined objectives forming a project. For the success of a project - a project manager will assure an efficient use of resources and a proper execution of tasks to deliver value to users and “clients” of products and services.  The Project Management Body of Knowledge (PMI) defines “project management” as “the application of knowledge - skills - tools - and techniques to project activities to meet requirements” - being  EO*GI projects are another type of information technology projects. PMI reflects different areas to take care of by project management. These areas are:  Integration - Scope - Time - Cost - Quality - Human Resource - Communications - Risks - Procurement and Stakeholder. There are a variety of tools and techniques used in the areas identified by PMI - just to name a few Gantt chart - Program evaluation and review (PERT) analysis - AGILE project management - etc. that will help in project management.,NONE174,DA2-2,Feasibility analysis,This concept embraces the factors that could affect a GI system / project and could constitute obstacles to success or even decide a project is not doable. In order to ensure the success of a GI system or a GIS project there are several criteria to take into account from the very beginning of the conception of the GI system or project. A feasibility study may encompass different perspectives (economic - legal - technical - operational or scheduling ) to inform whether or not a project is worth the investment. An organisation should list the foreseen costs from these  five perspectives listed above and the benefits (tangible or intangible) of implementing a system/project. Existing resources already available in-house and internal strategic plan in place could be critical to decide to undertake a project or not. The table below presents a non-exhaustive list of criteria  and under which perspectives they should be examined.\rFeasibility analysis should include a pilot study to evaluate and improve the system / project proposed.,NONE175,DA2-8,Proprietaty and open source software,This concept discusses the technical - organizational and monetary advantages and disadvantages of proprietary versus open source software. GIST industry and research are slowly but consistently moving toward the openness of software. Open software entails some clear advantages such as continuous development of new applications - building community of developers and users - starting a project even if limited funding is available -  increasing the chances of a project’s sustainability - to name a few. On the other side - proprietary initiatives in GIST are keeping their roots to the ground by developing cutting-edge tools to handle challenging and critical environments in large private sectors and public administrations. Advantages of proprietary software include  more stable software - a well developed documentation and personalised customer support service. Both open and proprietary geospatial software solutions can co-exist by applying the appropriate IPR licences for each type of solution. The future trend is to balance how proprietary and open source geospatial software complement each other and find synergies in increasingly complex and large projects.,NONE176,DA2,Resource planning,To design - build - and maintain a GIS - sufficient resources (e.g. - labor - capital - and time) must be secured. Resource planning consists of the allocation and use of  in-house resources  (people - equipment - tools - rooms - etc.) to achieve the maximal efficiency of those resources. These resources are required for a variety of system elements - including design - software purchase - labor - hardware - and facilities. The crucial task is to determine whether the project is worth the required resources.,NONE177,DA3-1,Major geospatial software architectures,The ecosystem of GIS software architectures has evolved substantially in recent years to include a variety of options ranging from desktop GIS - server-based and component-based architectures to Web-based - cloud-based - mobile-based approaches. Aligned with the main trend - geospatial software architectures or infrastructures are also moving from desktop architectures  to more cloud based or server based options to meet  ever-increasing requirements of interoperability - interdisciplinary work and computational power for processing large data sets and derived products. Cloud-based architectures also enable on the fly visualization of computed geospatial products - as complementary visualisation and mapping tools are seamlessly integrated into modern cloud-based based architectures. Usage of a particular architecture is fully dependent on the nature - size - requirements - functionalities - and available resources of a given project or task. Desktop and server based applications are particularly suited for small sized projects and startups while enterprise based applications are meant for larger sized projects. Cloud based infrastructure can be useful for varying sizes of projects in which the computational infrastructure is fully outsourced.,NONE178,DA3-2,Interoperability,Interoperability of GIS infrastructure or architecture ensures the consistent and uninterrupted usage of data and functionalities across platforms and systems. Components or tools residing on distinct platforms can “talk” to each other without friction.  Interoperability is a central characteristic - especially important in distributed systems and architectures. It can be applied to different levels or layers of a system - i.e. infrastructure level -  data level - business logic level - etc. For example - standard spatial data formats and protocols are especially relevant  for handling GIS data across multiple systems and platforms - regardless of their underlying software architecture. This is particularly important in large-scale - collaborative projects involving various teams using heterogeneous GIS architectures. Most software providers - developers communities and standardisation bodies and committees are striving to make their architectures interoperable in an open manner - so proprietary standards and protocols are a potential hindrance to this initiative.,NONE179,DA3-3,Architectural Patterns,This concept considers general architectural patterns like SOA - ROA - Web Services - etc.,NONE180,DA3-4,WebGIS - SDI services - map services,- WebGIS - - technical pecularities of spatial data infrastructures - standardiced GI services for SDI: WMS - WFS - CSW - Transformation Services - SOS - WPS etc. - - other map services and interfaces,NONE181,DA3-5,Reference Model of Open Distributed Processing,This concept deals with Reference Model of Open Distributed Processing (RM-ODP) - its standards - viewpoints modeling and the RM-ODP framework,NONE182,DA3-6,Cloud and Grid computing,Cloud computing provides an on-line computing transparent resource to the user - since a user doesn’t notice almost no difference between working on her own computer or the cloud. Owned and managed by infrastructure providers - cloud computing entails advantages (concurrent access by many users - software updates hosted in the cloud - cost-efficiency or outsourced maintenance in the cloud) and disadvantages (loose of control - network Connection Dependency or security breaches ). On the other side - grid computing is a full network of computers and data working together so functioning as a supercomputer. Grid computing presents advantages such as shorter resolution of complex problems - the ease of organizational collaboration or a better use of existing hardware.,NONE183,DA3-7,Desktop GIS - GIS libraries,Within this concept solutions based on Desktop GIS and GIS libraries will be compared and contrasted,NONE184,DA3,Architectural design of a GIS system,This concept describes the major geospatial software architectures available currently and choices when designing GI applications and systems - including desktop GIS - server-based - Internet - and component-based custom applications.,NONE185,DA4-1,Modeling tools,- Compare and contrast the relative merits of various textual and graphical tools for data modeling - including E-R diagrams - UML - and XML - Create conceptual - logical - and physical data models using automated software tools - Create E-R and UML diagrams of database designs,NONE186,DA4-2,Conceptual models,Within an initial phase of database design - a conceptual data model is created as a technology-independent specification of the data to be stored within a database.,NONE187,DA4-3,Logical models,A logical data model expresses the meaning context of a conceptual data model - and adds to that detail about data (base) structures - e.g. using topologically-organized records - relational tables - object-oriented classes - or extensible markup language (XML) construct  tags,NONE188,DA4-4,Physical models,A physical data model documents how data are to be stored and accessed on storage media of computer hardware,NONE189,DA4,Database design,The effective design of geospatial databases should follow the established methods and principles of database modeling and design developed in computer science. The basic method is a three-step process generally called the conceptual - logical - and physical models transforming the application from very human-oriented to machine-oriented. Several standards and software tools exist to aid the process of database design.,NONE190,DM,Data Modeling - Storage and Exploitation,This knowledge area deals with representation of formalized spatial and spatio-temporal reality through data models and the translation of these data models into data structures that are capable of being implemented within a computational environment (i.e. - within a GIS or more likely within a spatial database). Data modelling is a crucial issue as it defines the content of a spatial database and usefulness of these content (data) for certain applications. Data Modelling is performed using system neutral languages like UML (or more seldom ER-diagrams). These conceptual models have to be transferred to logical models (i.e. tables of a database). Data is stored in spatial databases which are normally organized in an object relational way. For certain types of data specific databases are used - like triple stores - NoSQL DBs - Array DBs etc. For data modelling quite a number of ISO standards are available for deriving the conceptual model as well as for rules for application schemas - spatial schemas - temporal schemas - Quality principles - encoding - 3D modelling (CityGML) etc. Data models provide the means for formalizing the spatio-temporal conceptualizations. Examples of spatial data model types are discrete (object-based) - continuous (location-based) - dynamic - and probabilistic. Mastery of the objectives presented in this knowledge area require knowledge and skills presented in the bodies of knowledge of allied fields - including computer science (ACM/IEEE-CS Joint Task Force - 2001) and information systems (Gorgone & Gray - 2000; Gorgone & others - 2002).,NONE191,DM1-1,Overview on database concepts,This topic includes the main basic database concepts: - Database - definition and overview - Database management system - definition and overview - Relational databases - overview - Object-oriented databases - overview - Object-relational databases - NoSQL databases - general overview - NoSQL databases - examples triple stores - array databases - others (overview),NONE192,DM1-2,The Relational Model,The Relational Model is the most important database model - therefore it is explained in more detail here: - Basic concepts (tables - tuples - etc.) - Relation to relational algebra (RA) - basics of RA - Constraints (key - domain - referential integrity) - Relation to entity relation (ER) model - basics of ER,NONE193,DM1-3,Relational Databases - Database Managements Systems and Database principles,Relational databases and database management systems are essential for GIS in consequence the important issues have to be treated here: - General aspects - basic architecture of a DB - advantages - features - DBMS concepts and functionalites (transactions - locks - multiuser access etc.) - Database design - techniques - Database administration - Normalization (1NF - 3NF) - Example of a database design,NONE194,DM1-4,Data Structures and Indices for Databases,Database queries and especially spatial queries require specific data structures to be performed satisfactory Relevant is: - Motivation - examples of typical non-spatial and spatial queries - Trees - B-tree - R-tree - Q-tree - Graphs - overview and relation to databases,NONE195,DM1-5,Data compression techniques,Big data like imagery but also for example GML data sets need compression to be accessed / transferred in an acceptable time. Therefore some compression techniques have to be taught: - Motivation - examples of data sets which need compression - General introduction - vector - / raster data compression - compression lossless - lossy - Popular compression techniques - LZW (Lempel-Ziv-Welch) encoding - Huffman encoding - Techniques for raster data - runlength encoding - JPEG coding - wavelet etc. - Techniques for the reduction of vector data (Douglas Peuker etc.) - Data formats - overview and relation to compression techniques,NONE196,DM1-6,SQL and its usage for data handling - spatial extensions to SQL,SQL is the 'standard' to perform spatial and non-spatial queries in databases. That means each student in a GI related course has to be familiar with the main aspects if it: - Motivation - history - overview - Data definition language DDL - Data manipulation language DML - Data control language DCL - Spatial extensions of SQL,NONE197,DM1-7,UML introduction and class diagrams,UML is the standard for describing the schema related to GI models - but also user requirements - workflows etc. can be described in UML using the UML diagrams: - Motivation - background - purpose - Use case diagrams - Class diagrams - Sequence diagrams - Activity diagrams,NONE198,DM1-8,XML introduction,XML knowledge is an important bases for understanding GML. Moreover XML tools like XSLT are important to transform XML or GML data sets into other XML based formats like SVG or others. Important issues: - Motivation - purpose - Relation to HTML - XML document structure - XML syntax - elements - attributes and namespaces - xlink - xpath and XSLT - XML DTD - XML schema,NONE199,DM1-9,Database concepts in GIS and Principles of spatial databases,The long term storage of GI data in general is based on spatial databases. Therefore the following is essential for a GI course: - Relation between GIS and DB / 'Long transactions'- Dual concepts - Characteristics of spatial databases - Spatial data in object relational databases - Spatial extensions of DBs - overview,NONE200,DM1,Foundations for Data Modelling Storage and Exploitation,This unit includes the basics for data modelling - storage and exploitation. Data modelling is one of the most important activities in conjunction with Geographic Information / GIS as it determines how the data can be used and if the requirements from applications are fulfilled. Data modelling can be done in conjunction with the database - e.g. through ER diagrams or according to the ISO 191xx standards by using UML. The costs of data acquisition can be tremendous - therefore the data represents an enormous value. This value has to be conserved through a safe long term data storage. Therefore databases and especially relational and object relational databases are crucial. For a proper storage and query of geographic information databases are extended with specific data types and data structures. As data sets can be very large suitable compression techniques became important especially in the context of accessing and delivering geographical data - e.g. through services. XML based modeling languages for encoding also play and important role in this context,NONE201,DM2-1,Overview on relevant standards and standardisation bodies,GI standards - mainly from ISO and OGC are essential nowadays. Moreover also an overview on ICT standards from W3C or OMG are important as well as some understanding of standardization processes. In detail: - Motivation for standards - examples from daily life - Overview on GIS and relevant ICT standardization bodies and selected standards - De jure and De facto standards - obligation - reasons for the usage of standards - Standardization within ISO - Standardization within OGC - relation to ISO - Examples of ISO 191xx standards,NONE202,DM2-2,The principle of conceptual data modelling according to ISO,Conceptual data modeling is a key skill for GI people. (see relations to other topics) The following therefore is important: - Overview on the relevant standards like conceptual schema language - Rules for application schema - Examples of conceptual schemas,NONE203,DM2-3,Geometry data types according to spatial schema and the simple feature specification,Geometric modelling is an important subtask of conceptual modelling and requires the following basics: - Overview of ISO 19107 - spatial schema - Overview of ISO 19125 - simple features - Examples of the usage of spatial schema and simple feature elements for feature class definitions - Relation to GML - Relation to DBs,NONE204,DM2-4,Temporal data types according to temporal schema,Also temporal aspects have to be considered within conceptual modelling. This also requires basics: - Motivation - examples - Temporal variability of features (move - change of structure or geometry) - Overview on ISO 19108 temporal schema - Examples of modeling temporal aspects,NONE205,DM2-5,Transferring conceptual models to logical models,Conceptual models of course have to be implemented - in general in a GIS (which is often proprietary) - or in a database (which can be standard based)  -therefore here the implementation in a database is treated: - Repetition of conceptual and logical models - Examples of the transferring of a conceptual model to a logical (database) model,NONE206,DM2-6b,Other standards,Metadata is considered as very important for the usage as well for the search for Geodata Relevant basics are: - Motivation - importance of data quality as part of metadata - Metadata in an spatial data infrastructure with many There are quite a number of relevant standards for GI courses. Some are listed here - others might be considered - depending on the background of the course: - Select other standards and explain them - Important are: - ISO 19141 Schema for moving features - ISO 19142 Web Feature Service or others - 19109 - Rules for application schema - Selection of other standards is depending on the background of the course,NONE207,DM2-7,Introduction to GML,GML is the most important standard for the transfer of Geodata as it allows to transfer the schema information as well as the data. Important issues: - Motivation - Importance of a Geography Markup Language - History of GML - Overview 19136 - Geography Markup Language - Relation to spatial schema - Supported features in GML (Topology - 3D ...) - Structure of GNL - profiles - application schemas etc. - Transfer of models and of data - Examples,NONE208,DM2-8,Introduction to CityGML,3D Models - especially 3D city models are becoming more and more important. CityGML is the most important standard within the GI domain to describe City models semantically and geometrically. Relevant issues: - Motivation - Usage of CityGML - Relation to GML - Coherence of semantics and geometry - Principles of modeling - Level of detail concept - CityGML vs KML - Examples,NONE209,DM2,Standards for Spatial Data Modeling,This unit includes the essentials of relevant standards for spatial data modelling. A number of ISO and OGC standards are available for deriving the conceptual model as well as for rules for application schemas - spatial schema provides data types for geometry models in various forms - Point - line - area - body based - temporal schema allows to consider temporal dimensions - Quality principles can be used to describe the quality of geodata - encoding standards (mainly GML) allow the standard based transfer of data and data models - CityGML allows a standard based 3D modelling - etc.,NONE210,DM3-1b,The concept of fields,There are two basic concepts related to this topic: Features and Fields - or Geo-fields - as named by Goodchild at al. The concept of fields can be differently represented as explained here: - Repetition of basic concepts of Geographic Information Science - Explanation of the concept of continuous fields and the commonly used ways of representing geo-fields - Relation between fields and coverages - an important discretizations of a Geo-field - Types of Coverages,NONE211,DM3-2,The raster model,The raster data model holds values in a regularly spaced matrix of cells arranged in rows and columns covering a two dimensional space.  Rasters are commonly used to store continuous data like colors in an image and height values but they are also used for discrete (thematic) values like land use.,NONE212,DM3-2b,Grid representations,Grids are on the one hand one important type of caverages and on the other hand Grids are used as basic structure in some applications. Important here is: - Definition of the concept of grid in GIS - Grid as an instance of coverages - Grids as a basic structure for certain applications / medium for aggregation of data - Examples of grid-based data such as Digital Terrain Models (DTM) - Grids in census / statistical data and Geo-marketing applications,NONE213,DM3-3,Grid compression methods,Grid data models can contain millions of discrete values. This leads to very large datasets. Depending on the way values change over the grid - different methods can be used for an optimal (lossy or lossless) data compression. Type of data - computer power needed - application of the data - method of transport and storage all contribute to the choice of compression method.,NONE214,DM3-3b,TIN and Voronoi tesselations,TINs and Voronoi tessellations are important types of coverages. TINs play a very important role also in Computer graphics. Important here is: - Basics from Graph theory - Definition of Triangulated Irregular Networks (TIN) - purpose and applications - TINs and voronoi diagrams as a type of coverages - One important instance of a TIN: Delauney Triangulation - Definition of Voronoi Diagrams - purpose and applications - Relation between Delauney Triangulation and Voronoi Diagram - the 'Dual Graph' - Examples from applications,NONE215,DM3-4,The hexagonal model,While the classical grid structure uses rectangular cells - the hexagonal data model uses hexagons to represent raster data,NONE216,DM3-4b,Other models like linear referencing,Linear referencing is 1 dimensional positioning. The position of an object is defined by the distance from the object to the start point along a line. Linear referencing is for example used in railway dispatching systems,NONE217,DM3-5b,Resolution and georeferencing system,Resolution of raster and gridded data - Georeferencing of data - direct and indirect methods (t.b.d.),NONE218,DM3-7,Hierarchical data models,In hierarchical  data models data is organized in a tree-like structure. Data are connected with parent-child relations. Hierarchical structures are often used for spatial indexing.,NONE219,DM3,Tessellation data models,This unit includes relevant tessellation data models. Besides features (sometimes also called geo-objects) geo-fields play and important role. In recent literature tessellation models are classified as discretizations of fields. In traditional GI literature tessellations are defined as important data structure itself. Tessellation discretise a continuous surface into a set of non-overlapping polygons that cover the surface without gaps. Tessellation data models represent continuous surfaces with sets of data values that correspond to partitions. Important tessellation models are Grids - TINs and Voronoi diagrams.,NONE220,DM4-1,Feature based modelling,This topic includes the basics for feature based modelling. There are a number of standards also relevant for this topic (see relations). The following items should be included: - Definition of a feature (in some literature also called object - or geoobject) and of feature classes respectively. - Aspects of the definition (ID - geometry - topology - thematic - time etc.) - Techniques for the definition of features / feature classes (mainly link - as they are described elsewhere - see relations),NONE221,DM4-2,Geometric modelling,This topic describes the process of Geometric modelling using vector data - means the primitives like points - lines - areas - bodies - or raster data. There is a strong relation to ISO standards (see relations) as they provide basic data types for geometric modelling. Main issues: - Geometric modeling based on vector data - Geometric modeling based on raster data - Conversion between the models - examples - advantages - disadvantages of the models,NONE222,DM4-3,Topological modelling,In topological modelling the geospatial relations in a data model are represented by the position of geospatial objects - especially nodes - edges and surfaces.,NONE223,DM4-4,Application models based on vector data,This topics deals with the definition of an application schema. There are other units which are important for this topic (see Relations). Issues to be included: - Methods to define and describe an application schema (requirement analysis - description of the schema etc.) - Feature attribute catalogues - Domains / data relevant for INSPIRE,NONE224,DM4-5,Examples of important application models,This Topic deals with important application models - which should be chosen with relation to the course (geographically / related to the background of the course) INSPIRE should be treated in any case. In detail: - Overview on important application models relevant for the course - e.g. from topography or environment in the country - Repetition of the principles of Spatial data infrastructures - Overview on the INSPIRE initiative and the goals related - The INSPIRE data model - The architecture of INSPIRE and the necessary services - Domains / data relevant for INSPIRE,NONE225,DM4-6,Model based interoperability - model transformations,This topic is dedicated to the challenges of model based interoperability and related issues - The principles of interoperability are included in DA3-2. In detail: - The challenges of model interoparability (semantics - different modelling of the same features in different models - syntacs) - Overview on IT concepts for schema integration / transformation - Approaches for model integration - Approaches for model transformations - e.g. related to INSPIRE - from the Humboldt project,NONE226,DM4-7,Network models,Network models are crucial in some application domains - such as Navigation (roads etc.) - but also in utility applications (facilities like pipes etc.) In this topic should be treated: - The network model in the database domain - Graph based NoSQL databases - Topology of network models - Data structures for storing network data - The Dijkstra algorithm - Overview on important applications,NONE227,DM4,Vector data model - Feature based modelling - Applications,This unit includes relevant issues related to vector data models - feature based modelling - applications. Besides imagery data the majority of GI data available is feature based and founded on vector geometry. Topology modeling also is very common nowadays - as many analysis like routing or neighborhood analysis require it. Spaghetti modelling becomes more and more and exception. In every country there are important feature and vector geometry based application models available e.g. in Topography / Cartography. In Europe every GI course should include some information on INSPIRE. As in different application domains different data models are used - sometimes for the same feature types - integration and transformation of models are an important issue also.,NONE228,DM5-1,Basics of uncertainty and its modelling,- Many geographical phenomena are not defined sharply but uncertain Uncertainty has a number of considerations: - Motivation - background - purpose - Conceptual model of uncertainty - Uncertainty of geographic phenomena (vagueness - ambiguity) - Uncertainty of measurements - Uncertainty of analysis - Uncertainty vs. data quality - Statistical models of uncertainty - Outline of Fuzzy approaches,NONE229,DM5-2,Modelling time aspects,Space and time are 2 connected concepts - this topic is dedicated to some basics of modelling time and the temporal dimensions related to features and fields: - Motivation - background - purpose - Changes in time in Entity based and field based representations - A conceptual model of changes in time - Move of objects - Change of structure - Change of geometry - Examples from applications,NONE230,DM5-3,Modelling 3D,Traditionally many GIS used 2D or 2.5 D data models - but in the last decade 3D modeling mainly in form of city models or in the context of Building Information Models (BIM): - Basic concepts of 3D modelling - edge - area - volume models - The workflow of 3D modelling - general aspects - choose of the proper model - Methods of 3D modeling - Principles of Constructive Solid Geometry (CSG) - Principles of Boundary representation (BR) - Principles of Voxel-beased modeling - Comparison of the methods - The concept of BIM - principles and purpose - City models - principles and purpose - Examples / applications,NONE231,DM5,Modelling 3D - temporal and uncertain phenomena,Traditional raster and vector data models cannot easily represent the more complex aspects of geographic information - such as temporal change - uncertainty - three-dimensional phenomena - and integrated multimedia. A variety of models have been proposed to represent these complexities - including both extensions to existing models and software - and entirely new models and software. During the 1990s - work in this area was largely experimental - but many solutions are now available to practitioners in commercial and open source software. The data models in this unit are based on concepts discussed in Knowledge Area CF Conceptual Foundations.,NONE232,DN3-1,Database change,Modification of spatial and attribute data while ensuring consistency within the database - implications of transactions on database integrity - scenarios for periodic changes in GIS database and monitoring the periodic changes.,NONE233,DN3-2,Modeling database change,Rules for modelling spatial database change - techniques for handling version control - techniques for managing long and short transactions - management of spatial databases in multi-user environment,NONE234,DN3-3,Reconciling database change,Reliability tests of change information - design and implementation. Logical consistency of updates.,NONE235,DN3-4,Managing versioned geospatial databases,Needs for versioned databases - queries for change scenarios using DB management tools - algorithms for performing dynamic queries - role of time-criticality and data security while choosing methods for change detection.,NONE236,GC,Geocomputation,The term geocomputation dates back to the first international conference on the topic in 1996 held at the University of Leeds under the title “The art and science of solving complex spatial problems with computers’. The term “geocomputation” was coined to describe the use of computer-intensive methods for knowledge discovery in physical and human geography. This new area distinguishes it  from the application of statistical techniques to spatial data in the focus on “creative and experimental applications” and in “developing relevant geo-tools within the overall context of a ‘scientific’ approach.” Other authors reinforced the unique character of geocomputation as “to provide better solutions to many geographical problems by developing new - computationally dependent tools for analysis and modelling”.  Simply defined - the interdisciplinary area of ​​geocomputation was - from the beginning - closely linked to the application of computer technology and the development of tools and applications to real-world spatio-temporal problems through the combination of geographic information system techniques - spatial modelling - cellular automata - and other non-conventional data clustering and analysis techniques.\rEven though geocomputation is still seeking to define the field conceptually) - it is closely related to computational science - the use of high-computing performance - artificial intelligence - computational intelligence - grid infrastructure and parallel computing . Nevertheless - the evolution of new computing paradigms - such as edge-fog-cloud computing  along with the new forms of data create new opportunities for the geocomputation community .  \r\rWhile the underlying idea remains intact --a diverse and interdisciplinary area of research that uses geospatial data - methods and tools for applied scientific work-- - the current approach to geocomputation differs from the founders in that it focuses more attention on open science - reproducible research practices - and in a vibrant collaborative community to develop new methods - tools and applications that are integrated into multiple application domains such as economics - sociology - geodemography - health - criminology - transportation - biology - remote sensing and cities . The theoretical roots and experimental emphasis of geocomputation makes it an excellent vehicle to creatively explore in parallel the theory and practice of the use of geospatial data in a computational way to solve real-world problems.,REMOTE SENSING237,GC1-1,Complex systems,A complex system can be viewed as a system composed of many interacting parts - with the ability to generate a new collective behaviour through self-organisation - for example - though the spontaneous formation of temporal - spatial or functional structures. Complex systems are therefore adaptive as they evolve and may contain self-driving feedback loops. Most real-world systems such as global climate - an ecosystem - a city - the human brain - and the entire universe - are complex systems. Therefore - complex systems are much more than a sum of their parts.The general characteristics of the structure and dynamics of complex systems have been characterised - including path dependence - positive feedback loops - self-organisation - and emergence. Complex system types include nonlinear systems - chaotic systems - and complex adaptive systems. \rTraditional approaches focus on the individual system components and define a system as the sum of its parts. Whereas the modern approach relies on complexity theory and complex adaptive systems - to emphasise the linkages between system components in order to understand complex systems as a whole.  Agent-based models - for example -  have been highly recommended for studying complex adaptive spatial systems because they support the explicit representation of situation-dependent information for decision making within dynamic spatial environments.,NONE238,GC1-2,Computational science and technology,Computational science is a discipline focused on the design - implementation and use of mathematical models or simulations through the use of computers to analyse scientific problems - systems or processes. Computational science heavily relies on computational technologies such as high performance computing - artificial intelligence - computational intelligence - grid infrastructure and parallel computing. Geocomputation is closely related to computational science and - therefore - geocomputational methods are often derived from machine learning - clustering - simulation - parallel computing and high performance computing. Contrary to the methods and tools applied for spatial analysis described under the Analytical Methods Knowledge Area - geocomputation methods may involve spatial methods available in standard GIS packages - but quite often require self-development -  or at least customisation - involving computational technologies to solve target problems. The aim of this topic is to provide an introduction to computational science with particular emphasis on its  usage and relation to geocomputation.,NONE239,GC1-3,Spatio-temporal problems and applications,While geocomputation is not daily used in GIS environments and traditional GIS projects -  it is the focus of   a vibrant collaborative and research community in developing new geocomputational methods - tools and applications that are integrated into multiple application domains such as economics - sociology - geodemography - health - criminology - transportation - biology - remote sensing and cities. Open science - reproducible research practices - and strong collaboration make geocomputing an excellent vehicle for creatively exploring together the theory and practice of using geospatial data in a computational way to solve real-world problems.,REMOTE SENSING240,GC1-4,Origin of geocomputation,The origin of geocomputation dates back to the first international conference on the topic in 1996  and was coined to describe the use of computer-intensive methods for knowledge discovery in physical and human geography. Geocomputation is closely related to other widely known areas of knowledge within the geospatial community - such as GIScience - Spatial Information Science - GeoInformatics - and Geographic Data Science. While these terms clearly overlap and boundaries are fuzzy - the term geocomputation puts the focus on creative and experimental applications and in developing relevant computationally geospatial tools for analysis and modelling within the overall context of a ‘scientific’ approach. Therefore -  a common interpretation of geocomputation is to describe the application of computational models to geographic problems.,NONE241,GC1,Geocomputation and complex systems,Geocomputation represents an attempt to move the geospatial  research agenda back to geographical analysis and modelling by providing a toolbox of methods to analyse and model a range of highly complex - often non-deterministic problems. In this context -  complex systems and computational science are foundational aspects upon which geocomputation approaches and methods are built to address a variety of real-world - spatio-temporal issues,NONE242,GC2-1,Principles of computer simulation,Building a model that mimics a real-world system generally follows a series of stages: from conceptual models to mathematical models and - finally - simulation models. In model development - system analysis is a process whereby a real-world system is simplified by dividing it into simpler - more manageable parts. A conceptual model captures the components - variables and interactions of a system - and provides a useful way of thinking about the trade-offs between abstraction and representativeness of real-world phenomena. Taken in isolation - however - the interacting parts of a system fail to explain its dynamics behavior. A conceptual model is then translated into a mathematical model to explain system dynamics and interaction. Mathematical models often take the form of equations -  logical rules or other mathematical mechanisms to represent the interrelations and relationships among the constituted parts of a system. Lastly - a simulation model is the computer-based implementation of mathematical models consisting of interrelated equations and logical rules. When a simulation model runs on a computer - it iteratively recalculates the modelled system state as it changes over time in accordance with the relationships represented by the mathematical relationships that describe the system dynamic. Therefore - developing detailed and dynamic simulation models comes at the cost of generality and interpretability - but it brings us realism and the ability to represent real-world processes in specific contexts. Simulation modelling is often used for prediction - exploration - theory development - or even optimization of conditions to achieve desired outcomes - with the goal of examining how the interconnections and relationships that characterise complex social and environmental systems (e.g. ecosystems - urban systems - social systems - global climate system) produces patterns of behavior over time. Therefore - simulation models are increasingly gaining relevance as scientific mechanisms for several reasons. First - simulation models allow researchers to study systems inaccessible to experimental and observational scientific methods - complementing more conventional approaches to discover or formalize theories about real world systems. Also - aS many real-world systems are nonlinear - simulation modelling has turned into a necessary method to explore and understand better such systems. In addition - the availability of computational science methods and technology - together with a large amount of data available from different sources - have greatly driven the adoption of simulation models in a wide range of scientific disciplines.,NONE243,GC2-3,Rule-based models,Rule-based models are based on logic programming with condition-action expressions - where the left side of the expressions consists of several conditions that returns a logical result - and the right side consists of several actions. Rules in rule-based models indirectly specify a mathematical model. However - unlike equation-based models which refer to the overall or aggregate behaviour of a system - rule-based models focus on the behaviour of the individual components of a system. That’s why the implementation of rule-based models is most often done by cellular automata models or agent-based models - in which the aggregate behaviour of the system emerges from the interaction of the individual agents or cells over time. Many geographic patterns and dynamics are formed by systems of interacting actors/cells with heterogeneous characteristics and behaviours - in which such dynamic behaviours can be implemented as rules. The aim of this topic is to provide knowledge about rule based models and to understand their advantages and disadvantages.,NONE244,GC2-4,Equation-based models,Equation-based models are a set of interrelated equations that capture the variability of a system over time (differential equations) - and the execution (simulation) of the model means to evaluate such equations. Equation-based models do not aim at representing the behaviour of the individual components in a system. Rather - they focus on the overall or aggregate behaviour of a system. Therefore -   equation-based models are well suited to represent physical processes and some topics within natural sciences - where the system to some degree can be described by physical laws. Hydrological modelling is a good example of models based on equations. However - other real-world systems  can rarely be fully described by the laws of the natural sciences - and their behavior and interrelation must  be represented by means of other types of mathematical mechanisms. The aim of this topic is to present the advantages and challenges in using equation-based simulation models - which are most naturally applied to systems centrally governed by physical laws rather than by information processing and flow.,NONE245,GC2-5,Space-time dynamics,Space-time dynamics are closely related to the concepts of change and process - which are inherent to our dynamic world. Space-time dynamics especially manifest when we move from a static representation to a dynamic representation of phenomena. Various processes that take place at different spatial and temporal scales interact with each other and lead to complex changes to the phenomena being modeled. There exist many different approaches of conceptualizing and understanding space-time dynamics in order to understand or predict phenomena in heterogeneous application domains ranging from human activities and urban sprawl to disease spread and traffic flow.,NONE246,GC2-6,Cellular automata,Cellular automata are a standard type of spatially explicit simulation model in which complex processes are modelled over space and time by means of a lattice of cells in which each cell defines its neighbouring cells. The spatial lattice composed of a two-dimensional grid of squared cells  is the simple configuration of a cellular automata. Based on this regular configuration - each cell has associated a set of states that change at each iteration by the execution of transition rules - which take into account the state of each cell and those of its neighbours. As such - cellular automata consist of six defining components: a framework or lattice - cells - neighborhood - transition rules - initial conditions (states) - and an update sequence (time). Cellular automata models map easily onto existing data structures widely used in geographic information systems - are easy to implement - and are able to show changes and spatial patterns in an understandable manner. All of this has contributed to their popularity in simulation modelling for applications such as measuring land use changes and monitoring disease spread,NONE247,GC2-7,Agent-based modelling,Agent-based models are simulation models that decompose a complex system into small entities (agents) with modeling properties and behavior. Contrary to modelling at an aggregate level - agent-based models are focused on the individual level - where a set of discrete agents with well-defined behaviors represents an individual - object or component of the modelled system. Therefore - the individual agent is the explicit - basic unit. The macro-level behaviour of the system emerges thereafter from the interaction of the individual agents and with the environment over time. Agent-based models are used for spatial modelling - offering possibilities to consider topological particularities of interaction and information transfer among agents and/or with the environment. In relation to spatial simulation - agent-based models have been used for example to model natural and social phenomena such as animal behaviour - pedestrian behavior - social insects and biological cells.,NONE248,GC2,Spatial simulation modelling,The concept spatial simulation modelling can be better understood by looking at the meaning of its individual words. A model is widely defined as a simplified representation of a real-world system under study - which can be used to explore or to better understand the system it represents. Computer models or simulation models are computer-based implementations of a model to produce outputs based on certain model assumptions. Simulation  - therefore - relies on the use of computers for virtual experimentation to gain insight into real-world problems by proposing alternative assumptions that arise from exploring “what if” questions about a dynamic problem of interest over the course of successive simulation experiments.\rSimulation modelling is also useful for the study of spatial patterns over time. Spatial simulation models are relevant when the study of spatial elements and their relationships in a system are necessary for a fully understanding of that system. In this sense - spatial simulation modelling approaches include rule-based models - equation-based models - grid-based cellular automata models - discrete event simulation - and agent-based models.\rSimulation modelling is often used for prediction - exploration - theory development - or even optimization of conditions to achieve desired outcomes - with the goal of examining how the interconnections and relationships that characterize these systems produces patterns of behavior over time. Across broad areas of the environmental and social sciences - researchers use simulation models as a way to study systems inaccessible to experimental and observational scientific methods - and also as an essential complement of those more conventional approaches to discover or formalize theories about the real world. \rSimulation models are a relatively recent addition to the scientific toolbox - and the reasons for their widespread adoption are - on one hand - the impossibility to study in-situ some complex social and environmental systems (e.g. ecosystems - urban systems - social systems - global climate system) and - on the other hand - the availability of  High Performance Computing and large amount of data from different sources. Finally - the nonlinear behaviour of many natural systems provides challenges building traditional mathematical models based on linearization.   \rSimulation modelling is also useful for the study of spatial patterns over time. In this sense - spatial simulation modelling approaches include rule-based models - equation-based models - grid-based cellular automata models - discrete event simulation - and agent-based models.,NONE249,GC3-1,Heuristics,Among the recent artificial intelligence techniques are those pertaining to heuristics. A heuristic technique is an approach to problem solving - that employs a practical method - which is necessarily not optimal or perfect - but in many situations sufficient. Heuristic methods can be useful - where the optimal solution in practice is impossible. The aim of the topic is to provide insight into the principles of heuristics and the most important algorithms.,NONE250,GC3-2,Genetic algorithms,Genetic algorithms - genetic programming and evolutionary computing are terms that fall within the general sphere of `Evolutionary Computation`. Genetic algorithms (GAs) are computationally intensive global search heuristics with very wide applicability - but their implementation is often highly problem specific and there is only a relatively loose understanding as to why they often work rather well. The central idea behind GAs is to mimic the Darwinian notion that selective breeding seeks optimum individuals in a given environment. In order to do this a GA requires a way of representing a solution to a (spatial) problem as if it were an individual viewed as a chromosome or `genome` like object. The aim of the topic is to provide fundamental understanding of the principles behind genetic algorithms - and its application in solving geospatial problems.,NONE251,GC3-3,Artificial Neural Networks,Biological neurons - or nerve cells - receive multiple input stimuli - combine and modify the inputs in some way - and then transmit the result to other neurons. Artificial neural networks are an attempt to emulate features of biological neural networks in order to address a range of difficult information processing - analysis and modelling problems. The principal class of ANNs are so-called feed-forward networks - but other types of ANN are for example recurrent neural networks. Among the feed-forward networks the most widely used approach is the multi-level perceptron (MLP) model. The application range is broad from non-linear regression to land cover change modelling. The aim of the topic is to introduce the principles of ANN and to understand and demonstrate its use in geospatial modelling.,NONE252,GC3-4,Pattern recognition,Pattern recognition is the process of classifying input data into objects or classes based on key features. There are two classification methods in pattern recognition: supervised and unsupervised classification. The supervised classification of input data in the pattern recognition method uses supervised learning algorithms that create classifiers based on training data from different object classes. The classifier then accepts input data and assigns the appropriate object or class label. The unsupervised classification method works by finding hidden structures in unlabelled data using segmentation or clustering techniques. Common unsupervised classification methods include: K-means clustering - Gaussian mixture models - Hidden Markov models. The aim of the topic is to provide knowledge about the different methods in pattern recognition and how to choose the optimum method for a specific spatial problem.,NONE253,GC3-5,Spatio-temporal knowledge discovery,Understanding natural and human-induced structures and processes in space and time has long been the agenda of geographical research. Through theoretical and experimental studies - geographers have accumulated a wealth of knowledge about our physical and man-made world over the years. Knowledge is often discovered through critical observations of phenomena in space and time. Due to the rapidly expanding amount of data and information the problem is often not having enough data but having too much and too complex a database. The aim of the topic is to provide insight into several methods to carry out spatio-temporal knowledge discovery through spatial data mining and clustering techniques.,NONE254,GC3-6,Big data filtering,Data-intensive computing is now starting to be considered as the basis for a new - fourth paradigm for science. Two factors are encouraging this trend. First - vast amounts of data are becoming available in more and more application areas. Second - the infrastructures allowing to persistently store these data for sharing and processing are becoming a reality. The technical and scientific issues related to this context have been designated as `Big Data` challenges and have been identified as highly strategic by major research agencies. The aim of this topic is to introduce Big Data as a concept - and the needed methods to navigate through the vast amount of heterogeneous information.,NONE255,GC3,Artificial Intelligence and Data Mining,The amount of data in current geospatial repositories along with their high-dimensional nature requires a sophisticated set of analysis capabilities in order to extract new and unexpected patterns - trends - and relationships embedded in that data. Artificial intelligence and data mining methods constitute an alternative to explore and extract knowledge from geospatial data - which is less assumption dependent. Data Mining is a step in the knowledge discovery process that automatically detects patterns in data - and Geographic Data Mining is a special type of data mining that seeks to apply standard data mining tools modified to take into account the special features of geospatial data,NONE256,GC4-1,Open Geocomputation,The use of the term Open geocomputation doesn't intend to coin a new term; Open GIScience and Open GIS are well explored and discussed terms in the literature. Both embrace the idea of open data - open source - collaboration among peers - and the integration of these practices into GIS research projects - tools - services and applications. Open geocomputation brings the ideas of Open GIScience (and hence Open Science in general) into geocomputation - focussing on openness as a fundamental tenet to conduct research in geocomputation and for the development of new computational methods and tools. In fact - many community-led developments and tools have recently appeared in the field of geocomputation - notably based on R and Python. The widespread popularity and adoption of these computing environments for geocomputing and geospatial analysis is simply because they encompass open - transparent - and reproducible tool development.,NONE257,GC4,Open Science,A distinguible feature of the current approach to geocomputation is the emphasis on openness: open science - open source - open data. All of this propelled by a vibrant collaborative community with the aim to develop open and reproducible methods - tools and applications applied to a variety of real-life - spatio-temporal application domains. Open Science is a paradigm that can be applied to any scientific discipline and area of ​​knowledge - characterised by openness - access to large volumes of data and unprecedented levels of computing power - availability of community-driven tools - and new types of collaboration between multidisciplinary researchers. Open Science clearly goes beyond geocomputation - but at the same time - its practices and principles characterise recent geocomputation-related projects as well as its community. Therefore - the vision of Open Science taken here is contextualised to the field of geocomputation.,NONE258,GD,Geospatial Data,Geospatial data represent measurements of the locations and attributes of phenomena at or near Earth`s surface. Information is data made meaningful in the context of a question or problem. Information is rendered from data by analytical methods. Information quality and value depends to a large extent on the quality and currency of data (though historical data are valuable for many applications). Geospatial data may have spatial - temporal - and attribute (descriptive) components - as well as associated metadata. Data may be acquired from primary or secondary data sources. Examples of primary data sources include surveying - remote sensing (including aerial and satellite imaging) - the global positioning system (GPS) - work logs (e.g. - police traffic crash reports) - environmental monitoring stations - and field surveys. Secondary geospatial or geospatial-temporal data can be acquired by digitizing and scanning analog maps - as well as from other sources - such as governmental agencies. The legitimacy of geographic information science as a discrete field has been claimed in terms of the unique properties of geospatial data. In a paper in which he coined the term GIScience - Goodchild (1992) identified several such properties - including: 1. Geospatial data represent spatial locations and non-spatial attributes measured at certain times. 2. The Earth`s surface is highly complex in shape and continuous in extent. 3. Geospatial data tend to be spatially autocorrelated. It has long been said that data account for the largest portion of geospatial project costs. While this maxim remains true for many projects - practitioners and their clients now can reasonably expect certain kinds of data to be freely or cheaply available via the World Wide Web. Federal - state - regional - and local government agencies - as well as commercial geospatial data producers - operate clearinghouses that provide access to geospatial data. Although geospatial data are much more abundant now than they were ten years ago - data quality issues persist. Good data are expensive to produce and to maintain. Proprietary interests simultaneously increase the supply of geospatial data and impede data accessibility. Standards for geospatial data and metadata are useful in facilitating effective search - retrieval - evaluation - integration with existing data - and appropriate uses. National and international organizations - such as the Open Geospatial Consortium (OGC) and International Organization for Standardization (ISO) - develop and promulgate such standards. INSPIRE directive (Infrastructure for Spatial Information in the European Community) regulates geospatial data management,REMOTE SENSING259,GD1-1,Earth geometry,Usable and accurate geospatial data are based upon proper model of the Earth`s surface. Shape of the Earth is complex and complicated to measure. Approximations are used to minimize complexity of the task and possible errors.,NONE260,GD1-2,Georeferencing systems,Geospatial referencing systems provide unique codes for every location on the surface of the Earth (or other celestial bodies). These codes are used to measure distances - areas - and volumes - to navigate - and to predict how and where phenomena on the Earths surface may move - spread - or contract. Point-based - vector coordinate systems specify locations in relation to the origins of planar or spherical grids. Tessellated referencing systems specify locations hierarchically - as sequences of numbers that represent smaller and smaller subdivisions of two- or three dimensional surfaces that approximate the Earths shape - Linear referencing systems specify locations in relation to distances along a path from a starting point. Tessellation data models - are considered in Unit DM3 Tessellation data models - and linear referencing models are considered in Unit DM4 Vector data models.,NONE261,GD1-3,Datums,Horizontal datums determine the geometric relations between a coordinate system grid and a particular ellipsoid approximating the Earth`s surface. Vertical datums determine elevation reference surfaces - like mean sea level. A. Horizontal datums. Relation of coordinate system to particular ellipsoid - datum transformation options - Molodensky and Helmert transformation - other high accuracy transformations - ED50 and WGS84 - historical development of horizontal datums - ETRS89. B. Vertical datums. Historical development of vertical datums - difference between vertical datum and geoid - relations between ellipsoidal (geodetic) heiht - geoidal height and orthometric elevation.,NONE262,GD1-4,Map projections,Map projections are systematic transformations of geographic coordinates of the surface of ellipsoid into locations in plane. Plane coordinates are based on map projection. As the transformation of a spherical grid into a plane grid causes inevitably distortions of the geometry - and - different projections cause different distortions - knowledgeable choice of appropriate projection for any particular use is crucial. A. Map projection poperties. Geometric properties that may be preserved or lost in projected grid - usefulness of compromise projection - Tissot indicatrix as an indicator of projection errors - visual appearance of the Earth`s graticule - distortion patterns for projection classes - distortions in raster data. B. Map projection classes. Three main classes of map projection based on developable surface - projection types by geometric properties preserved - mathematical basis of projecting longitude and latitude into x and y coordinates. UTM - ETM - projections used by EC. C. Map projection parameters. Standard line - projection case - latitutde and longitude of origin - aspects of projection. D. Georegistration. Rectification vs orthorectification - ground controle points in georegistration of aerial imagery.,NONE263,GD1,Geolocating Data to Earth,Proper model of the Earth`s surface and ability to locate spatial phenomena accurately to it - is crucial in effective collection - management and use of data. Characterising size and shape of the Earth - using appropriate surfaces to approximate it - choosing suitable coordinate system and map projection is bases for efficient understanding of spatial data.,NONE264,GD10-4,Stereoscopy and orthoimagery,A stereoscopy acquisition mode collects remotely sensed data where each location on the ground (or the imaged objects) is covered multiple times (at least twice) - from different perspectives. Stereopairs and stereoscopic coverage enable the extraction of 3D representations of the environment from remotely sensed imagery.,NONE265,GD10,Aerial imaging and photogrammetry,Since the 1940s aerial imagery has been the primary source of detailed geospatial data for extensive study areas. Photogrammetry is the profession concerned with producing precise measurements from aerial imagery. Aerial imaging and photogrammetry comprise a major component of the geospatial industry. The topics included in this unit do not comprise an exhaustive treatment of photogrammetry - but they are aspects of the field about which all geospatial professionals should be knowledgeable.,NONE266,GD11-2,Platforms and sensors,the physical environment to sense data without direct contact. It contains a carrier device (platform) and a sampling unit (sensor).,NONE267,GD11,Satellite and shipboard remote sensing,Satellite-based sensors enable frequent mapping and analysis of very large areas. Many sensing instruments are able to measure electromagnetic energy at multiple wavelengths - including those beyond the visible band. Satellite remote sensing is a key source for regional- and global-scale land use and land cover mapping - environmental resource management - mineral exploration - and global change research. Shipboard sensors employ acoustic energy to determine seafloor depth or to create imagery of the seafloor or water column. The topics included in this unit do not comprise an exhaustive treatment of remote sensing - but they are aspects of the field about which all geospatial professionals should be knowledgeable.,REMOTE SENSING268,GD12,Metadata - standards - and infrastructures,Meaning of geospatial metadata - elements of metadata - use of metadata - integration of metadata in data production - standards in geospatial data - ISO standard family 191xx - data warehouse - exchange protocol - transport protocols - spatial data infrastructure - INSPIRE - OGC - DCAT profiles for CKAN applications   bridging metadata from GI and IT domains.,NONE269,GD2-1,Land surveying and field data collection,Classic land survey methods and manual attribute data collection in the field,NONE270,GD2-2,Remote sensing,Aerial imagery has been the primary source of detailed geospatial data for extensive study areas. Photogrammetry is producing precise measurements from aerial imagery. Aerial imaging and photogrammetry comprise a major component of the geospatial data production. Satellite-based sensors enable frequent mapping and analysis of very large areas. Sensing instruments are able to measure electromagnetic energy at multiple wavelengths. Satellite remote sensing is a key source for regional- and global-scale land use and land cover mapping - environmental resource management - mineral exploration - and global change research. Shipboard sensors employ acoustic energy to determine seafloor depth or to create imagery of the seafloor or water column. Principles of aerial photography - oblique and vertical imagery - spatial and radiometric resolution - spectral sensitivity - principal point - distortions and displacements in aerial image - parallax - stereophotogrammetry - generation of an orthoimage from a vertical aerial phoptograph - aerotriangulation - vector data extraction from digital seteroimagery - mission planning. Use of UAV in photogrammetry. Main platforms and sensors in spatial image acquisition - active and passive sensors - LiDAR and microwave - multispectral and hypersepctral imagery - interpretation of imagery - supervised and unsupervised classification - pixel based and segmented classification - ground verification - main applications - bathymetric mapping. SENTINEL.,REMOTE SENSING271,GD2-3,Crowdsourced data collection,Crowdsourcing is the practice of obtaining needed services - ideas - or content by soliciting contributions from a large group of people and especially from the online community rather than from traditional employees or suppliers. Crowdsourced spatial data collection is becoming more and more important. The advantages and disadvantages of crowdsourced data - opensource mapping tools - potential application of crowdsourcing - VGI - OSM or cell-phone based - aspects of crowdsourced data quality and reliabilty.,NONE272,GD2-4,Digitizing,Digitizing as the main secondary spatial data production technique. Encoding vector points - lines - and polygons by tracing map sheets has diminished in importance - but remains a useful technique for incorporating historical geographies and local knowledge. 'Heads-up' digitizing using digital imagery as a backdrop on-screen is a standard technique for editing and updating GIS databases. Tablet and on-screen digitizing - scanning and (semi)automatic vectorization.,NONE273,GD2,Data Collection,Spatial data collection / production involves measurement of locations in relation to the coordinate system - and collection of attributed data about the spatial phenomena. Measurements may be direct (e.g. surveying) or remote - data acquisition involves measurement of parameter values - evaluation of parameters - polls - interpretation of spatial imagery - and re-use of secondary data (e.g. old maps). Volunteered geographic information is becoming more important.,NONE274,GD3,Transaction management of geospatial data,It is quite common - that data including both spatial entities and their attribute data undergo changes. These changes need to be catalogued fully and explicitly - including initial conditions - new conditions - all intermediate stages and operations used. The geospatial data needs to contain an archival history of change.,NONE275,GD4-1,Data quality,Geometric accuracy - factors influencing it - geometric accuracy and topological fidelity - geometric accuracy in survey and GPS mesurements - thematic accuracy - relations between thematic accuracy - geometric accuracy and topological fidelity - misclassification matrix - commission and omission - logical consistency - relations between resolution - precision - and accuracy - spatial resolution - thematic resolution - and temporal resolution - precision - uncertainties associated with coordinate precision - primary and secondary data sources.\r\rParticular application. That standard varies from one application to another. In general - however - the key criteria are how much uncertainty is present in a data set and how much is acceptable. Judgments about fitness for use may be more difficult when data are acquired from secondary rather than primary sources. Aspects of data quality include accuracy - resolution - and precision. Concepts of data quality - error - and uncertainty are also covered in Knowledge Areas CF Conceptual Foundations (in a theoretical context) and GC Geocomputation (in the context of analysis); the focus here is on the measurement and assessment of data quality.,NONE276,GD4,Data Quality - Metadata and Data Infrastructure,Data quality is the degree of data usability in relation to given objective and particular application. The expectations to data vary between different applications. The key criteria in data quality are the amount of uncertainty in data as compared to the acceptable level of uncertainty. Evaluation of the usability may be more complicated using data from secondary sources. Appropriate metadata is inevitable for these judgements. Aspects of data quality include geometric and thematic accuracy - (in)consistencies - resolution - precision - usability and others. Assurance of data quality may be improved by following proper standards and spatial data infrastructure   regulations for data collection and management. System of basic data quality measures for geospatial domain in the EN ISO 19157:2013 standard.,NONE277,GD6-1,Geometric accuracy,Geometric accuracy is a measure indicating how close the geometric values of the data are to the real world position of the mapped feature.,NONE278,GD6-2,Thematic accuracy,Thematic accuracy evaluates the correctness of attribute values of geospatial objects compared to the expected (real world) reference value,NONE279,GD6-3,Resolution,The resolution of a data source indicates the smallest unit of detail provided by the data source.,NONE280,GD6-4,Precision,The precision of a measurement system - related to reproducibility and repeatability - is the degree to which repeated measurements under unchanged conditions show the same results.,NONE281,GD6-5,Primary and secondary sources,Primary data sources provide information collected directly for GIS use. Secondary sources are data sources that need to be processed before they are ready for GIS use.,NONE282,GD8-1,Tablet digitizing,Tablet digitizing is the conversion from physical map to digital data by re-drawing the features on the map fixed on a digitizing tablet,NONE283,GD8-2,On-screen digitizing,On-screen digitizing is the conversion from raster to vector data by manually drawing the features visible in the raster file on the screen.,NONE284,GD8-3,Scanning and automated vectorization techniques,Scanning is the conversion of a physical object to a digital representation by moving a sensor over it. Vectorization is the technique to extract features from the grid information in vector format,NONE285,GS,GI and Society,Geographic Information Science and Technology serve the society - but it is not a panacea. The history of its development is the sum of fragmented efforts - which have still not been fully integrated. Its potential benefits are often constrained and its potential impacts are not fully understood. Institutional and economic factors limit access to data - technology - and expertise by some of those who need it to make better decisions. Political - ideological - and personal issues aside - organizations invest in GIS&T when estimated benefits outweigh estimated costs. Evaluating costs and benefits is difficult - however and too often leads to nothing being done. For some individuals and groups - costs are prohibitive even though potential benefits are compelling. The legal framework provides a structure for regulating a number of key aspects of geographic information science - technology - and applications. Legal regimes determine who can claim the exclusive right to hold and use geospatial data - the conditions under which others may have access to the data - and what subsequent uses are permitted. Political struggles arise from conflicting proprietary and public interests about who benefits from geospatial information - and how the power to allocate the use of this information is - or should be - distributed among members of a society. The need to choose among conflicting interests sometimes poses ethical dilemmas for GIS&T professionals. The explosive growth of the geospatial information contributed by users through various application programming interfaces has made geospatial information is a powerful tool in the social media toola powerful media for the general public to communicate - but perhaps more importantly - geographic information have also become a tool media for constructive dialogs and interactions about social issues - recent growth of Web-based geospatial information and volunteered geographic information (VGI). Because so many public agencies and private organizations rely upon GIS&T for planning - decision making - and management - GIS&T increasingly affects and is used to direct daily life. Critical approaches to understanding the role of GIS in society equip practitioners to employ GIS&T reflectively. The critical approach specifically questions the assumptions and premises that underlie the economic - legal and political regimes and institutional structures within which GIS&T is implemented. Related concerns are considered in Knowledge Area OI: Organizational and Institutional Aspects.,NONE286,GS1-1,The legal regime and legal framework,The most basic definition of a legal regime is a system or framework of rules governing some physical territory or discrete realm of action that is at least in principle rooted in some sort of law. Often the concept has been applied to specific areas of law.,NONE287,GS1-2,Contract law - liability and licensing,Contract law is defined as a set of rules that govern the contractual agreements between merchants or persons. A contract is an agreement between different parties that state their responsibilities and duties to each other. A liability in contract law is when certain conditions are written into a contract that makes a party liable. Licensing is the process of giving or getting official permission to do something. A license is an agreement through which a licensee leases the rights to a legally protected piece of intellectual property from a licensor — the entity which owns or represents the property — for use in conjunction with a product or service.,NONE288,GS1-3,Privacy and Security,Data privacy and security are two essential components of a successful strategy for data protection. Data security refers to the protection of data from unauthorized access - use - change - disclosure - and destruction. It encompasses network security - physical security - and file security. Data privacy involves protecting consumer data by eliminating or reducing the possibility of re-identifying an individual whose information is present in the data. This is done by either removing specific information or by transforming the data with random “noise” or generalization.,NONE289,GS1-4,Ownership and property rights,Property is secured by laws that are clearly defined and enforced by the state. These laws define ownership and any associated benefits that come with holding the property. The term property is very expansive - though the legal protection for certain kinds of property varies between jurisdictions. Property is generally owned by individuals or a small group of people. The rights of property ownership can be extended by using patents and copyrights. Property rights give the owner or right holder the ability to do with the property what they choose. That includes holding on to it - selling or renting it out for profit - or transferring it to another party.,NONE290,GS1-5,Competition and public-private sector relationships,In economics - competition is a condition where different economic firms seek to obtain a share of a limited good by varying the elements of the marketing mix: price - product - promotion and place. Competition law is a law that promotes or seeks to maintain market competition by regulating anti-competitive conduct by companies. Public-private sector relationships deal with a particular subset of competition - i.e. competition between public and private organizations.,NONE291,GS1-6,Open data,Open data is data that can be accessed - shared - used and reused without any barrier for any type of (re)user. According to the Open Definition - open data can be defined as data that be freely used - modified - and shared by anyone for any purpose subject - at most - to measures that preserve provenance and openness. Open data requires datasets to be either in the public domain - or distributed through an open license. The data must be provided as a whole - free of charge - and preferably downloadable via the Internet - including any additional information that might be  necessary to comply with the open license’s terms. Openness requires the data to be provided in a readily machine-readable form. The format must be open as well - meaning that it does not place any restriction upon its use - and that the files in that format can be processed with open-source software tools. The Open Definition speaks broadly of open ‘works’ - rather than of open data. Focusing on data tout court - one can move from the Open Government Data (OGD) principles. According to the OGD principles - which are arguably foundational in understanding the concept of open data - data must be: Complete;  Primary; Timely; Accessible; Machine-processable; Non-discriminatory; Non-proprietary; and License-free. Compliance with the OGD principles needs to be demonstrable - i.e. there need to be accountability measures in place to allow the review of the adherence to the principles above. The concepts of Open Work and open data highlight how data needs to be both legally - technically and financially open - so either in the public domain or covered by an open license - and kept in a machine-readable and non-proprietary format. Open data aims at making information available to everybody - for any purpose - in a machine-readable and interoperable format - based on open standards and digestible by free/libre open source software (FLOSS). Also with respect to the financial accessibility open data is data available free of charge. Marginal costs of dissemination are accepted by some as a reasonable cost for users. However - open data is data that can be accessed and reused without any barrier for any type of reuse - and some user groups experience any price to be paid as a barrier.,NONE292,GS1,Legal aspects,Legal problems can arise when geospatial information is used for land management - among other activities. Geospatial professionals may be liable for harm that results from flawed data or the misuse of data. Understanding of contract law and liability standards is essential to mitigate risks associated with the provision of geospatial information products and services. Legal relations between public and private organizations and individuals govern data access. The nature of information in general - and the characteristics of geospatial information in particular - make it an unusual and difficult subject for a legal regime that seeks to establish and enforce the type of exclusive control associated with other commodities. Geospatial information is in many ways unlike the kinds of works that intellectual property rights were intended to protect. Still - organizations can - and do - assert proprietary interests in geospatial information. Perspectives on geospatial information as property vary between the public and private sectors and between different countries.,NONE293,GS2-1,GI Business models,Business models determine how organizations can create and deliver value - for example - through the provision or use of geographic data. A business model is a conceptual tool that contains\ra set of interrelated elements that allow organizations to create and capture value and generate revenues. The development and implementation of an appropriate business model are considered to be a key to the success of the organization and a crucial source for value creation. \r\rAlthough business models determine how organizations create - deliver - and capture value - they should not be regarded as permanent and invariable structures or settings. Business models are shaped by both internal and external forces - and will only be successful if they are able to adapt to a changing environment. In the GI domain - several technological - regulatory - and societal developments have challenged the existing business models and opened up opportunities for new business models. Among these developments are the establishment of spatial data infrastructures (SDIs) worldwide - the democratization of geographic knowledge - and the move toward open source - open standards - and open data.\r\rSince the development and implementation of SDIs in different parts of the world - much attention has been paid to the need to find appropriate business models for GI - and in particular - for geographic data providers in the public sector. Traditional business models in which public data providers were selling their data to customers in the private industry and other public agencies were questioned - because they restricted the opportunity for data sharing. The concept of SDI is about moving to new business models - where partnerships between GI organizations are promoted to allow access to a much wider scope of geographic data and services. A key challenge in the development of these SDIs was the alignment of different existing business models of the actors in the GI domain. Moreover - the development and implementation of SDIs also led to the emergence of new business models - which was even more the case with the more recent move toward open geographic data.\r\rOrganizations can be active in different parts of the geo-information value chain - and can create and offer value in many different ways. As a result - many different GI business models exist. Data providers - data enablers - and data end users could be seen as three main categories of GI business models. Each of these categories consists of many different business models - as different value propositions\rwill exist - and value can be created and captured in several ways.,NONE294,GS2-5,Geo-information value chain,To provide a better insight into the process of adding value to GI - several authors have introduced and applied the information value chain approach. A value chain can be defined as the set of value-adding activities that one or more organizations perform in creating and distributing goods and services. The value chain concept originally was developed for the manufacturing sector - as a tool to evaluate the competitive advantage of firms. More recently - the value chain concept has been applied to other sectors - including information technology where the good or service - and the benefits it provides - is less tangible in nature. A value chain involves the progress of goods from raw materials to finished products through a number of stages - during each of which a new value is added to the original input by various activities. The value chain concept was extended into the information market - with the information value chain referring to the set of activities adding value to information and turning raw data into new information products or services. Especially important in this context is the role of information and communication technologies (ICT) - which have an impact on all activities in the information value chain - such as information collection - processing - dissemination - and use. In the context of GI - the value chain relates to the series of value- adding activities to transform raw geographic data into new products that are used by certain end users. Although there are slightly different descriptions of the various steps of the GI value chain - in general - the essential steps in the value chain are: acquisition of raw data - the application of a data model - quality control - and integration with other sources - presentation - and distribution. In recent years - particular attention has been paid to different steps between the process of distributing data and the actual end use of an end product of GI. In addition - after the publication of the data - value can be added to the data in many different ways. Value can be added by making data from different sources easily accessible through repositories and data portals - by building and selling tailored solutions using the data to end users or by using geographic data to improve existing products and services delivered to an end user. In certain cases - this end product will be the first step of a next value chain.,NONE295,GS2,Economic aspects,Most organizations insist that investments in GIS and T be justified in economic terms. Quantifying the value of information - and of information systems - however - is not a straightforward matter.,NONE296,GS3-1,Use of geospatial information in the public sector,The use of geospatial information allows public sector organizations and actors to make better decisions and provide better services to their citizens. Geospatial information is increasingly being used at different administrative levels and in different policy areas.,NONE297,GS3-2,Use of geospatial information in the private sector,Geospatial information is increasingly being used by private companies for different purposes and the private sector plays an important role in the development and implementation of geospatial information infrastructures.,NONE298,GS3-3,Use of geospatial information in research and education,Research and education institutions use geospatial information for various purposes - in support of their research and educational activities.,NONE299,GS3-4,Use of geospatial information in environmental issues,Effective monitoring of the environment and an improved understanding of the same requires valuable information and data that can be extracted through application of geospatial technologies.  GIS can be used most effectively for environmental data analysis and planning. It allows better viewing and understanding physical features and the relationships that influence in a given critical environmental condition. GIS can help in effective planning and managing the environmental hazards and risks. In order to plan and monitor the environmental problems - the assessment of hazards and risks becomes the foundation for planning decisions and for mitigation activities. GIS supports activities in environmental assessment - monitoring - and mitigation and can also be used for generating environmental models. GIS can aid in hazard mitigation and future planning - air pollution & control - disaster management - forest fires management - managing natural resources - wastewater management - oil spills and its remedial actions etc.,NONE300,GS3,Use of geospatial information,Geospatial Information used in Government agencies and public authorities at local - state - and federal levels produce and use geospatial data for many activities - including provision of social services - public safety - economic development - environmental management - and national defence. Public participation in governing - empowered by geospatial technologies - offers the potential to strengthen democratic societies by involving grassroots community organizations and by engaging local knowledge. The private sector covers a broad range of areas of opportunity. With continued advancements in technology - greater awareness of its advantages as a powerful decision support tool the use of geospatial information use in the private sector needs to be discussed.,NONE301,GS4-1,Public participation GIS,Public participation GIS (PPGIS) is a field within geographic information science that focuses on ways the public uses various forms of geospatial technologies to participate in public processes - such as mapping and decision making.,NONE302,GS4-2b,Social Media Geographic Information,Social Media Geographic Information (SMGI) can be defined as any piece or collection of multimedia data or information with explicit (i.e. coordinates) or implicit (i.e. place names or toponyms) geographic reference collected through the social networking web or mobile applications. Social data are acknowledged as a good of major value in the digital economy - and their potential for enhancing more traditional analytics is of the utmost importance. A big part of social data however also features spatial (and temporal) references - thus their integration with more traditional Authoritative Geographic Information (AGI) may enable a further step towards the next generation of geospatial intelligence. SMGI is a sub-category of VGI and can be active or passive - depending on the type of application with which it is collected: applications purposefully created and/or used to collect SMGI in participatory initiatives,NONE303,GS4-3b,Citizens and volunteered geographic information,Volunteered geographic information (VGI) is a special kind of user-generated content. It refers to geographic information collected and shared voluntarily by the general public. Web.2.0 and associated advances in web mapping technologies have greatly enhanced the abilities to collect - share and interact with geographic information online - leading to VGI.,NONE304,GS4,Geospatial citizenship,Today - geo data has become a conventional and pervasively familiar data type seen at once to underpin and significantly re-characterize the digital world - with broad implications for both technology and society. Geospatial data are abundant - but access to data varies with the nature of the data - the user groups wishes to acquire it and for what purpose - under what conditions - and at what price geodata can be obtained. The explosive growth of geographic information contributed by users through various application programming interfaces has made geographic information a powerful media for the general public - but perhaps more importantly - geospatial information have also become media for constructive dialogs and interactions about social issues - recent growth of Web-based Geographic information and volunteered geographic information (VGI).,NONE305,GS5-1b,Ethics in the geospatial information society,The advantages of geospatial technologies and resulting data present ethical dilemmas such as privacy and security concerns as well as the potential for stigma and discrimination resulting from being associated with particular locations. the use of geospatial technologies and the resulting data needs to be critically assessed through an ethical lens prior to implementation of programmes - analyses or partnerships. Using this lens requires not only explicit consideration of potential negative consequences of adoption but also clear articulation of the specific contexts and conditions under which benefits may be realized.,NONE306,GS5-2b,Codes of ethics for geospatial professionals,A code of ethics is a guide of principles designed to help professionals conduct business honestly and with integrity. A code of ethics document may outline the mission and values of the business or organization - how professionals are supposed to approach problems - the ethical principles based on the organization's core values - and the standards to which the professional is held. Codes of ethics for geospatial professionals are intended to provide these principles and guidelines for GIS professionals,NONE307,GS5,Ethical aspects,Ethics provide frameworks that help individuals and organizations make decisions when confronted with choices that have moral implications. Most professional organizations develop codes of ethics to help their members do the right thing - preserve their good reputation in the community - and help their members develop as a community,NONE308,GS6-1,Epistemological and critical issues,US GIS&T BoK: As GIS became a firmly established presence in geography and catalysed the emergence of GIScience - it became the target of a series of critiques regarding modes of knowledge production that were perceived as problematic. The first wave of critiques charged GIS with resuscitating logical positivism and its erroneous treatment of social phenomena as indistinguishable from natural/physical phenomena. The second wave of critiques objected to GIS on the basis that it was a representational technology. In the third wave of critiques - rather than objecting to GIS simply because it represented - scholars engaged with the ways in which GIS represents natural and social phenomena - pointing to the masculinist and heteronormative modes of knowledge production that are bound up in some - but not all - uses and applications of geographic information technologies. In response to these critiques - GIScience scholars and theorists positioned GIS as a critically realist technology by virtue of its commitment to the contingency of representation and its non-universal claims to knowledge production in geography. Contemporary engagements of GIS epistemologies emphasize the epistemological flexibility of geospatial technologies.,NONE309,GS6-2,Critical approach on the use of geospatial information,Various types of critiques exist on the way geospatial information is being used and re-used.,NONE310,GS6-3,Critical aspects and invisible groups,Defending or refuting the argument that the 'digital divide' that characterizes access use of geospatial information perpetuates inequities among developed and developing nations - among socio-economic groups -and between individuals - community organizations - and public agencies and private firms.,NONE311,GS6,Critical approach,Many of the educational objectives used to define topics in this knowledge area - and in the Body of Knowledge as a whole - challenge educators and students to think critically about GI and Society. Since the 1990s - scholars have criticized cartography and the GIS science from a wide range of perspectives. Common among these critiques are questioned assumptions about the purported benefits of GI and Society and attention to its unexamined risks. By promoting reflective practice among current and aspiring geospatial information professionals - an understanding of the range of critical perspectives increases the likelihood that geospatial information will fulfil its potential to benefit all stakeholders. Philosophical - psychological - and social underpinnings of these critiques are considered in Knowledge Area CF: Conceptual Foundations.,NONE312,GS7-1,Epistemological critiques,US GIS&T BoK: As GIS became a firmly established presence in geography and catalysed the emergence of GIScience - it became the target of a series of critiques regarding modes of knowledge production that were perceived as problematic. The first wave of critiques charged GIS with resuscitating logical positivism and its erroneous treatment of social phenomena as indistinguishable from natural/physical phenomena. The second wave of critiques objected to GIS on the basis that it was a representational technology. In the third wave of critiques - rather than objecting to GIS simply because it represented - scholars engaged with the ways in which GIS represents natural and social phenomena - pointing to the masculinist and heteronormative modes of knowledge production that are bound up in some - but not all - uses and applications of geographic information technologies. In response to these critiques - GIScience scholars and theorists positioned GIS as a critically realist technology by virtue of its commitment to the contingency of representation and its non-universal claims to knowledge production in geography. Contemporary engagements of GIS epistemologies emphasize the epistemological flexibility of geospatial technologies.,NONE313,GS7-3,Feminist critiques,US GIS&T BoK: \r\rFeminist interactions with GIS started in the 1990s in the form of strong critiques against GIS inspired by feminist and postpositivist theories. Those critiques mainly highlighted a supposed epistemological dissonance between GIS and feminist scholarship. GIS was accused of being shaped by positivist and masculinist epistemologies - especially due to its emphasis on vision as the principal way of knowing. In addition - feminist critiques claimed that GIS was largely incompatible with positionality and reflexivity - two core concepts of feminist theory. Feminist critiques of GIS also discussed power issues embedded in GIS practices - including the predominance of men in the early days of the GIS industry and the development of GIS practices for the military and surveillance purposes.\r\rAt the beginning of the 21st century - feminist geographers reexamined those critiques and argued against an inherent epistemological incompatibility between GIS methods and feminist scholarship. They advocated for a reappropriation of GIS by feminist scholars in the form of critical feminist GIS practices. The critical GIS perspective promotes an unorthodox - reconstructed - and emancipatory set of GIS practices by critiquing dominant approaches of knowledge production - implementing GIS in critically informed progressive social research - and developing postpositivist techniques of GIS. Inspired by those debates - feminist scholars did reclaim GIS and effectively developed feminist GIS practices.,NONE314,GS7-4,Social critiques,In the early 1990s social critiques of GIS from human geographers began to appear. These initial critiques set off an ensuing debate between GISers - defending GIS and human geographers - who critiqued GIS. This debate materialized in academic journals including: Political Geography Quarterly - Environment and Planning A - and Progress in Human Geography. Schuurman (2000) notes that the GIS debate - while unique to the discipline of Geography - was part of a larger debate in other disciplines about the effects of technology. This presentation will be limited (unfortunately) to two aspects of this debate. It will first discuss conditions within human geography that made GIS a target of human geographers' critique. Second - this paper will discuss the particular critiques that were directed at GIS by human geographers. Though the reaction of such critiques and their effect on GIS is an important topic there is not enough time and space to address these issues. See Schuurman (2000) 'Trouble in the Heartland: GIS and its critics in the 1990s' in Progress in Human Geography for a thoughtful look at this debate and its effects on the discipline of GIS.,NONE315,IP,Image processing and analysis,Image processing and analysis comprises all relevant steps to reach from (raw) image data to [...] information via image interpretation and digital image classification. In traditional remote sensing workflows - this step follows the image acquisition process. There are two main components - i.e. (1) image processing - (2) analysis - which emphasizes the sequential nature of the process – while increasingly this dichotomy disappears.\rThe information production workflow aims at converting semantically rich - but unstructured image data into a set of classes - objects - arrangements - etc. - to enable ultimately a complete image understanding and scene reconstruction. This scene reconstruction entails a mental component (“understanding”) and a technical one - by providing standardized classification results or even beyond - dedicated information products in form of digital maps and reports - tailored to the specific application domains and use cases - in order to make informed decisions. Such information products can be maps - reports - dashboards etc. - overall it is the transformation from quantitative - semi-continuous digital numbers (“brightness”) to qualitative information using categories and figures - which can be stored and further used in a GIS environment. \rThe first part of the process entails image calibration - image correction (geometric - radiometric) - data assimilation - and any type of enhancement (contrast manipulation - filtering - etc.) which aims to better condition the information extraction part. It ends where we achieve a significant milestone in the processing milestone - remarkably denoted as analysis-ready data (ARD). From there - we enter into the analysis realm - classically referred to as digital image classification - the process of assigning pixels to classes. In other words - the aggregation of pixel values according to their similarity into categorical (nominal) classes. The discrimination of these classes by and large depend on application domain - and ideally - these classes match with information classes. To address the issue of ambiguity and to overcome the so-called semantic gap in image interpretation by providing a stepping-stone in the information extraction process - the strategy of pre-classification (semi-concepts) has been introduced in the literature.\rToday - boundaries between pre-processing and classification increasingly vanish - through an increasing level of automation in the pre-processing and image correction steps. In addition - new ways of analysis emerge - in particular in large time series - including image data cubes.  Instead of a processing chain - which suggests a linear – and potentially irreversible – cascade of manipulations - the automation of large parts of this part allows us to see the process more reversible and approachable from either side.,REMOTE SENSING316,IP1-1-1,Image subset,The image spatial subset allows to extract the group of pixels / grid cells using a defined polygon e.g. area of interest – AOI or defining the new image extent. It is used to limit spatially the image extent to which - for example an image function or classification model will be applied.,NONE317,IP1-1-2,Layer stack,Layer stacking is a process for combining multiple images into a single image. The image stack is used to build a ‘new’ multiple band file from the georeferenced images of various pixel sizes - extents - projections. The image bands must be resampled and reprojected to a common spatial grid. The layer stacking is used for example to combine spectral bands from a Landsat - Sentinel-2 data and SRTM DEM into one multi-dimensional file. The process of layer stacking increases the size of the final stacked image - which may have consequences that increase the processing time of operations performed on the stacked image.,NONE318,IP1-1,Data manipulation,Data manipulation adjusts a dataset to the needs of a specific application by subsetting the spatial extent or the number of bands or by organizing bands from separate single layer files into a single multi-layer file.,NONE319,IP1-2,Fourier transformation,Fourier analysis - A characteristic of remotely sensed images is a parameter called spatial frequency - defined as the number of changes in brightness value per unit distance for any particular part of an image. There are low-frequency and high-frequency areas. Spatial frequency may be enhanced or subdued using Fourier Analysis (an alternative technique is spatial convolution filtering). Fourier analysis mathematically separates an image into its spatial frequency components. It is then possible interactively to emphasize certain groups (or bands) of frequencies relative to others and recombine the spatial frequencies to produce an enhanced image.\rThe signal received by a pulsed radar is a time sequence of pulses for which the amplitude and phase are measured. The frequency content of this time-domain signal is obtained by taking its Fourier transformation.,NONE320,IP1-3-1-1,DEM generation with 'Structure-from-Motion',Structure from motion (SfM) describes the photogrammetric process for estimating the 3D structure of a scene - whereby correspondences between multiple images are established and used to detect motion parallax. When a camera moves over a surface while taking successive overlapping images - the distances between features on the surface will change from one image to the next. The changes depend on the distance of the feature points to the camera - and thus the surface elevation. This motion parallax can be used to generate an accurate 3D representation of the surface. \rThe photogrammetric problem of SfM is similar to stereo vision - but has gained popularity with the advent of inexpensive cameras which have variable internal geometries - unlike metrically stabilized cameras traditionally used in airborne mapping. Even with less accurate or even missing GPS location and orientation metadata - SfM still allows for the creation of (hyper)local DEMs as long as the imagery contains sufficient overlap. Airborne or spaceborne platforms can be used - provided that 2D frame-based cameras are used which can be represented with a pinhole mathematical model. \rGenerating a digital elevation model (DEM) from SfM is typically handled automatically using specialized software. Firstly - image correspondences are detected. Feature points are identified in the individual images using local contrast feature detectors. The features extracted from all the images are matched with all the available overlapping images and erroneous matches are filtered out. The process typically results in hundreds or thousands of tie-points per image - which allows for robust matching even with large a priori uncertainties in camera orientation. A bundle adjustment - solving for the 3D coordinates of the feature points - the position and orientation of the camera and its internal characteristics then results in an initial - so-called sparse 3D point cloud. \rNext - ground control points (GCPs) can be introduced. These are surface features (naturally present or introduced into the scene)  which can be identified at the pixel level in the images by users. Measured also in the field with an accuracy smaller than the pixel size - they can be used to constrain the bundle adjustment solution to improve georeferencing and camera calibration to an accuracy similar to that of the GCP measurement or the GSD size. \rSince this process yields a match only for a small subset of all pixels - an additional step - called dense image matching is added. It starts from the exact position and orientations resulting from the bundle adjustment to rectify the images and overlay two or more images - to compare them row by row and in 16 different directions in a process called semi-global matching (SGM). Matching pixels are identified along these lines - and 3D intersection distances photogrammetrically inferred. By combining results from different directions - a 3D coordinate for almost every pixel is obtained with similar accuracy. Finally - DEM products with a regularly spaced grid are generated and exported based on the dense point cloud. Depending on the point classes used in the export (obtained through topographic filtering or deep-learning-based classification of the dense point cloud) - the outcome will be a digital surface model (DSM) or digital terrain model (DTM).,NONE321,IP1-3-1-2,Photogrammetric principles,Photogrammetry is the science and technology of obtaining spatial measurements and other geometrically reliable derived products from photographs. Basic geometric principles applying both traditional analogue and modern digital procedures are related to the central projection of the image in case of typical cameras and to the dynamic projection mostly in case of push-broom sensors - popular in the satellite photogrammetry. The fundamental principle used by photogrammetry is called triangulation. By taking photographs from at least two different locations - so-called “lines of sight” can be developed from each camera to points in a block on the object. These lines of sight (called rays) are mathematically intersected to produce the 3-dimensional coordinates of the points of interest.\rWithin data processing the most important parts of photogrammetric workflow are: (1) image orientation - (2) model reconstruction - and (3) orthorectification. Image orientation is based mostly on aerial triangulation - however recently the computer vision algorithm - called structure from motion - became more popular in particularly in close range photogrammetry. Both orientation approaches include detection or measurement of the points between overlapping images in a block - control points measurements in a field defining orientation in reference system and check points verifying the orientation process. The satellite photogrammetry due to different projection and much bigger areas of imaging is usually related to Rational Polynomial Coefficients (RPCs) defining preliminary scene orientation during image orientation. However - to receive more accurate results also here the control points measured in a field are in use. The second part of the modern photogrammetric processing is 3D model reconstruction. In past - vectorization within the stereoscopic measurements was the most popular way of using photogrammetric data after the image orientation. The development of the informatics contributed to the development of the image matching algorithms that can provide dense image point clouds - which can be used to the 3D detailed modelling including digital elevation model production. The final step of photogrammetric processing is orthorectification - which delivers cartometric image called orthophoto mosaiced into orthophotomaps. This process comprises the influence of digital terrain model - model of camera (interior orientation) and image orientation (exterior orientation). Orthophotomap and elevation models derived from photogrammetric processing are applied as very popular data source in many GIS systems. The other photogrammetric outcomes are - for example a 3D measurement or 3D models of some real-world object or scene.,NONE322,IP1-3-1-3,RPC correction,In satellite photogrammetry to obtain the orientation mostly of satellite scene Rational Polynomial Coefficients (RPCs) are applied. They provide a compact representation of a ground-to-image geometry - that allow for photogrammetric processing without requiring a physical camera model. Model with RPC is provided with satellite image and can be improved using measurements of indirect surveying methods used for control point measurement. The RPC model for the coordinates of the image point is calculated as ratios of the cubic polynomials in the coordinates of the world or object space or ground point. \rIn photogrammetry and remote sensing - rational polynomial coefficients (RPCs) describe a specific imaging geometry model for transforming image pixel coordinates to map coordinates (thereby accounting for terrain displacement errors). A sensor model describes the geometric relationship between the object space and the image space - or vice versa. It relates 3-D object coordinates to 2-D image coordinates. RPCs are part of a general sensor model that approximates the physical sensor model. The physical sensor model represents the physical imageing process - making use of information on the sensor's position and orientation (during image acquisition). The RPC model often refers to a specific case of the RFM (rational function model) that is in forward form - has third-order polynomials - and is usually solved by the terrain-independent scenario.,REMOTE SENSING323,IP1-3-1-4,Ground Control Points (GCP),A ground control point (GCP) is a location of the surface of the Earth (e.g. a road intersection) that can be identified on the imagery and located accurately on the map (i.e. the reference dataset). Two distinct sets of coordinates are associated with the GCP: image coordinates in i rows and j columns - and map coordinates (e.g. x - y measured in degrees of latitude and longitude or as specified by the spatial reference system).,NONE324,IP1-3-1,Orthorectification,Orthorectification is the process of removing sensor (scanner or camera) - satellite/aircraft - and terrain-related distortions for creating a planimetrically correct image.  \rTo obtain an accurately orthorectified image - the following information is required: (1) accurate elevation model - and (2) a camera model or rational polynomial coefficients (RPCs) that depicts the positional relationship of the collected image to the ground. Many companies deliver their images together with RPCs and existing software implementations can automatically read these files and apply the RPC transformation on the fly. An accurate elevation model is important to remove the influence of topography (e.g. hills - valley - etc.) on the raw image so that users can accurately compute distances - areas - and directions. Without performing orthorectification - the features in the image are tilted (especially the features located away from the center of the camera). Many satellite data products (e.g. Sentinel images - Landsat data products) are orthorectified using Shuttle Radar Topography Mission (SRTM) Digital Elevation Model (DEM) data which is a freely available data product and has a spatial resolution of e.g. 1 arc-second (30 m). In the case of extremely jagged surface topography - i.e. areas of high relief - a DEM with a higher spatial resolution is required. \rTwo main models can be used in the orthorectification process: black-box and the physical-based model. The black-box model (called also the analytical model) is commonly implemented in different software because it relies solely on the RPC files. This model does not require access to any proprietary information of the sensor used to collect the image. \rThe physical-based models are more complex (and hence expected to be more accurate) because they account for various factors that might influence the quality of the acquired image: e.g. position of the satellite when collecting the images - atmospheric effects - etc. An example of a physical-based model is the so-called camera model. This model requires access to proprietary sensor information that has to be provided by the image owner.,NONE325,IP1-3-2-1,Image co-registration,Image co-registration [aka Image-to-image registration] is the translation and rotation alignment process by which two images of like geometry and of the same geographic area are positioned coincident with respect to one another so that corresponding elements of the same ground area appear in the same place on the registered images (Jensen 2005 referencing Chen and Lee 1992).,NONE326,IP1-3-2,Spatial referencing,Spatial referencing (referred to as geo-referencing as well) is the process of aligning available EO or GIS data to a coordinate system so that further spatial analysis and image analysis tasks can be applied using these data as input. \rTo be able to perform spatial referencing - users have to generate the so called Ground Control Points (GCPs) with known coordinates. In case of images - the easiest features that could be used as GCPs are the intersections - isolated trees etc.,NONE327,IP1-3,Geometric correction,Geometric correction is concerned with placing the reflected - emitted - or back-scattered measurements or derivative products in their proper planimetric (map) location so they can be associated with other spatial information. It is usually necessary to preprocess the remotely sensed data and remove the geometric distortions so that individual picture elements (pixels) are in their proper planimetric (x - y) map locations. This allows remote sensing-derived information to be related to other thematic information in geographic information systems (GIS) or spatial decision support systems (SDSS). Geometrically corrected imagery can be used to extract accurate distance - polygon area - and direction (bearing) information.\r\rGeometric correction techniques are dedicated to resolving the geometric distortions caused by: (1) variations in sensor position; (2) Earth curvature; (3) rotation of Earth on its axis; (4) relief displacement. \r\rThere are two types of geometric distortions - namely systematic and random distortions. The former might be caused by Earth's rotation for example and - therefore they are predictable and systematic. The second type of distortions might be caused by terrain or variations in sensor altitude. \rGeometric correction includes georeferencing and orthorectification techniques.,REMOTE SENSING328,IP1-4-1,Contrast stretching,Contrast stretching (also referred to as contrast enhancement) expands the original input brightness values to make use of the total dynamic range or sensitivity of the output device (a computer display).,NONE329,IP1-4-2,Histogram,The histogram is a useful graphic representation of the information content of a remotely sensed image. Histograms for each band of imagery are often displayed and analysed in many remote sensing investigations because they provide the analyst with an appreciation of the quality of the original data (e.g. whether it is low in contrast - high in contrast or multimodal in nature. [...] Tabulating the frequency of occurrence of each brightness value within the image provides statistical information that can be displayed graphically in a histogram.,REMOTE SENSING330,IP1-4,Image enhancement,Image enhancement algorithms are applied to remotely sensed data to improve the appearance of an image for human visual analysis or occasionally for subsequent machine analysis. The quality of results of image analysis are subjectively judged by humans as to whether they are useful. They include contrast enhancement.,NONE331,IP1-6,Principal component analysis (PCA),Principal component analysis (PCA) has proven to be of value in the analysis of multispectral and hyperspectral remotely sensed data. PCA is a technique that transforms the original correlated spectral dataset into a substantially smaller and easier set of uncorrelated variables that represents most of the information present in the original dataset. The first component accounts for the maximum proportion of the variance of the original dataset - and subsequent orthogonal components account for the maximum proportion of the remaining variance.,NONE332,IP1-7-1-1,Bottom-of-Atmosphere (BOA),Bottom-of-Atmosphere (BOA) reflectance is also called surface reflectance and consists of the solar radiation that is reflected from the Earth's surface.,NONE333,IP1-7-1-4,Top-Of-Atmosphere (TOA),Top-Of-Atmosphere (TOA) radiance represents the radiance observed outside Earth’s atmosphere. It is derived from the Digital Numbers (DN) using metadata delivered with the image.,NONE334,IP1-7-1,Atmospheric correction,Atmospheric correction accounts for the attenuation caused by scattering and absorption in the atmosphere. It transforms top-of-atmosphere (TOA) reflectance to bottom-of-atmosphere (BOA) reflectance.\rThe decision to perform atmospheric correction depends on the need - i.e. the envisioned usage of the derived EO information product and the nature of the underlying problem. This includes requirements to the accuracy of extracted biophysical information. Additionally - the decision and choice of methods depends on the type of remote sensing data available - the amount of in-situ historical and/or concurrent atmospheric information available.\rAn atmospheric correction is essential when biophysical or geophysical parameters (e.g. of water or vegetation) are going to be extracted from the remote sensing data. If the data is not corrected - the subtle differences in reflectance among the contributing image bands may be lost. This is especially relevant when biophysical information shall be compared to that of images from other dates.\rHowever - some cases exist where it is unnecessary to perform atmospheric correction. For example - it is not necessary for producing an image classification product from a single date of remotely sensed data. If a maximum likelihood classification is applied that uses training data with the same relative scale for the pixel values - then - atmospheric correction has little effect on the classification accuracy. The same holds true for a post-classification change detection where the classifications of the two different dates were performed independently. \rThe process of (absolute) atmospheric correction requires a model atmosphere and in situ atmospheric measurements acquired at the time of remote sensor data acquisition as input. In situ data can be available from other sensors on-board the sensor platform.\r\rDark Object Subtraction (DOS) is one of the most popular empirical atmospheric correction techniques. This technique assumes that a black object has a reflectance value of zero. Yet - a dark object present in a satellite image will have a value different than zero because of the atmospheric scattering. This value is then subtracted from all pixels in a given spectral band.,REMOTE SENSING335,IP1-7-2-1,Minimum noise fraction (MNF),A method for dimensionality reduction in hyperspectral data is Minimum Noise Fraction (MNF). The purpose is to minimize the noise in the imagery - i.e. to identify noise and segregate it from true information - and to colaps the useful information into a much smaller set of MNF images. The MNF transformation applies two cascaded principal components analyses.,NONE336,IP1-7-2,Dimensionality reduction,The number of spectral bands assocuates with a remote sensing system is referred to as its data dimensionality. Hyperspectral remote sensing systems such as AVIRIS ans MODIS obtain data in 224 and 36 bands - respectively. The greater the number of bands in a dataset (i.e. - its dimensionality) - the more pixels that must be stored and processed by the digital image processing system. Storage and processing consume valuable resources. It is necessary to reduce the dimensionality of hyperspectral data while retaining the information content inherent in the image. On method to reduce dimensionality of hyperspectral data and minimizing the noise in the imagery is the minimum noise fraction (MNF) transformation (Green et al. - 1988).,REMOTE SENSING337,IP1-7-3,Sensor calibration,Sensor calibration converts the sensor’s digital numbers (DNs) to at-sensor radiance above the atmosphere. A further radiometric adjustment accounts for the viewing angle and sun angle during acquisition to transform radiance values to top-of-atmosphere (TOA) reflectance. Therefore - the process requires sensor calibration information and telemetry data that satellite image providers deliver within the metadata.\rDNs are raw sensor data without physical units. The sensor calibration information for converting the DNs to radiance are the calibration gain (cal_gain) and calibration offset (cal_offset) values. The sensor calibration uses linear function f(DN) = DN * cal_gain + cal_offset that multiplies the DNs of each pixel in each spectral band with their corresponding cal_gain and adds the corresponding cal_offset. The resulting at-sensor radiance image is the basis for the radiometric adjustment that uses information about the viewing angle and sun angle during acquisition to transform at-sensor radiance to TOA reflectance. \rSensor calibration obtains TOA reflectance and is a minimum requirement for performing band math calculations to derive spectral indices such as the normalized vegetation difference index (NDVI). Uncalibrated image data would arrive at NDVI values that are distorted because the cal_gain and cal_offset parameters for the involved spectral bands were not considered.,NONE338,IP1-7-4,Noise reduction,As an optical remote sensing system is not perfect - noise can enter the data collection system at several points. Necessary corrections include the removal of shot noise (random bad pixels) - correcting line or column drop-outs - accounting for line-start problems and radiometric correction of n-line striping caused by detector miscalibration.\rSAR data have global - random speckle noise. Speckle filters are designed to adapt to local image variations in order to smooth values - thus reducing speckle and enhancing lines and edges to maintain the sharpness of an image. A widely used way to reduce speckle is to apply spatial filters to the images. Typical approaches for speckle filtering include Laplace filtering for smoothing and sigma filters that preserve more of the signal with a lesser effect of smoothing.,REMOTE SENSING339,IP1-7-5,Topographic correction,Topographic correction - or topographic effects correction - aims to adjust the spectral values of an image according to effects of solar illumination differences due to the irregular shape of the terrain. Topographic slope and aspect introduce radiometric distortion of the recorded signal. Further - terrain shadow dramatically affects the brightness values of the covered pixels in an image. Topographic effects of illumination and shadow are particularly relevant in mountainous regions and in regions towards the higher latitudes of the southern and northern hemisphere. The effects appear pronounced during the winter season. \rTogether with sensor calibration and atmospheric correction - topographic correction is part of the radiometric correction process to obtain true reflectance values from sensor radiance. This process is necessary when using EO data for obtaining geophysical measurements. It can also benefit the accuracy of image classifications by reducing the internal variability of vegetation types - since the corrected reflectance relates better to the geometrical or biological properties of the plant than to the original reflectance.\rMethods for the removal of topographic effects from remotely sensed images can simply be based on band ratios that do not require additional input. Alternatively - they use digital elevation models (DEMs) as an additional input and apply sophisticated modelling of the illumination conditions. The illumination model describes various aspects of the relationship between the sensor measurement - the sun illumination - the ground reflectance and the diffuse irradiance at the surface. The model incorporates the angles between the sun position - the ground position (described by slope and aspect from the DEM) - and the sensor position. Among these methods are lambertian methods and non-lambertian methods such as the bidirectional reflectance distribution function (BRDF). The BRDF - which is more suitable to the non-Lambertian properties of the observed surfaces - describes how the reflectance varies in each cover considering the angles of incidence and observation. \rIf achieved with a high quality - the resulting topographically corrected image appears to be illuminated evenly as if all its pixels would be part of a flat surface without the presence of any terrain differences. However - the much larger benefit than the improved appearance is the availability of pixel values that are closest to the true reflectance when compared to TOA - BOA and DN values.,NONE340,IP1-7,Radiometric calibration and correction,Radiometric calibration and correction converts the sensor’s digital numbers (DNs) to radiance values and subsequently reflectance values. Additionally - the term “correction” points to the fact that radiometric measurements with satellite sensors contain error. Therefore - radiometric correction is concerned with improving the accuracy of surface spectral reflectance - emittance - or back-scattered measurements obtained using a remote sensing system. The Earth’s atmosphere - land and water are complex and can never be captured perfectly because of the limitations of remote sensing devices that lie in their spatial - spectral temporal and radiometric resolution. Therefore - error occurs in the data acquisition process and degrades the quality of remotely sensed data. The most common errors in remote sensing are radiometric and geometric. This concept is focused on the correction of remote sensing data to account for radiometric error that is to some degree systematic. Systematic errors in radiometric measurements come from the interaction of the sensed radiance with the atmosphere - the acquisition geometry in relation to the radiance source (the sun) and the Earth surface geometry (terrain).\rThere are several levels of radiometric calibration and correction. The first is sensor calibration that converts the DNs to top-of-atmosphere (TOA) reflectance. It converts to radiance values and further to reflectance values by accounting for the viewing angle and sun angle during acquisition. The second is atmospheric correction that converts TOA reflectance to bottom-of-atmosphere (BOA) reflectance. The third is topographic correction that converts BOA reflectance to surface reflectance. \rRadiometric calibration is necessary to ensure radiometric comparability of the measurements. There is a need for calibration when comparing different spectral bands within one image - e.g. for the calculation of geo-biophysical parameters with band math operations. Results from uncalibrated image data would differ from results achieved with calibrated data because the unaccounted cal_gain and cal_offset of the used spectral bands would lead to distortions. \rIn addition - radiometric calibration complements the geospatial comparability that is achieved with geo-referencing an image to geographic coordinates. Geo-referencing enables comparison of an image pixel to the geospatially matching pixel in another image acquired with a different sensor but with comparable resolution. Radiometric calibration enables a radiometric comparison between these two pixels’ radiance values. In case the two images are from different acquisition dates - a calculated radiometric difference would indicate change. This example shows the relevance of radiometric calibration for inter-sensor comparisons.\rRadiometric comparability is particularly relevant in studies that require inter-sensor comparisons - comparisons of surface features over time - or comparisons to laboratory or field reflectance data. Then the radiometric correction should cover atmospheric - solar and topographic effects. A full radiometric correction that also includes topographic correction can benefit the accuracy of image classifications by reducing the internal variability of vegetation types - since the corrected reflectance relates better to the geometrical or biological properties of the plant than to the original reflectance.,REMOTE SENSING341,IP1,Image pre-processing,Image pre-processing focuses on transforming the electrical signal measured by a sensor to a processing level at which pixel values can be used for the next information extraction step. Therefore - pre-processing operations involve the removal of errors encountered while collecting remotely sensed data to get as close as possible to the true radiant energy and spatial characteristics of the study area at the time of data collection. Different sensor type (optical - radar - lidar) require different processing levels\rThe most common image pre-processing procedures include: \r(1)	Radiometric calibration involves the transformation of Digital Numbers (DN) to physical unit: radiance/reflectance. Radiometric calibration can be done before the launch of a satellite sensor - i.e. pre-launch calibration - or after launch. In the second case - the calibration is performed on-board or by comparing ground measurements with satellite radiance. Through radiometric calibration various scene illumination procedures such as sun elevation correction or earth-sun distance correction are applied. Furthermore - image noises caused by striping or line drop as happened in case of Landsat TM7 due to failure of the Scan Line Corrector (SLC) are also corrected using specialized procedures.\r(2)	Atmospheric correction accounts for two main processes: scattering and absorption. Scattering represents a disturbance of the electromagnetic waves caused by rayleight scattering (caused by very small particles such as the air molecules) - mie scattering (caused by aerosol particles) and non-selective scattering (dust - smoke - rain etc.). Absorption occurs when the electromagnetic energy is absorbed by the atmospheric components. Therefore - atmospheric windows have to be removed before using the satellite images in the next processing steps. Atmospheric corrections can be carried out either using simple statistical methods or complex radiative transfer based methods\r(3)	Geometric correction is required to remove the distortions caused by the Earth curvature - Earth rotation - panoramic distortion due to the field of view of the sensor and the topography of the terrain. Geometrics distortions are corrected using Ground Control Points (GCP) and a Digital Elevation Model (DEM). In case of airborne images - additional distortions caused by variations in the platform altitude or velocity might occur.,NONE342,IP2-1-1,Data augmentation,Data augmentation refers to a scheme of augmenting the observed data so as to make it more easy to analyze. An application from deep lerarning is to increase the number of input training sample images with augmented data. Examples of data augmentation techniques include horizontal flips - random crops - and principal component analysis.,NONE343,IP2-1-2,Data imputation,Data imputation refers to a scheme of replacing missing values by imputed values. Imputation can be done - for example with mean - median and mode. Imputation methods can efficiently predict multiple response variables simultaneously.,NONE344,IP2-1-3-1,Gram-Schmidt pan-sharpening,Gram-Schmidt is a pan-sharpening method that has been invented by Laben and Brover in 1998 and patented by Eastman Kodak. It makes use of the Gram-Schmidt orthogonalization to decorrelate the spectral bands (panchromatic - red - green - blue - etc.) and transform them into one multidimensional vector.,NONE345,IP2-1-3-2,Principal Component Analysis (PCA)-based pan-sharpening,This pan-sharpening method uses PCA to transfer detailed spatial information from panchromatic band to the available multispectral bands.,NONE346,IP2-1-3,Pan-sharpening,Pan-sharpening methods are used to enhance spatial resolution of images by merging a panchromatic image with high resolution with a multispectral image with low resolution.,NONE347,IP2-1-4,Spatio-temporal image fusion,Spatiotemporal image fusion methods - called also spatiotemporal downscaling methods - represent an efficient solution to generate fine-scale images at a high temporal resolution for more detailed land cover mapping and monitoring applications. Spatiotemporal image fusion methods can be classified into three categories: (1) reconstruction-based  - (2) unmixing based and (3) learning-based methods.,NONE348,IP2-1,Data fusion,Image fusion is defined as the “combination of two or more different images to form a new image by using a certain algorithm” Data fusion is a well-established research field. Image fusion methods are primarily used for improving the level of interpretability of the input data. Additionally - they can be utilized to address the problem of missing data caused by cloud or shadow contamination in satellite images time series. Image fusion can be performed at pixel-level - feature-level (e.g. land-cover classes of interest) - and decision-level (e.g. purpose driven).,NONE349,IP2-2,Data harmonisation,Data harmonization aims to transform different datasets in such a way that they fit together - both with respect to geometry and semantics. The goal is that a user - who is using data from different authorities - shall have a unified view - where conflicts  in the datasets have been removed.,NONE350,IP2-3,Data integration,Data integration is the process of combining different geographic datasets including those derived from remote sensing data. The combined datasets can have different coverage - but they have to have the same geographic coordinates.,REMOTE SENSING351,IP2,Data assimilation,Data assimilation is a strategy to foster data integration and data harmonisation in a bi-directional way between the measured and the modelled reality. In other words - it aims to combine measurements (observations) with the understanding of the spatio-temporal properties and evolution of system’s variables or properties and model information about them. Models can be calibrated and keeping them ‘on track’ by constraining them with observations. Vice versa - observations can be validated through models. Approached as a mathematical problem - data assimilation aims at minimizing cost functions or penalize a function to ensure optimality in fitting. Equations are used to describe system parameters and the relationships among them - It is noteworthy - that models encompass information from previous measurements - experiences - and theory. While the observations are influenced by (known) properties such as precisions - etc. of the measurement devices - the robustness of models rely on the consolidated knowledge. Because uncertainties reside in all components with unknown or even undeterminable errors - the approach is usually probabilistic - including Bayesian and other related techniques.  Widely used in meteorological sciences - successful data assimilation has been boosted the reliability of weather forecast  - while sensitivity to errors remains. \rIn Earth observation - data assimilation compensates for the fact that a specific site could be observed in a variety of measurements by satellites with different sensor types - at different dates - different angular geometries and viewing directions - illumination conditions (solar time) - observation frequencies - etc. In particular - for monitoring processes - measurements over time need to assure to actually measure the status of the system or object and not the divergence in observation. To overcome these divergences and converge them with the actual properties of an observed object or target class such as spectral or geospatial properties - observation modelling can be considered an important contribution from geospatial theory. this also links to class modelling or geon modelling. The synergy of a vegetation growth model and a remote sensing observation model can be exploited to improve the retrieval of geo-biophysical information. For vegetation and crop type monitoring radiative transfer modelling (RTF) is being used as an example. \rData assimilation can also serve in bridging the gaps between non-availabilities of EO data and other observations - to provide estimates or prediction for geographical variables - testing of hypotheses or continuous observation (monitoring). A related aspect is data imputation - i.e. filling gaps in observations e.g. by other - complementary data sets (e.g. Radar imagery in the absence of VHR data in cloudy weather conditions). Recently - these sources can also be complemented by crowd mapping and citizen science. \rWhen interpretation of data comes into play - such as image classification - we introduce another level of uncertainty. Thus the community seeks for rigorus classifiers based on solid spectral models - acting across sensors. Semantic enrichment of satellite data is a related strategy for reaching to interpreted data in a rigorous way. \rSummarizing - data assimilation comprises steps to improve the level of interpretability of the input data - by enrichment (get rid of spatial/temporal gaps) - by accounting for heterogeneity (through harmonization) - and by integration (combination with other data that is relevant to the application). Thereby - datasets become more comparable to each other.,REMOTE SENSING352,IP3-1-1-1,Vegetation fraction,Vegetation fraction (VF) is defined “as the percentage of vegetation occupying a pixel as viewed in vertical projection. It’s a comprehensive quantitative index in forest management and vegetation community cover conditions - and it’s also an important parameter in many remote sensing ecological models.”,REMOTE SENSING353,IP3-1-1-2,LAI (Leaf Area Index),Leaf area index (LAI) is the ratio between the total area of the upper leaf surface of vegetation and the surface area of the pixel in question. LAI is a dimensionless value - typically ranging between 0 (for a pixel composed of bare soil) and values as high as 6 (for a dense forest).,NONE354,IP3-1-1-3,Net primary production (NPP),Net primary production (NPP) is a measure of the inherent productivity of a region or ecological system—mainly the Earth’s production of organic matter - principally through the process of photosynthesis in plants.,NONE355,IP3-1-1-4,Water quality variables,Water quality variables can be derived from Earth observation (EO) data to provide essential ocean variables. They include Sea-surface temperature (SST) - Sea-surface salinity (SSS) and Air-Sea Fluxes. SST controls the atmospheric response to the ocean at both weather and climate time scales. The spatial patterns of SST reveal the structure of the underlying ocean dynamics - such as - ocean fronts - eddies - coastal upwelling and exchanges between the coastal shelf and open ocean. SSS observations contribute to monitoring the global water cycle (evaporation - precipitation and glacier and river runoff). Water quality variables can be derived from EO data by using ocean colour products from optical sensors and relating them to ground truth information from in situ sensor networks.,NONE356,IP3-1-1,Biophysical and geophysical parameters,Biophysical parameter retrieval is an approach in remote sensing that aims to estimate parameters which have physical meaning related to properties of living organisms.  The goal is to provide quantitative results directly relating to the biophysical state - but independent of acquisition conditions and technology. Assessment of vegetation status is a key motivation for this - because through plant respiration and photosynthesis - vegetation is critical for modelling terrestrial ecosystems and energy cycles in environmental studies. \rImportant parameters describing canopy structure include leaf area index (LAI) - green cover fraction (fCover) - fraction of absorbed photosynthetically active radiation (fAPAR) - plant height - biomass and leaf angle distribution.  At leaf biochemical level - leaf chlorophyll/water -  fuel moisture and leaf pigmentation content are used.\rVisual inspection can provide a first assessment of plant status. For detailed measurements of biophysical parameters - mostly destructive methods have been used. Chemical measurement techniques on leaf samples can measure pigment concentrations very accurately - but are time consuming and only use very limited samples.  \rMuch more extensive data can be collected using earth observation imagery.  These range from large scale spaceborne observations with high frequency at coarse resolution to dedicated UAV flights which can offer spectral information of  individual plants. Radar and LiDAR acquisitions - which are insensitive to weather conditions - now complement optical observations. \rMethods to retrieve the parameters from remote sensing data fall into two main categories. Statistical models empirically match data to a biophysical variable. Univariate techniques use a single quantity derived from the data - usually a vegetation index whereas multivariate techniques link a combination of measurements at different wavelengths to one or more biophysical parameters.\rPhysically-based modeling is an alternative approach which uses advanced radiative transfer models to describe the transfer and interaction of radiation inside a leaf or canopy based on robust physical - chemical - and biological processes. They compute the interaction between solar radiation and plants and provide as such a better understanding between biophysical variables and reflectance characteristics. Good examples are Leaf optical models such as PROSPECT and LIBERTY which simulate leaf optical properties by absorption and scattering coefficients. Canopy reflectance models simulate canopy reflectance as a function of a complex description of plant structural and radiometric attributes to develop a quantitative understanding of remote sensing information.,REMOTE SENSING357,IP3-1-2-1,Soil-adjusted Vegetation Index (SAVI),This spectral index is calculated using the following formula: SAVI = [(NIR-Red)/(NIR+Red+L)]/(1+L) - where L can be - for example - 1 in area with no vegetation or 0 in area with dense veegtaion. It is used to minimize the influence of the soil brightness from the vegetation indices that are based on red and near-infrared wavelengths.,NONE358,IP3-1-2-2,Normalized Difference Snow index (NDSI),This spectral index is calculate using the following formula NDSI = (green-SWIR)/(green+SWIR). It is the most popular index used to identify snow cover due to the fact that snow reflects visible wavelength stronger than middle-infrared wavelengths.,NONE359,IP3-1-2-3,Normalized Difference Vegetation Index (NDVI),Leaves - when healthy and vigour show a characteristic green colour. This visual effect evident to humans is caused by the co-existence of two evolutionarily facts: the specific interaction of the chlorophyll pigment in living leaves to the visible spectrum (VIS - 400-700 nm wavelength) of light emitted by the sun and the sensitivity of our human eye to the same sub-spectrum. According to fundamental physical laws of radiation (Stefan Boltzmann law of blackbody radiation and Wien’s displacement law) - the VIS sub-spectrum corresponds to the radiation maximum of the sun - a hot blackbody with a surface heat of about 6000 K. Living leaves are structured in specific layers exhibiting characteristic interaction with light. The chloroplasts located in the so-called palisade layer - make use of the blue and the red part of sunlight for photosynthesis - the unique process of transforming light to create energy (carbohydrates) from water and carbon dioxide. This leads to the specific behaviour of leaves to absorb large portions (up to 90%) of the blue and red part of the electromagnetic spectrum and reflect nearly 100% of the green light. The peak reflectance in green light makes leaves (and plants in general) appear in green colour in our visual perception. \rA second - by no means less characteristic - feature of leaves is the specific response to near infrared (NIR - at around 700 nm wavelength) light in the mesophyll tissue (transmittance - scattering and reflectance). Only a small fraction of NIR is being absorbed. \rThis combination of two specific spectral characteristics - the absorption in VIS (red colour) by chlorophyll a in palisade layers - and the reflectance of NIR in the spongy tissue - makes the spectral profiles of plants and vegetation exhibiting a very characteristic shape - the so-called red edge. This absorption edge between red and NIR light is sharper for higher intensity green reflectance and brighter green tones (such as grassland or bright deciduous forest) than for less intensive reflectance and darker tones (coniferous forest). \rThe red edge may shift for the same vegetation type due to plant maturity or plant stress. This effect we call the red shift. The red shift is sensitive to crop maturity (headed stage) and may indicate harvesting time. Notably - there is also a blue shift - indicating green plants’ exposure to geochemical stress - which causes the absorption spectra to shift towards shorter wavelengths. \rPlants usually do not appear in isolation but form a canopy with a certain degree of coverage (e.g. - crown closure in forests) - and a certain part of understorey or soil per area unit. The resulting canopy reflectance is therefore a spectral mix of soil and vegetation (or even different types of vegetation) and generally lower than the reflectance of a pure vegetation sample under lab conditions. \rTo capture most of these plant-typical spectral characteristics - the so-called normalised difference vegetation index (NDVI) was developed. NDVI is an arithmetic band combination of red and NIR bands in a normalised value range. \rThe NDVI is calculated as:\rNDVI=((NIR-R))/((NIR+R))\rThe (hypothetic) value range of the NDVI is [-1 | +1]. Under real-world conditions - the NDVI ranges from values of around -0.2 to 0.6 or 0.7. To discriminate principal land cover classes such as water - non-vegetation (soil - sealed - etc.) and vegetation the following thresholds in the continuous range are used:  \r	NDVI < ~ 0: water\r	~ 0 < NDVI < ~ 0.2: non-vegetation (soil - sealed surfaces - bare rock - etc.)\r	~ 0.2 < NDVI: vegetation.\rNotably - these class limits are just a very rough approximation (indicated by the ~ sign) - due to the mixed pixels effect - canopy reflectance - the abundance of water plants and suspending particles - and the illumination effect of specific atmospheric or topographic conditions. \rWe can use the NDVI to generally mask out vegetation from other land cover types and - more specifically - to indicate vegetation vigour and health. It is also suitable for monitoring plant phenology as the relationship between vegetative growth and the (changing) conditions of the environmental conditions. A range of variations has been suggested - enhancing one or the other mathematical or statistical behaviour of the index - or making it even more sensitive to specific plant behaviour. A well-known example is the enhanced vegetation index (EVI).,NONE360,IP3-1-2,Spectral indices,Spectral indices are calculated using a mathematical equation that is applied on two or more spectral reflectance bands of the image. The calculated spectral index is a ‘new’ image that highlights particular land surface features or properties e.g. vegetation - soil - water - better than the original input bands. The spectral indices vary from simple spectral ratioing of two bands to more complex combinations of multiple bands. Spectral indexes are developed based on the spectral properties of the object of interest. For example - spectral indices dedicated to the vegetation condition are developed based on the principle that the healthy vegetation reflects strongly in the near-infrared spectrum while absorbing strongly in the visible red. These properties are used to develop more complex spectral indexes for monitoring vegetation condition - phenology parameters - i.e. Normalised Difference Vegetation Index (NDVI) - Advanced Vegetation Index (AVI). The spectral indices calculated using the short wave infrared spectral bands are more sensitive to vegetation water content and spongy mesophyll structure in the vegetation canopy thus are used to assess the vegetation decline - moisture that is particularly useful for drought monitoring (e.g. Normalized Difference Water Index (NDWI) or Normalized Difference Moisture Index – NDMI). The water-related spectral indices are widely applied in agricultural and ecological applications including surface water body characteristics - vegetation water stress - soil water content assessment and wetlands monitoring. The combination of near infrared and short wave infrared spectral bands is also used to detect burned area and to monitor the vegetation recovery (e.g. Normalised Burned Ratio – NBR). There are other spectral indices dedicated to snow cover and glacier monitoring - which are developed based on visual green and short wave infrared spectral bands. Snow reflects most of the radiation in the visible bands whiles absorbing in the short wave infrared.,NONE361,IP3-1,Band maths,The term band maths denotes the arithmetic combination (addition/subtraction - multiplication/division) of two or more spectral bands in an early stage of image analysis. The resulting scalar values represent the spectral behaviour in different bands in a single value; such procedure makes particular sense - when spectral behaviour varies in those bands (like the red edge of vegetation spectra in the NIR band). \rThere are several reasons for applying band maths when working with multispectral imagery: (1) A single range of values rather than multiple bands is easier to comprehend and interpret; (2) Thresholds or class limits are applied more intuitively in a grey scale image; (3) Indices can be easily calculated and compared across different sensors; they are implemented as standard routines in many software environments as well as cloud processing environments (such as Google Earth Engine or the Proba-V exploitation platform)\rOut of the many possible - literature suggests a few arithmetic band combinations as application-specific quasi-standards. Band ratios (e.g. red band divided by NIR band) and indices (such as the normalised difference vegetation index - NDVI) belong to this group. Indices have the advantage over simple ratios in constraining the value range - e.g. [-1 | 1]. Designated to indicate specific land cover types (such as water index - snow index - soil index - etc.) such indices are widely used as a basis for operational information products. Another index is the normalised burn ratio (NBR) which relates near infrared and short-wave infrared reflectance to measure burn severity taking into consideration the increasing of SWIR reflectance in the course of a fire. \rPre-processing such as dark object subtraction and radiometric or even atmospheric correction is a key requirement prior to indexing. The coding in digital numbers (DN) is a function of the sensitivity and the radiometric resolution of the sensor. The actual recording depends on atmospheric conditions (additional brightness - haze - etc.). Therefore - in order to make the resulting values comparable among different types of sensors and scenes - radiometric correction is mandatory - converting DNs into radiances - i.e. true reflectance values as physical measurement units.  \rTwo advanced examples of band maths beyond rationing are the perpendicular vegetation index (PVI) and the tasselled cap (TC) transformation. PVI is based on the assumption that vegetation pixels are generally separable from soil pixels (at least after unmixing or for pure pixels) - and thus pixel values are located in a perpendicular direction from the soil line in a NIR/red feature space. The Euclidean distance from the soil line - determined by Pythagorean triangle - yields the PVI.  Tasselled cap instead rests on the notion of a cap-like histogram shape when plotting pixels on a brightness vs. greenness plot - with the latter determined by linear combinations of VIS and NIR bands - along with empirically determined coefficients. TC 1 as a weighted sum corresponds to brightness - TC 2 to greenness - TC 3 to yellowness - sometimes referred to as wetness. A fourth TC called nonesuch likely corresponds to noise and atmospheric disturbance effects in the image.,NONE362,IP3-10,Semantic enrichment,Semantic enrichment is the process of adding semantic metadata elements to improve the content-based image retrieval. These semantic metadata elements enable the explicit specification of the content of the images stored in the remote sensing databases.,REMOTE SENSING363,IP3-11-1,Change detection,Different types of changes are investigated using remotely sensed data: (i) abrupt changes - such as the changes caused by a fire or flooding - and (ii) gradual changes such as urban growth. Besides these kinds of changes - remote sensing community differentiates between transitional changes and conditional changes. Transitional changes refer to a major change of land surface such as conversion of forest to pasture or the expansion of mangroves into the surrounding water. Conditional changes refer to the change in condition at the surface such as water stress in an agricultural field - forest degradation caused by pest. \rIn the past - many remote sensing studies used two images to detect different types of changes such as deforestation - land cover change or change in the health or condition of the vegetation (e.g. pest infestation). Meanwhile - satellite image time series are used to assess the change. Time series analysis allows for monitoring more subtle changes and for providing temporal patterns of change. In this way - the timing of changes and drivers of change can be easily identified. \rDifferent methods are being used in change detection studies. There are studies that analyze individual images available in the investigated time series to map the target class/phenomena/events at the time when images were collected and to identify the changes: e.g. mapping the mangroves extent on an year basis and measuring it to identify changes. Alternative studies search for breaks in time series for detecting changes. The breaks are used to segment the time series into before and after changes periods which are further classified using one of the existing supervised or unsupervised classification methods (K-means - fuzzy k-means - Random Forest - Support Vector Machine etc.).,REMOTE SENSING364,IP3-11-2,Cube-based time series analysis,The (data)cube model for analysis of time series of earth observation raster data - represents the dataset as a multidimensional array with one or more spatial or temporal dimensions. Scalar values in the cube can be selected (or ‘filtered’) and processed based on dimension labels. This allows analysis algorithms to be thought of as a set of operations on the multidimensional array. Technologies that support this model allow to efficiently implement such algorithms.\rSome possible operations on a multidimensional cube include: filtering - ‘reducing’ all values along a dimension - ‘aggregating’ values in a  dimension - or transforming all values along a dimension. Generally speaking - these operations require the selection of a subset of the data on which work is to be done. This allows implementing the operations efficiently even on very large datasets.\rIn comparison to file-based processing - most technologies that support cube-based time series analysis reduce implementation overhead - as the user does not need to read and write individual files - also more complex aspects like distributed computing for parallelization can be hidden in a cube based approach. So a cube based approach can also be thought of as an abstraction layer that effectively reduces the need for specific IT-related skills when analyzing earth observation timeseries.\rMultiple initiatives support cube based analysis. Some common features include a programming API - often using the Python programming language. Some tools are only accessible as web services - while others can also run locally (on a small dataset). This diversity is still a drawback - as users would need to familiarize themselves with different systems. Initiatives such as openEO try to address this by providing a common API.,NONE365,IP3-11-3,Dynamic Time Warping,Dynamic Time Warping (DTW) works by comparing the similarity between two temporal sequences and finds their optimal alignment - resulting in a dissimilarity measure. In the case of remote sensing data - DTW can deal with temporal distortions - and can compare shifted evolution profiles and irregular sampling thanks to its ability to align radiometric profiles in an optimal manner,REMOTE SENSING366,IP3-11,Time series analysis,Satellite image time series analysis plays an important role in different domains including vegetation dynamics monitoring - estimating crop yields - discriminating between different land cover classes - exploring human-nature interactions -  monitoring land cover change - assessing environmental threats - or evaluating ecosystems-climate feedbacks or urbanization.\rTime series analysis requires high quality time series which are reconstructed by removing any source of contamination such as clouds - cloud shadows - or scan-line corrector (SLC) gaps of the Enhanced Thematic Mapper plus sensor (ETM+) on Landsat 7. Removed pixels are usually filled in with data predicted from a different date (temporal interpolation) -  nearby pixels (spatial interpolation) or from both (spatiotemporal interpolation). Different methods are available for screening and masking out clouds and shadows in satellite images including mono-temporal methods such as Function of mask (Fmask) - or multitemporal mask (e.g. Tmask algorithm). Fmask is used by the United States Geological Survey (USGS) to produce a cloud mask layer of Landsat images. European Space Agency (ESA) is using Sen2cor processor to produce Level 2A Sentinel-2 data with a shadow and cloud shadow mask. All images used in the time series have to be co-registered - i.e. they align as closely as possible. \rTime series analysis is used to (1) investigate various surface properties such as evapotranspiration - land surface temperature - (2) map the cover of the Earth surface (e.g. land cover mapping - crop mapping etc.) -  (3) detect  different type of changes such as abrupt changes (fire event) or gradual changes (urbanization) - and (4) study the trends.\rTo map surface features from satellite image time series - numerous studies make use of the vegetation phenology extracted from a spectral-temporal trajectory of a given spectral vegetation index such as the normalized difference vegetation index (NDVI) or enhanced vegetation index (EVI). Several metrics can be used to characterized vegetation phenology: metrics of greenness and metrics of time. The metrics of greenness include the minimum and maximum spectral vegetation indices - their difference or amplitude - seasonally averaged greenness etc. The metrics of time include start and end of the growing season - duration or length of the growing season or the timing of maximum greenness. Changes - on the other hand - are identified either by investigating two images acquired at two different points in time or by identifying breaks in a dense (annual or multi-annual) satellite image time series.,NONE367,IP3-12-1,Error propagation,Remote sensing-derived products such as land-use and land-cover maps contain error. The error accumulates as the remote sensing data are collected and various types of processing take place. An error assessment is necessary to identify the type and amount of error in a remote sensing-derived product.,REMOTE SENSING368,IP3-12-2,Precision,The precision of a measurement system - related to reproducibility and repeatability - is the degree to which repeated measurements under unchanged conditions show the same results.,NONE369,IP3-12,Uncertainty,Uncertainty is the result of the lack or imprecision of our knowledge about the world. A proposition is uncertain if we do not know whether it is true or not. In most circumstances we describe a proposition as uncertain when the reason we do not know whether it is true is that we do not possess complete and accurate knowledge about the state of the world.,NONE370,IP3-13-1,Elements (cues) of interpretation,The main elements of visual interpretation are: tone - shape - size - pattern - texture - shadow -  - association. Tone refers to the relative brightness or colour of objects in an image. It depends on the spectral properties of an object. Variation in tone allows to distinguish elements of different shape - texture and pattern. Shape refers to the general form - structure - or outline of individual objects. Straight and sharp edge shape represent typically the anthropogenic features i.e. urban or agriculture - the natural features like rivers - wetlands are more irregular in shape. Size of objects in an image is a function of scale and it depends on the spatial resolution of the image. The assessment of the size of the target’s object in relation to other objectives as well as an absolute size of the object are the important part of the interpretation. Pattern refers to the spatial arrangement of objects - i.e. network of street and houses in an urban area - orchards with the line of trees. Texture refers to the arrangement of frequency of tonal variation in particular areas of an image. Rough texture would have very large - coarse tonal variation (e.g. forest canopy) - whereas smooth texture very little tonal version (e.g. uniform - homogenous surfaces). It depends on the size - shape and pattern of objects. Shadow depends on the scale and spatial resolution of an image. Shadow is useful to measure the height of an object - to distinguish the coniferous from broadleaf trees. In the radar imagery is useful for identifying topography and landforms.  Association refers to the relationship between objects and features in proximity to the target interest.,NONE371,IP3-13-2,Information-as-data-interpretation,Information-as-data-interpretation considers information as the outcome of the cognitive process of vision that reconstructs a scene from an image.,NONE372,IP3-13-3,Interpretation keys,An image interpretation key is simply reference material designed to permit rapid and accurate identification of objects or features represented on aerial images.,NONE373,IP3-13,Visual interpretation,Interpretation is the processes of detection - identification - description and assessment of an object and pattern imaged. Visual interpretation is the ability of a human operator to identify an object through the data content in an image / photo by combining several elements of interpretation. The image characteristics used in the interpretation process are: shape - size - tone/colour - texture - shadow - neighbourhood and pattern. The importance of the image characteristics varied according to the spatial resolution of the images and the properties of the feature of interest. The interpretation can be performed on the single image or between several images acquired at different time - which result in the differentiation of the temporal changes. The principle of the image interpretation is the process of delineating (digitalizing) the outlines of the objects - features on the image. It is performed “on-screen” using a GIS software. The process of visual interpretation is time consuming and requires a skilled interpreter with knowledge of the study area. Even though - the image interpretation supports many applications in for example selection of the training and verification data sets for image classification and accuracy assessment.,NONE374,IP3-2-1,Artificial intelligence (AI) in EO,Artificial intelligence (AI) is an area of computer science that emphasizes the creation of intelligent machines that work and react like humans.,NONE375,IP3-2-2,Information theory,Information theory answers two fundamental questions in communication theory: what is the ultimate data compression (answer: the entropy H) and what is the ultimate transmission rate of communication (answer: the channel capacity - C). For this reason - it is considered that information theory is a subset of communication theory.,NONE376,IP3-2-3,Keypoint detection,Keypoints are objects (or locations) on the ground that reveal locally invariant features in images and therefore are easily detectable by automatic algorithms. Methods for this process employ scale-invariant feature transform (SIFT) algorithms for the automatic detection of geospatial objects.,NONE377,IP3-2,Computer vision in EO,Image understanding is part of computer vision. Computer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering - it seeks to automate tasks that the human visual system can perform.,NONE378,IP3-3-1,DEM generation,A Digital Elevation Model (DEM) is a digital raster (or grid) representation of elevation values of land surface shapes and features - where each grid cell takes a single elevation value with reference to a certain vertical datum. A DEM can be global - regional or local in scope - and can be used to characterize the dry land surface (topography) or submerged surfaces (bathymetry). Since a DEM cannot contain information of shapes and features under overhanging structures - it is often referred to as 2.5D instead of truly 3D. \rA digital elevation model is an overarching term for either a digital surface model (DSM) or digital terrain model (DTM). A DSM includes elevations of surface features such as trees - buildings - bridges and artificial objects such as poles - power lines - cars etc. - and thus contains always the highest elevations of any feature for any given raster cell. A DTM does not include such features but reflects the elevation of bare land surface shapes - excluding elevated or overhanging features.\rDEMs can be obtained using active or passive measurements. Active measurements involve the generation of electromagnetic signals towards a surface and timing the reception of the (return) signal(s). This can be achieved through laser scanning (LiDAR) using visible or infrared light pulses for bathymetric or topographic measurements respectively - radio waves (SONAR) used in bathymetric measurements - or microwaves (synthetic aperture radar - SAR) used in topographic mapping. The most widely known active remotely sensed global DEM is derived from the Shuttle Radar Topography Mission (SRTM) obtained by a SAR mounted on the space shuttle Endeavour - offering  30 m resolution with a vertical accuracy typically between 5 and 20 m - covering 80% of Earth’s surface.\rPassive measurements detect reflection of sun light - or energy radiated from the surfaces. Their distance to the detector can then be inferred from the measurement of angles. Historically - line scanning imagers were used - but nowadays - these are replaced by acquisitions of overlapping 2D frame images. On the images - corresponding land surface features are detected which act as tie-points. The distance between the sensor and the tie-points is calculated in a process called photogrammetry. The most widely known spaceborne passive remotely sensed global DEM is derived from the Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) data onboard the Terra satellite. It offers similar resolution and accuracy compared to SRTM - but with 99% coverage. \rOnly LiDAR can generate both accurate DSMs and DTMs from the same data acquisition - by using multiple returns from a single emitted pulse. All other techniques generate DSMs - from which elevated features can be identified and filtered out in postprocessing to create DTMs - however with typically lower accuracy and more artefacts.,NONE379,IP3-3-2,DSM generation,DSM can be produced automatically from stereo satellite scenes - from satellite sensors such as GeoEye - IKONOS - SPOT-5 - Terra-ASTER etc. The DSM can also be provided from stereo digital aerial photography at various resolutions - depending on the quality and scale of the aerial photography. The quality of the automatic generated DSM is substantially improved if ground measurements from GPS are incorporated in the DSM stereoscopic model.,NONE380,IP3-3,Cross-stereo analysis,Stereo pairs of optical satellite images with the support of ground control points provide a basis for cross-stereo analysis for generating Digital Surface Models.,NONE381,IP3-4-1-1,Filtering,The goal of filtering is to remove unnecessary components from images (e.g. - noise) - while emphasizing the necessary ones. In the context of spatial aggregation - low pass filters aim at removing sharp transitions in the image intensities (high spatial frequencies) and thereby focus the information content of the image on a coarser scale level.,NONE382,IP3-4-1-2,Gridding,Gridding is the technique used to generate a uniform raster grid with one value for every cell in the raster. The values of the raster cells can represent different attributes such as mean - max or min of all Normalized Difference Vegetation Index (NDVI) values measured within a particular cell.,NONE383,IP3-4-1,Spatial aggregation,Spatial aggregation produces images of coarser resolution (grouping pixels in a grid of coarser resolution and calculating mean values) or of coarser scale (by filtering with low-pass filters). Thereby it is a form of generalization that may improve classification results. Spatial aggregation can be applied after classification to get rid of the salt-and-pepper effect.,NONE384,IP3-4-10,Classification features and feature space,Classification processes use features - also known as predictor variables - for discriminating between classes. A feature is an individual measurable property or characteristic of a geographic phenomenon being observed. Features in Earth observation include the individual bands of images and further properties derived from the image data. For example - the single band of a panchromatic image represents a feature that allows distinguishing between pixels of darker and lighter reflectance. Multispectral images have more bands and thereby enable the differentiation between classes by more features. This means - if two classes are different from each other in several of their properties - it becomes easier to distinguish them. The set of features used in a particular classification comprise the feature space where each feature represents one space dimension. \rWith an increased number of features it becomes possible to increase the number of classes that can be separated. For example land cover classifications have a large number of classes. For identifying suitable bands for optical EO satellites - the spectral signatures of all the target classes have to be analysed to identify in which bands they are separable from other classes. Classes like soil - water - and vegetation have spectral signatures that differ in particular in the blue - green - red - and infrared bands of the electromagnetic spectrum. These bands are present in virtually all multispectral sensors used for land cover classification. \rAs geographic phenomena differ by more than their reflectance in different bands - further properties have been used for classification. In addition to multispectral features - the classification may include image derivatives like derived spectral indices - principal components - or filtered bands (convolution layers). Object-based image analysis also uses spatial features - i.e. distance and proximity features - planar geometric features and topological features.,NONE385,IP3-4-2-1,Conditional probability,Bayes’s theorem is an extremely powerful means of using information at hand to estimate probabilities of outcomes related to the occurrence of preceding events. Bayes' Theorem uses a priori (subjective) and conditional probabilities to calculate the probability of an uncertain event occurring. A priori probabilities represent what the modeler believes - before testing - to be the probability of an event occurring. Conditional probabilities are probabilities that other events occur in conjunction with the original event.,NONE386,IP3-4-2-2,Maximum likelihood,Maximum likelihood classification uses the training data for estimating means and variances of the classes - which are then used to estimate the probabilities. This method considers not only the mean - or average - values in assigning classification but also the variability of brightness values in each class.,NONE387,IP3-4-3-1,Land cover classification system (LCCS),The Land Cover Classification System (LCCS) was developed by FAO to provide a consistent framework for the classification and mapping of land cover. Its main objectives were to overcome the rigidity of a-priori land cover classifications - which in many practical situations do not allow easy assignment into one of the pre-defined classes and are therefore not very suitable for mapping. LCCS instead opted for an approach based on two main phases. The first phase is an initial ‘Dichotomous Phase’ - in which eight major land cover types are defined: (1) Cultivated and Managed Terrestrial Areas - (2) Natural and Semi-Natural Terrestrial Vegetation - (3) Cultivated Aquatic or Regularly Flooded Areas - (4) Natural and Semi-Natural Aquatic or Regularly Flooded Vegetation - (5) Artificial Surfaces and Associated Areas - (6) Bare Areas - (7) Artificial Waterbodies - Snow and Ice - and (8) Natural Waterbodies - Snow and Ice. The Dichotomous Phase is followed by a subsequent ‘Modular-Hierarchical Phase’ - in which land cover classes are created by the combination of sets of pre-defined classifiers - which are different for each of the eight major land cover types. For example - common classifiers used for (semi-) natural terrestrial vegetation types are Life Form - Cover - Height - Macropattern. For aquatic or regularly flooded natural and semi-natural vegetation - water seasonality is an indispensable classifier. LCCS offers several advantages from a conceptual point of view. LCCS is a real a priori classification system in the sense that - for the classifiers considered - it covers all their possible combinations. The classification is also hierarchical and the more classifiers used - the greater the detail of the defined land cover class. The classes derived from the proposed classification system are all unique and unambiguous - due to the internal consistency and systematic description of the classes. LCCS is designed to map at a variety of scales - from small to large. From a practical viewpoint LCCS offers several advantages: (1) easy incorporation into GIS and databases - (2) allows flexible response to information available in a given area - project budget and time constraints - (3) unlinks the field data collection from the interpretation process.,NONE388,IP3-4-3,Classification schemes (taxonomies),Long-term monitoring of land cover and land use are particularly relevant for land ecosystem monitoring. Therefore - baseline datasets are necessary that allow assessing changes of land cover and land use where the class definitions remain consistent over time. Accordingly - classification schemes have been established that adhere to taxonomically correct definitions of classes of information organized according to logical criteria. If hard classification is to be performed (i.e. without fuzzy class boundaries) - the classes in the classification system should normally be mutually exclusive - exhaustive - and hierarchical. Mutual exclusive classes have no taxonomic overlap and assign a land cover patch to a single class. An exhaustive classification scheme is able to cover the area of interest comprehensively and leaves no land cover patch unassigned. A hierarchical system allows combining sub-classes into higher-level categories.\rFrom a remote sensing classification perspective - it becomes clear that a classification scheme consists of information classes defined by human beings. Conversely - spectral classes are those inherent to EO data. An analyst must identify spectral classes and label them as information classes that satisfy bureaucratic (or scientific requirements). Additionally - the advantage of using established classification schemes is that their use in scientific studies and applications produces results that are comparable to other studies and suitable for sharing of data.\rEstablished classification schemes include: CORINE land cover (CLC) - Land cover classification system (LCCS) - American Planning Association land-based classification standard - United States Geological Survey land-use/land-cover classification system for remote sensor data - U.S. Department of the Interior Fish & Wildlife Service classification of wetland and deep water habitats of the United States - U.S. National Vegetation Classification system (NVCS) - International Geosphere-Biosphere Program IGBP Land cover classification system.,REMOTE SENSING389,IP3-4-4,Clustering (unsupervised),Unsupervised methods are defined as the identification of natural groups - or structures - within existing data. Clustering requires only the number of to-be generated classes as an input parameter and assigns spectrally defined classes to an image.,NONE390,IP3-4-5-1,Production system,A production system performs automatic transformation of remote sensing imagery into useful information (such as biophysical parameters - categorical maps etc). An example can be a preliminary pixel-based classifier that works top-down (deductive - physical model-driven - prior knowledge-based) and arrives at preliminary classes for each pixel of an image. Such a production system does not require interaction of an operator. The process makes use of a decision tree that encodes the prior knowledge for assigning pixels to a class.,REMOTE SENSING391,IP3-4-5,Decision trees,Decision trees is a data mining technique used in different disciplines including Remote Sensing. It uses a tree-like prediction model to identify a pattern in the input data. One of the most popular decision tree algorithms is the CART (Classification and Regression Tree) algorithm.,REMOTE SENSING392,IP3-4-6-1,Convolutional neural networks (CNN),Convolutional Neural Networks (CNNs) are among the most popular deep learning methods.,NONE393,IP3-4-6,Deep learning,Deep learning approaches have classically been divided into spatial learning (for example - convolutional neural networks for object classification) and sequence learning (for example - speech recognition),NONE394,IP3-4-7-1,Random forest (RF),The RF classifier is an ensemble classifier that uses a set of Classification and Regression Trees (CARTs) to make a prediction The trees are created by drawing a subset of training samples through replacement (a bagging approach).,NONE395,IP3-4-7-2,Support vector machines (SVM),In machine learning - support vector machines (SVMs) are supervised non-parametric statistical learning techniques with associates learning algorithms that analysze data used for both classification and regression analysis. SVM algorithm was originally designed for binary classification. The SVM is based on the main hypothesis that the training set is linearly separable. Given a set of training examples - each marked as belonging to one or another of two categories - an SVM training algorithm builds a model that can assign each new occurrence into one of these two categories - making it a non-probabilistic binary linear classifier. The SVM model is a representation of the examples as points in space - mapped so that the algorithm can find the optimal line (hyperplane) which separates with minimum error the training set - and maximizes the distance - named the “gap” - between the objects of both classes and the hyperplane. Thus - instead of using the whole available training set to describe classes - SVM uses only those training samples that describe class boundaries (support vectors) - thought it can be more efficient than other algorithm because it uses a subset of training points. New occurs are then mapped into that same space and predicted to belong to a category based on the side of the gap on which they fall. In addition to performing linear classification - SVMs can also efficiently perform a non-linear classification using what is called the kernel trick - implicitly mapping their inputs into high-dimensional feature spaces. Unfortunately - because of the technique used for separating classes SVM is less effective on noisier datasets with overlapping classes. When data are unlabelled - supervised learning is not possible - and an unsupervised learning approach is required. SVM is used for text classification tasks such as category assignment - spam detection and sentimental analysis. It is also commonly used for image recognition - performing particularly well in aspect-based recognition and colour-based recognition. SVM also plays a vital role in many areas of handwritten digit recognition - such as postal automation services.,NONE396,IP3-4-7,Machine learning,Field of study that gives computers the ability to learn without being explicitly programmed,NONE397,IP3-4-8,Mental concepts and categories,Image classification operator needs a set of terms to express the characteristics of an image. These characteristics are called interpretation elements and are used to define interpretation keys: tone/hue - texture - pattern - shape - size - height/elevation - location/association,NONE398,IP3-4-9,Sampling strategies,Sampling strategies or sampling pattern specifies the arrangement of observations used for training and/or validation purposes.\rTypically - the simple random sample of a geographic region is defined by first dividing the region to be studied into a network of cells. Each row and column in the network is numbered - then a random number table is used to select values that - taken two at a time - form coordinate pairs for defining the locations of observations. Because the coordinates are selected at random - the locations they define should be positioned at random. The random sample is probably the most powerful sampling strategy available as it yields data that can be subjected to analysis using inferential statistics.\rA stratified sampling pattern assigns observations to subregions of the image to ensure that the sampling effort is distributed in a rational manner. For example - a stratified sampling effort plan might assign specific numbers of observations to each category on the map to be evaluated. This procedure would ensure that every category would be sampled.\rSystematic sampling positions observations at equal intervals according to a specific strategy. Because selection of the starting point predetermines the positions of all subsequent observations - data derived from systematic samples will not meet the requirements of inferential statistics for randomly selected observations.,NONE399,IP3-4,Image classification,The process of image classification extracts information about semantic labels of pixels or objects (i.e. regions) from imagery. Apart of input imagery - the process requires an input set of target classes (classification scheme) for which their spectral (and other) properties have to be identified. A classification method has to be selected that transforms the image data and the classification scheme into semantic map information. In complement to the resulting sematic labelling products - a secondary outcome are instructions or rulesets with the used parameters that constitute the documentation of the classification process.\rThe input imagery consists of one or more images (optical and/or SAR data) of a specific geographic area - collected in multiple bands of the electromagnetic spectrum (that may have already undergone certain pre-processing steps; determined by the purpose). Additionally - the imagery may include derived spectral indices - principal components - filtered bands - or other features to support the classification process.\rThe classification purpose defines the information about the target classes. It includes classification schemes (taxonomies) - spectral signatures for each class and - mental concepts and categories about the classes (that enable an analyst to distinguish classes by texture - spatial relationships etc.). Often - training areas are used to understand how an object of a particular class is discernible in the available imagery and separable from other classes. Both the input imagery and the chosen classification method determine which features of each class can be exploited for classification. For example - spectral signatures of the target classes (extracted from training areas with known class label) may be a suitable input for extracting information with a pixel-based classification. For shape features - objects are a pre-requirement - derived with segmentation. They are only available with object-based classification approaches.\rClassification methods: Various methods exist that can be categorized according to the classification logic that they follow when transforming the input information into the output semantic labelling products. These can be parametric or nonparametric - supervised or unsupervised - per-pixel or object-oriented - semi-automated or fully automatic - and hybrid approaches. Classification methods are for example bayesian techniques like conditional probability or maximum likelihood - clustering (unsupervised) - decision trees - deep learning and machine learning.,NONE400,IP3-5-1,Edge-based segmentation,Edge detection is a fundamental tool used in many image processing applications to obtain information from the frames as a precursor step to feature extraction and object segmentation. This process detects outlines of an object and boundaries between objects and the background in the image. An edge-detection filter can also be used to improve the appearance of blurred image.,NONE401,IP3-5-2,Histogram-based segmentation,Histogram-based segmentation makes use of histogram to select the gray levels for grouping the pixels into regions - e.g. background and the object of interest,NONE402,IP3-5-3,Local variance,Local variance can be calculated as the value of standard deviation in a small neighborhood (e.g. 3x 3 moving window) - then computing the mean of these values over the entire image. The obtained value is an indicator of the local variability in the image.,NONE403,IP3-5-4,Mean-shift segmentation,Mean Shift is defined as finding modes in a set of data samples - manifesting an underlying probability density function (PDF).,NONE404,IP3-5-5,Regionalisation,Regionalization is an important concept in Geographic Information Science for synthesizing multi-dimensional data into homogeneous objects through spatially constrained clustering methods,NONE405,IP3-5-6-1,Multi-resolution segmentation,Multi-resolution segmentation is a region-growing algorithm. It relies on several parameters - which need to be tuned. These include the scale parameter (SP) - which dictates the size and homogeneity of the resultant objects.,NONE406,IP3-5-6-2,Watershed segmentation,Watershed segmentation is a region-based method that has its origins in mathematical morphology. In watershed segmentation an image is regarded as a topographic landscape with ridges and valleys. The elevation values of the landscape are typically defined by the gray values of the respective pixels or their gradient magnitude. Based on such a 3D representation the watershed transform decomposes an image into catchment basins. For each local minimum - a catchment basin comprises all points whose path of steepest descent terminates at this minimum. Watersheds separate basins from each other. The watershed transform decomposes an image completely and thus assigns each pixel either to a region or a watershed.,NONE407,IP3-5-6,Region-based segmentation,Region-based segmentation algorithms can be devided into region growing - merging and splitting techniques and their combinations. Region merging starts from all pixels on the pixel level and iteratively aggregates pixels into objects until some conditions of homogeneity imposed by the user are met.,NONE408,IP3-5-7,Spatial autocorrelation,Spatial autocorrelation is the term used to describe the presence of systematic spatial variation in a variable.,NONE409,IP3-5,Image segmentation,The term image segmentation denotes the process of algorithmically grouping neighbouring pixels that are similar. What sounds rather straight forward - is in fact a great computational challenge - some even call it an ill-posed problem - because there is a high degree of ambiguity in this process. \rThe two attributes in the general definition provided above - i.e. neighbouring and similar - evoke the principles of regionalisation as a fundamental concept in geography. Regionalisation is the bottom-up approach to congregate adjacent elements with the aim to form a larger unit. (Conversely - this could be understood in a top-down manner when subdividing a larger whole into smaller homogeneous units). This follows the general notion of hierarchical organisation according to general systems theory (GST). The organisation of a state in smaller administrative units is a good example for a hierarchical structure - the composition of the human body by organs - cells - etc. another. In image analysis such regions are commonly referred to image regions - originating from the concept of “photomorphic regions” - literally meaning regions formed on images – originally by human interpreter through manual delineation. Today - advanced pixel grouping algorithms aim to delineate homogenous regions in an image automatically. As those regions usually are assumed to match with real-world objects - it is often stated in literature that image segmentation generates image objects. Deriving some general heuristics on their properties (colour - size - shape - orientation - etc.) we can label these objects according to a given semantic scheme. The procedure of object delineation and classification using object features and relations is a fundamental principle in object-based image analysis (OBIA). \rDue to the effect of spatial autocorrelation (the tendency of neighbouring pixels to be similar irrespective of scale or geographical location) - pixel grouping is ambiguous and by no means trivial - but not arbitrary either. Intuitively - image regions are those quasi-homogeneous areas that we perceive as landscape units on a specific scene (a lake - a forest patch - a single tree - a building - a residential area). According to hierarchy theory - we can assume that we find multiple scales within a single image even - according to the level of detail we are interested in. Whether or not a specific grouping of pixels is considered valid - e.g. because it corresponds to a real-world object - can hardly be answered unanimously - but rather needs to be judged by experts in the respective application domain. That is why often in literature we find the term ‘meaningful objects’. \rImage segmentation is as a sub-field of computer vision and aims to apply computer algorithms to generate image regions (a.k.a. tokens) within digital image analysis. There are several strategies for performing image segmentation - all resting on the following general principles: (1) regions do not overlap; (2) regions are (relatively) homogenous; regions are (relatively) different to neighbouring regions; regions are fairly equally sized (belong to one scale domain) but can be built in several hierarchical scales. General strategies include (1) edge-based segmentation and (2) region-based segmentation - and multi-scale segmentation as a specific case. \rAlso referred to spatial classification emphasizing the constraint of spatial contingency - image segmentation aggregates neighbouring pixels - but – as compared to statistical clustering techniques – does not provide a unique set of classes (either semantic or statistic) in the feature space. \rRecently the term semantic segmentation has emerged in the machine-learning community - which is in fact a combination of segmentation and categorisation (labelling) via deep learning methods (e.g. convolutional neural networks).,NONE410,IP3-6-1,Combined filtering,Combined filtering uses different filters to arrive at more complex filters for specific purposes. \rFor example - Laplacian filters are derivative filters used to find areas of rapid change (edges) in images. Since derivative filters are very sensitive to noise - it is common to smooth the image (e.g. - using a Gaussian filter) before applying the Laplacian. This two-step process is called the Laplacian of Gaussian (LoG) operation.,NONE411,IP3-6-2,Edge detectors,The aim of sharpening filters is to highlight transitions in intensity (high frequency components) using different operators: directional (horizontal - vertical - diagonal) or isotropic (e.g. Laplacian Filter). Example of edge detectors include: Gaussian edge detector - Laplacian filter etc.,NONE412,IP3-6-3-1,Lee-Sigma,The Lee-sigma filter is a conceptually simple but effective alternative to the Lee and other sophisticated adaptive filters. It is based on the sigma probability of the Gaussian distribution.,NONE413,IP3-6-3,High-pass filtering,High-pass filtering enhance information of high frequencies (local extremes - lines - edges),NONE414,IP3-6-4-1,Gauss filter,Gaussian Filters are isotropic (same behavior in all directions).,NONE415,IP3-6-4,Low-pass filtering,Spatial filters transform an image by taking into account the local neighborhood of a pixel. The goal of filtering is to remove unnecessary components from images (e.g. - noise) - while emphasizing the necessary ones. In this context - low pass filters aim at removing sharp transitions in the image intensities (high spatial frequencies).,NONE416,IP3-6,Neighbourhood analysis (convolution),In contrast to the point operations used for radiometric modification of image data - techniques for geometric processing are characterized by operations over local neighborhoods of pixels. The result of a neighborhood operation is still a modified brightness value for the single pixel at the center of the neighborhood  - however the new value is determined by the brightness of all the local neighbors rather than just the original brightness value of the central pixel alone.,NONE417,IP3-7-1,Class modelling,Class modelling provides flexibility in designing a transferable workflow from scene-specific high-level segmentation and classification to region-specific multi-scale modelling,NONE418,IP3-7-2,Hierarchical representation,Hierarchical representation refers to hierarchically scaled compositions of the classes to be classified.,NONE419,IP3-7-3,Per-parcel analysis,Per-parcel analysis relies on parcels or objects as the smallest units of image analysis. The parcels are usually obtained through image segmentation that partition the input images into homogeneous units - i.e. parcels - in a supervised or unsupervised manner.,NONE420,IP3-7-4-1,Distance and proximity features,Distance relationships describe how far an object is with respect to a reference. Proximity analysis allows the identification of the distance between a geographic feature of interest and its neighbors.,NONE421,IP3-7-4-2,Planar geometric features,The most important geometric features of geographic objects are their size and shape.  Shape refers to general form or outline of individual objects and can be quantified using different metric such as shape index - compactness - asymmetry - density - elliptic fit - roundness - rectangular fit etc.,NONE422,IP3-7-4-3,Topological features,Topological features characterize qualitatively the position of spatial objects relative to each other. There are different models for representing topological relationships.  Calculus-based method - for example -  allows us to model five topological relationships  of two spatial objects: touch - in - cross - overlap - disjoint.,NONE423,IP3-7-4,Spatial features,An object of a specific object class has a value on the range of values of a spatial or spectral feature. A set of features provides the feature space that is used for classification.,NONE424,IP3-7,Object-based image analysis (OBIA),OBIA is an iterative method that starts with the segmentation of satellite imagery into homogeneous and contiguous image segments (also called image objects. In the next step - resulting image segments are assigned to the target classes.,NONE425,IP3-8-1,Feature space polyhedralization,The feature space represents in various dimensions all the features that can be used for classification (e.g. image bands - band math parameters - derived texture properties). A point in that space is also called a vector with values for each feature (or dimension). Polyhedralization is a form of vector space quantization where a vector is assigned to the closest centre point of one polyhedron.,NONE426,IP3-8-2,Radiative transfer modelling,Radiative transfer models describing the interaction between matter and electromagnetic radiation serve as cornerstones for optical remote sensing. The radiative transfer theory provides the most logical linkage between observations and physical processes that generate signals in optical remote sensing. Radiative transfer modelling is therefore an integral part of  remote sensing - since it provides the most efficient tool for accurate retrievals of Earth properties from satellite data. Radiative transfer models  are used in a number of different applications such as sensor radiometric calibration - atmospheric correction and the modelling radiation processes in vegetation canopies. \rVegetation radiative transfer models (RTMs) study the relationship between leaf and canopy biophysical variables and reflectance - absorbance and scattering mechanisms. The infinite variability of vegetation structure complicates the modeling of RT in vegetation canopies. Numerous models of RT in vegetation canopies were developed in the second half of the last century. Models differ by the details accounted for and by the simplifications introduced in the description of canopy structure and photon–vegetation interactions. Gradual improvement in RTMs accuracy - yet in complexity too - have diversified RTMs from simple turbid medium RTMs towards advanced Monte Carlo RTMs that allow for explicit 3D representations of complex canopy architectures. This evolution has resulted in an increase in the computational requirements to run the model - which bears implications towards practical applications. When choosing an RTM - a trade-off between invertibility and realism has to be made: simpler models are easier to invert but less realistic - while advanced models more realistic but require a large amount of variables to be configured. The two most widely used models are the leaf model PROSPECT and Scattering by Arbitrary Inclined Leaves (SAIL) canopy model. \rAtmosphere RTMs study the interaction of radiation with the atmosphere. The remotely-sensed signals at satellite or airborne platforms are combinations of surface and atmospheric contributions - with relative amounts varying across the two wavelength regions - depending on the condition of the atmosphere.  The order of magnitude of atmosphere signals can be equal or larger than that of land or ocean surface signals that arise at the top of the atmosphere (TOA). In order to derive accurate sensor calibration and atmospheric correction - the contribution of the atmospheric constituents to the total retrieved signal must be understood and modelled. Atmospheric radiative transfer models simulate the radiative transfer interactions of light scattering -  absorption and emission through the atmosphere. Some widely used atmospheric RTMs are 6SV - libRadtran - MODTRAN - and ATCOR.\rAdvances in radiative transfer modeling enhance our ability to detect and monitor changes in our planet through new methodologies and technical approaches to analyze and interpret measurements from air- and space-borne sensors.,REMOTE SENSING427,IP3-8,Physical-model based analysis,Historically - physical modelling and machine learning have often been treated as two different fields with very different scientific paradigms (theory-driven versus data-driven). Yet - in fact these approaches are complementary - with physical approaches in principle being directly interpretable and offering the potential of extrapolation beyond observed conditions - whereas data-driven approaches are highly flexible in adapting to data and are amenable to finding unexpected patterns (surprises).,NONE428,IP3-9-1,Difference of Gaussian (DoG),Difference of Gaussians (DoG) method consists of subtracting two Gaussians - where a kernel has a standard deviation smaller than the previous one. The convolution between the subtraction of kernels and the input image results in the edge detection of this image.,NONE429,IP3-9-2,Scale invariant feature transformation (SIFT),Scale Invariant Feature Transform (SIFT) is an image descriptor for image-based matching and it is used for a large number of purposes in computer vision related to point matching between different views of a 3-D scene and view-based object recognition. The SIFT descriptor is invariant to translations - rotations and scaling transformations in the image domain and robust to moderate perspective transformations and illumination variations. Experimentally - the SIFT descriptor has been proven to be very useful in practice for robust image matching and object recognition under real-world conditions.,NONE430,IP3-9,Scale space analysis,Scale-space theory is a framework for multiscale image representation - which has been developed by the computer vision community with complementary motivations from physics and biologic vision. The idea is to handle the multiscale nature of real-world objects - which implies that objects may be perceived in different ways depending on the scale of observation. If one aims to develop automatic algorithms for interpreting images of unknown scenes - there is no way to know a priori what scales are relevant. Hence - the only reasonable approach is to consider representations at all scales simultaneously.,NONE431,IP3,Image understanding,Image data - in order to be turned into information - require interpretation. Thereby image understanding is the process of scene reconstruction - the description and mental representation of the content of imaged - and potentially complex - realities. \rImage understanding thereby goes beyond single feature extraction. Instead - it aims at  a complete description of the image content - i.e. the reconstruction of a real-world scene. In the early days of digital image processing - image understanding was mainly confined to identifying and labelling image primitives. Today - advanced mapping keys and hierarchical classification schemes to analyse EO data - include composite and complex target classes. Thereby ‘full’ scene description means reaching from signal processing to a symbolic representation of the scene content. This entails the relationships of real‐world objects in different scales and spatio-temporal aspects.\rDescribing a scene - visually or computer-aided or mixed - depends on a conceptual framework comprising (a) the underlying research question within (b) a specific field of application and (c) pre‐existing knowledge and experience of the operator. Obtaining insights from imagery requires general knowledge about the expected scene content and domain expertise. The field of image understanding is interlinked with image (pre-)processing - computer vision - and artificial intelligence (AI). Image processing conditions the data material and enhances the interpretation source. Computer vision including pattern recognition providing knowledge representation - expert systems. AI is mainly concerned with automation processes - be it via  knowledge transfer to an automated system or machine / deep learning.\rIn analogy to the human mind - image understanding is the computational process of extracting information from images - i.e. locating - characterizing - and recognizing objects and other features in the depicted scene. However - image understanding is not a linear - but rather a cyclic process and takes place during the pre-processing and data assimilation steps. For example - cloud masks on EO images is an early product of image understanding - prior to many pre-processing tasks.\rIn a typical GEOBIA workflow - the process of image understanding can be illustrated by the following steps: Starting from the subset of a real‐world scene captured on an image first step may entail scaled representations by grouping neighbouring pixels on several hierarchical sales. The multi‐scale segmentation provides a set of nested objects with geospatial and spectral properties to be used in the classification process. \rWith object hypotheses in mind the object relation modelling can be realized by encoding expert knowledge into a rule system. This setp aims at categorizing the image objects by their spectral and spatial properties and their mutual relationships. Hereby - an object‐centred view is accomplished. This representation of the image content should meet the conceptual reality of the interpreter or user. Knowledge is stepwise adapted and improved through progressive interpretation and modelling. Experience grows - as knowledge will be enriched by analyzing unknown scenes and the transfer of knowledge may incorporate or stimulate new rules.,NONE432,IP4-1-1,Accessibility,Once the user finds the required data - she/he needs to know how can they be accessed - possibly including authentication and authorisation.,NONE433,IP4-1-2,GEO QA4EO,Quality Indicators (QIs) should be ascribed to data and - in particular - to delivered information products - at each stage of the data processing chain - from collection and processing to delivery. A QI should provide sufficient information to allow all users to readily evaluate a product’s suitability for their particular application - i.e. its “fitness for purpose”.,NONE434,IP4-1-4,ISO standards,ISO is an independent - non-governmental international organization with a membership of 164 national standards bodies. Through its members - it brings together experts to share knowledge and develop voluntary - consensus-based - market relevant International Standards that support innovation and provide solutions to global challenges. ISO/TC 211 Geographic information/Geomatics provides Standardization in the field of digital geographic information. Note: This work aims to establish a structured set of standards for information concerning objects or phenomena that are directly or indirectly associated with a location relative to the Earth. These standards may specify - for geographic information - methods - tools and services for data management (including definition and description) - acquiring - processing - analyzing - accessing - presenting and transferring such data in digital / electronic form between different users - systems and locations.,NONE435,IP4-1-5,OGC standards,The OGC is the worldwide leading consortium of GIS industries promoting the interoperability of geographic information across platform - system - and country borders. The main field of current activity is the complete integration of the sources of geographic information based on the Internet.The Open GIS Consortium (OGC) plays an important role on the implementation level.,NONE436,IP4-1-6,Replicability and reproducibility,A fundamental pillar in (open) science is to verify the scientific results of others to advance knowledge. The lack of reproducibility in scientific studies brings challenges in understanding and recreating the results of others - a situation that may be common in data-based and algorithm-based research like in geocomputation. In general - many authors define reproducibility as the ability to compute exactly the same results of a study based on original input data and analysis workflow. In other words - “to rerun the same computational steps on the same data the original authors used”.  Replicability is often seen as obtaining similar conclusions about a research question derived from an independent study or experiment. In the field of GIScience and geocomputation - in particular - a reproduction is always an exact copy or duplicate - with exactly the same features and scale - while a replication resembles the original but allows for variations in scale - for example. Hence - reproducibility is exact whereas replicability means confirming the original conclusions - although not necessarily with the same input data - methods - or results.,NONE437,IP4-1-7,Reusability,The ultimate goal of FAIR is to optimise the reuse of data. To achieve this - metadata and data should be well-described so that they can be replicated and/or combined in different settings.,NONE438,IP4-1,Data quality standards,Data quality standards are guiding principles and operational guidelines for the production and use of data. For example - QA4EO aims for the two key principles of accessibility / availability and suitability / reliability. The QA4EO guidelines provide instructions for the implementation of processes that follow these principles. Standards emerge from standardization processes within the community. They are based on the agreement of the members of the community.,NONE439,IP4-2-1-1,Error matrix,To correctly perform a classification accuracy (or error) assessment - it is necessary to systematically compare two sources of information: (1) pixels or polygons in a remote sensing-derived classification map - and (2) ground reference test information (which may in fact contain error). The relationship between these two sets of information is commonly summarized in an error matrix (sometimes referred to as contingency table or confusion matrix). Indeed - the error matrix provides the basis on which to both describe classification accuracy and characterize errors - which may help refine the classification or estimates derived from it.,REMOTE SENSING440,IP4-2-1-2,F-score,F-score represents the harmonic mean between precision and recall. As F-score combines both precision and recall - it can be regarded as an overall quality measure. The range of F is from 0 to 1 with larger values representing higher accuracy.,NONE441,IP4-2-1-3,Ground reference,Ground reference refers to the reference dataset for an accuracy assessment of a remote sensing classification. The process of obtaining ground reference is dedicated to support the production of suitable accuracy information. A sampling design (fitting to the produced image classification) determines the most appropriate distribution of sample locations (or regions). The response design consists of the evaluation protocol and the labeling protocol. The evaluation protocol initiates selecting the support region on the ground (represented by a pixel or polygon) where the ground information will be collected. Once the location and dimension of the sampling unit are defined - the labelling protocol is initiated and the sampling unit is assigned a hard or fuzzy ground reference label. This ground reference label (e.g. forest) is paired with the remote sensing-derived label (e.g. - forest) for assignment in the error matrix.,REMOTE SENSING442,IP4-2-1-4,Kappa statistics,Kappa is a value for measuring the overall accuracy of a classification that accounts for randomness of class assignment. Kappa analysis is a discrete multivariate technique of use in accuracy assessment. Kappa yields a statistic - ^K - which is an estimate of Kappa. It is a measure of agreement between the remote sensing-derived classification map and the reference data as is indicated by a) the major diagonal and b) the chance of agreement - which is indicated by the row and column totals in the error matrix.,REMOTE SENSING443,IP4-2-1-5,Precision & recall,These two quality assessment indicators are calculated as follows:\rPrecision = TP/(TP+FP) \rRecall = TP/(TP+FN) -\rwhere TS is true positive - FP is false positive - FN is false negative,NONE444,IP4-2-1-6,Root mean square error (RMSE),Geometric correction procedures (image-to-map rectification - image-to-image rectification) are used to rectify remotely sensed data to a standard map projection whereby it may be used in conjunction with other spatial information in a GIS to solve problems. The rectification process normally involves selecting ground control point (GCP) image pixel coordinates (row and column) with their map coordinate counterparts (e.g. meters northing and easting in a UTM map projection). Rectification requires that polynomial equations (that translate from image coordinates to map coordinates) be fit to the GCP data using least squares criteria. Depending on the distortion in the imagery - the number of GCPs used - and the degree of topographic reliefdisplacement in the area - higher -order polynomial equations may be required to geometrically correct the data. To determine how well the six coefficients derived from the least-squares registration of the initial GCPs account for geometric distortion in the inpit image - for each GCP - the root-mean-square error (RMSE) is computed.,NONE445,IP4-2-1,Accuracy assessment,A growing set of EO services and applications produce EO products that describe various aspects of the land - ocean and atmosphere. These products include for example image products at different processing levels - geometric measurements like in digital elevation models - semantic labelling products like land cover classifications - and EO-derived attribute products concerning air quality or other geophysical and biophysical parameters. Same as any geospatial data - EO products are not free of error and require accompanying documentation of their product quality. One term for describing different quality dimensions of an EO product is accuracy.\rAccuracy is a measure to estimate the uncertainty that originates from errors. An error is the deviation of a map value from a true value. The concept of error assumes well-defined phenomena where deviation results from imperfection of measurement equipment - environment effects - or imperfections of the observer. They cause gross errors and blunders - systematic errors - and random errors - for which different approaches are necessary to minimize error. Ideally - only random error remains that is probabilistic in nature and can be assessed with statistical approaches. For poorly defined phenomena - the concept of vagueness applies. For example in the case of thematic maps using fuzzy sets - the accuracy assessment requires a fuzzy approach as well. \rJudging error requires reference data with higher accuracy (by an order of magnitude) to which the map value can be compared. EO product quality dimensions about accuracy include thematic accuracy - spatial accuracy (both horizontal and vertical) - radiometric accuracy - and accuracy of biophysical/geophysical parameter measurements. Respective equipment and approaches for reference data collection includes ground verification for thematic maps - GNSS positioning devices - field spectrometers - air quality sensors and in-situ biomass estimation. Ideally - reference data is collected in the field. In case of inaccessible areas of interest and/or if the service requirements allow it - approaches may rely on proxy reference data.\rThe design of the accuracy assessment procedure should be done with the EO product design to match the requirements of the EO service. For example - a thematic accuracy assessment consists of the main three components of response design - analysis - and sampling design. The response design ensures that reference data and map data are comparable at a location and specifies under which cases they agree or disagree. The analysis - usually performed with an error matrix - specifies which quality indicators will be calculated to quantify accuracy. The sampling design specifies the subset of locations at which the response design will be applied. Depending on the classification process and application case - different sampling strategies can be suitable (e.g. clustered sampling - stratified random sampling). \rFor other accuracy dimensions - respective accuracy assessment procedures exist - e.g. root mean squared error (RSME) for the positional accuracy assessment.\rAfter an accuracy assessment has been performed and the uncertainty in the EO product is understood - the challenge is to clarify how the uncertainty affects subsequent spatial analyses with the EO product. Different strategies exist that ignore error completely or that account for error by modelling uncertainty in the analysis outcomes. If uncertainty is judged low enough (or more hazardous - if users are unaware of the limited accuracy) - subsequent analyses accept the EO product as true and ignore the accuracy value. If uncertainty is incorporated in subsequent analysis through uncertainty modelling - the results describe the bandwidth of outcomes - potentially supported with appropriate visualisations of uncertainty. The uncertainty modelling approach may greatly enhance the usability of the EO product - because it informs better how the error impacts the EO information and how much confidence a user should have in it.\rWith a new generation of EO products on the horizon and a largely increased user community - a large number of new applications is to be expected. They may also identify innovative accuracy assessment approaches. For example - the availability of EO archives with long time series of EO data led to response design protocols tailored to collect time series of reference data. The use of volunteered geographic information (VGI) as reference data has great potential - if approaches are implemented that ensure its reliability. Methods for object-based accuracy assessment are continued to be developed. Further - the increasing number of EO parameter products based on continuous variables creates the need to describe their accuracy. Finally - the focus on validation of EO products during EO service development and operation will make feedback from users available to service providers - ultimately leading to more meaningful EO products with more meaningful accuracy metrics and other quality indicators.,NONE446,IP4-2-2,Timeliness,The implementation of a service that provides remote sensing derived information on a regular basis introduces process-related quality criteria like the timeliness of information provisioning. For the case of refugee camp mapping - timely arrival of map information may be critical to support the decisions in planning facilities for humanitarian assistance.,REMOTE SENSING447,IP4-2-3-1,Completeness,Completeness is a quality dimension that can apply to different data properties.The Data completeness is dealing with the completeness of an image - handling for example the effect of shadowing objects - sun flares on water surfaces or masking out by an object (e.g. propeller of a UAV). Spatial completeness is a feature on the area coverage. In photogrammetry (especially in stereophotogrammetry) its 3D version - the stereo completeness has extreme importance. In monitoring systems and applications the Temporal completenesster term features how the taken images represent a complete time series. The thematic completeness measure describes the image interpretation quality how the expected and defined classes are evaluated. This feature is important with the use of e.g. multiple classifiers.,NONE448,IP4-2-3-2,Consistency,In remote sensing we can speak about spatial consistency in the Consistency cluster. It represents the quality of image interpretation/understanding: how are the different objects or classes recognized/evaluated integrally. A bridge above a water surface - like river can be detected in pixel-wised manner - but the question is how coherent they are in the output map. This phenomenon has very close to the thematic consistency - where the recognition integrity is represented in this way. The topological consistency is defined mainly for network-type surface objects - like roads or rivers - where the connection of all atomic segments are rated by this measure. Urban mapping focuses on the built environment objects - where e.g. house-parcel inclusions are described by this feature. The temporal consistency is for monitoring again - representing for example the possibility or impossibility of land cover changes in time. Having multiple data sources (even airborne or terrestrial) - their integral usage can be qualified by this measure.,REMOTE SENSING449,IP4-2-3-3,Readability,Readability refers to the content of a map being presented clearly enough that the content can be perceived and understood by the user. This includes legibility - e.g. whether the text of a label is large enough to be read and has enough contrast to the background to be easily perceivable. Additionally - readability has a broader meaning that explains whether a product as a whole is simple enough to be understood and not too complex that essential information can be overlooked by the user.,NONE450,IP4-2-3,User validation,Gathering information about the quality of an EO product or service by letting the user test it. The feedback from the user enables to verify whether specific quality criteria have been met.,NONE451,IP4-2,Product quality,A product in the sense of something that a user can use for a specific purpose requires a certain quality. Therefore - its accuracy needs to be judged with an accuracy assessment measure that the user understands and where he can interpret the meaning in relation to the purpose. The product has to be validated - i.e. it has to be known whether the product qualifies for use in a certain context. And in addition - the product needs to be available in time that the users can base their decision on it.,NONE452,IP4-3-1,Cloud cover percentage,The cloud cover percentage indicates the amount of area in the remote sensing image extent that is covered with clouds and therefore cannot provide information about the Earth surface conditions.The actual types of clouds included may depend on the product - but the CEOS definition includes cloud shadow. Next to that - from an optical remote sensing point of view - clouds can be roughly classified in: opaque/dense clouds - mainly composed of droplets that are highly reflective in the VIS region and generally located at low-medium altitudes and cirrus - consisting of a large number of thin non-spherical ice crystals that are normally translucent in the VIS region - relatively highly reflective in the SWIR spectrum - and located at high altitude.\r\rThe goal of cloud cover percentage is to provide a quality measure of usable information in a surface reflectance image. Earth observation product catalogs support it as a query parameter - to enable searching for products with a cloud cover percentage below a given threshold.\rThis simplifies for instance use cases that require only fully clear products (0% cloud cover) - and may save download and processing resources by only handling images that have some valid pixels. For instance - by only using products with a cloud cover percentage smaller than 99.95%. The measure also gives an estimate of the number of valid observations in a given geographical area - allowing a quick assessment of whether minimal data requirements for a specific use case are met.\r\rThe measure is a percentage of actual observations in an image - so pixels where no data was recorded are not included. For derived products - cloud cover pixels are often also flagged separately from pixels where no data was recorded - but this may depend on the data provider. The definition specifically also includes cloud shadow pixels.\rReliable cloud cover percentages depend on good cloud and cloud shadow detection methods. Especially handling of translucent cirrus clouds is an open issue: a product that has a 100% cloud cover percentage due to cirrus clouds might still be usable for some cases - while for other cases they also render the product useless. \r\rThe used cloud detection algorithm will also affect the cloud cover percentage. A more strict algorithm will yield higher percentages compared to an algorithm that under detects clouds.\rDue to these limitations - cloud cover percentages in product metadata have a fairly high error margin. The user should take this into account when determining optimal cloud cover percentage thresholds for the use case.,REMOTE SENSING453,IP4-3-2,Remote sensing lifecycle,The remote sensing lifecycle structures all possible phases of the data production process - from its beginning of the data's coming to existence (that includes the sensor design prior to data collection) over storage - processing and use to archiving and deletion.,REMOTE SENSING454,IP4-3-3,Capability to resolve anything,The capability of a sensor or EO product to resolve anything is a function of its (spatial - temporal - spectral and radiometric) resolution and of the detail at which a geographic phenomenon of interest manifests itself in time and space. A geographic phenomenon can be named or described - georeferenced and provided with a time interval at which it exists. The geographic phenomenon of interest is the one of which a user needs information to help him make a decision. Therefore - the geographic phenomenon needs to be resolved with a low enough uncertainty and a high enough quality that allows the user to make a decision with confidence. \rFor example - let’s consider a helicopter pilot that wants to know whether a specific site is suitable for an emergency landing. The decision to perform an emergency landing may be supported with an EO-derived digital map of emergency landing sites that are flat enough (as well as large enough for the pilot’s helicopter and free of any obstacles on the surface and in the approach area). If we only focus on the flatness of the terrain - we need a digital elevation model (DEM) of high enough spatial resolution and accuracy in the Z dimension to calculate slope within acceptable levels of uncertainty. The pilot probably can tell us what degrees of slope are okay for his helicopter and tell us sites (e.g. football fields) where such a landing would succeed. However - this is only the input to an analysis of different DEMs to identify the minimum spatial resolution and accuracy in the Z dimension to model slope products and associated uncertainty to derive an emergency landing site product that fulfils the requirements. Thereby the capability of different DEMs to resolve emergency landing sites can be analysed.\rSpatial resolution is a measure of the smallest angular or linear separation between two objects that can be resolved by the remote sensing system. A useful heuristic rule of thumb is that in order to detect a feature - the nominal spatial resolution of the sensor should be less than one-half the size of the feature measured in its smallest dimension.\rOther types of resolution of an EO dataset are available that determine for various geographic phenomena under investigation whether it is possible to resolve them in the data. These are radiometric resolution - spectral resolution and temporal resolution. Radiometric resolution is defined as the sensitivity of a remote sensing detector to differences in signal strength as it records the radiant flux reflected - emitted - or back-scattered from the terrain. Spectral resolution is the number and dimension (size) of specific wavelength intervals (referred to as bands or channels) in the electromagnetic spectrum to which a remote sensing instrument is sensitive. The temporal resolution of a remote sensing system generally refers to how often the sensor records imagery of a particular area. For time-series analysis - the temporal resolution determines the time granularity for resolving processes that underlie the change that is observable between subsequent images.,REMOTE SENSING455,IP4-3-4,Spatial coverage,The spatial coverage of a dataset (consisting of an image or a series of images) determines whether the dataset covers the area of the terrain that is of interest to the user of information derived from the dataset.,NONE456,IP4-3-5,Temporal validity,The temporal validity of a dataset (consisting of an image or a series of images) determines whether the acquisition date(s) (and period) match(es) the requirements for investigating a specific phenomenon and thereby enables the derivation of information about that phenomenon.,NONE457,IP4-3,Quality indicators,Values (or a value) that enable(s) judging a dataset or product on their fitness for a specific purpose (e.g. whether a specific satellite image is suitable for mapping landslides).  - A QI should provide sufficient information to allow all users to readily evaluate a product’s suitability for their particular application - i.e. its “fitness for purpose”.,NONE458,IP4,Image data quality,Data quality - in general - is the degree of data usability in relation to a specific application purpose. Assurance of data quality is of growing importance in remote sensing - due to the increasing relevance of remote sensing data in planning and operational decision of public bodies and private firms - and the huge amount of digital services (or apps) that exploit RS data. \rDifferent data quality dimensions exist according to the lifecycle phases of the remote sensing data: data acquisition - data storage - data pre-processing - processing and analysis and data visualization and delivery. Remote sensing data acquisition phase involves the following quality aspects: resolution - accessibility - spatial accuracy - temporal validity - accuracy and precision of the sensor calibration. Resolution is a multi-dimensional concept that includes the following dimensions: spatial resolution - temporal resolution - radiometric resolution - spectral resolution and temporal resolution. Temporal validity refers to the quality of an remote sensing data product in time - whereas spatial accuracy refers to the accuracy of the position of features relative the Earth.  \rData storage includes the accessibility and completeness data quality dimensions.  Accessibility includes both temporal and data accessibility. Temporal accessibility refers to the time delay between data acquisition and data delivery - whereas data accessibility refers to the availability of remote sensing data. Data completeness encompasses temporal completeness - i.e. completeness of a time series represented a phenomenon - thematic completeness - and spatial completeness which refers to the area coverage. Data preprocessing - processing and analysis phase includes consistency - completeness - temporal validity - resolution - radiometric and geometric accuracy - thematic and semantic accuracy. Thematic and sematic accuracy refers to the correctness of the remote sensing data product. The main quality dimensions of the data visualization and delivery include readability - completeness and temporal validity. \rDifferent metrics can be used to assess the quality of the remote sensing-derived information - such as the root-mean-square error (RMSE) measuring the differences between the true and measured values of the phenomenon under investigation - confusion matrix used for assessing the classification performance - producer’s accuracy - user’s accuracy or Cohen kappa. The quality of the remote sensing data per se can be assessed using Peak Signal-to-noise Ratio (PSNR) or the Universal Image Quality Index (UIQI).\rDifferent organizations are involved in the standardization of the image data and gridded data quality - including ISO/TC 211 ‘Geographic information/Geomatics’ - Open Geospatial Consortium (OGC) or the Quality Assurance Framework for Earth Observation (QA4EO) developed by the Group on Earth Observation (GEO). These organizations are responsible for developing metadata standards that are further used by the remote sensing community to document the quality of the remote sensing data. According to the QA4EO - for example - all remote sensing data products need to be accompanied by a Quality Indicator (QI) which helps users assessing their fitness-for-use.,REMOTE SENSING459,IP5-1-1,Array databases,Array databases make use of arrays as the primary storage representation. Such an array-oriented data model and query language is useful in many scientific applications - where the raw data consists of large collections of imagery or sequence data that needs to be filtered - subsetted - and processed.,NONE460,IP5-1-2,Open data cube,The Open Data Cube (ODC) is a non-profit - open source project that was motivated by the need to better manage Satellite Data. This project was born out of the work done under the 'Unlocking the Landsat Archive' and the Australian Geoscience Data Cube (AGDC) projects.,NONE461,IP5-1,Data cubes,The term data cube originally was used in Online Analytical Processing (OLAP) of business and statistics data. Technically speaking - such a data cube represents a multidimensional array together with metadata describing the semantics of axes - coordinates - and cells. It is an efficient approach to the management and analysis of large datasets.,NONE462,IP5-2-1,Content-based image retrieval,Content-based image retrieval helps users retrieve relevant images based on their contents.,NONE463,IP5-2-2,Web portals,Web Portals allow users to discover - understand - view - access and query information of their choice from local to global level for a variety of uses.,NONE464,IP5-2,Image archives,Image archives are repositories for storing - managing and retrieving remote sensing data.,REMOTE SENSING465,IP5-3-1,Data and information access service (DIAS),As an initiative stipulated by the European Commission to foster the bridge between the Copernicus ground segment and the user segment - the Copernicus data and information access service (C-DIAS) is a generic name for different sets of cloud-based platforms providing centralised access to Copernicus data and information - as well as to processing tools. The name indicates - however - that the focus of such advanced user-centred infrastructure implementations is not only on data access - but also on ‘information’. What is specifically meant here is the provision of information services and information layers as defined in the Copernicus service portfolio. This allows the users to develop and host their own applications in the cloud and a single access point - rather than processing data locally. Currently there are five different DIAS’s implemented (CREODIAS - SOBLOO - MUNDI - WEKEO - ONDA) - all with some specific technical assets - or a sector-specific application focus or any other unique selling position by e.g. targeting as specific user community. Currently - the DIAS - which have received co-funding from the European Commission as a kind of seed funding - are currently in the process of exploring opportunities and claiming market shares - striving to sustain in a competitive manner. Some of the features are highlighted in the following - without explicitly mentioning any of the associated DIAS: (i) data access of global data sets (satellite data mosaics or gridded data) by custom area; (ii) OGC interfaces - VM catalogue - SPAR QL search interface (combine searches like receive images over areas of high population density) - open source (accessible via API) or pay-per-use; (iii) access to core service products (e.g. CLMS - CMEMS - CAMS); (iv) focus on integrated applications such as smart cities - urban energies - precision agriculture; access to third-mission VHR satellite data (e.g. Pléiades); (v) utilizing GitLab as a developer platform.,NONE466,IP5-3-2,OGC interfaces and OGC web processing service,The OpenGIS® Web Processing Service (WPS) Interface Standard provides rules for standardizing how inputs and outputs (requests and responses) for geospatial processing services are defined. It defines an interface that facilitates the publishing of geospatial processes and clients’ discovery of and binding to those processes.,NONE467,IP5-3,Online processing,Online processing allows users to implement and run image analysis operations online independent of the underlying software.,NONE468,IP5,Infrastructure,In general - infrastructures such as cyberinfrastructures or Spatial Data Infrastructures (SDIs) - allow information sharing across distributed infrastructures and communities. SDIs  have gradually changed from a pool of authoritative data shared using standardized web services to a pool where the authoritative data co-exist with data collected by volunteers and different sensors. Many efforts were dedicated to data documentation - to improving the catalogues searching techniques by means of - for example - thesauri and to sharing these data using standardized web services such as Web Map Service - Web Feature Service or Web Coverage Service. Cloud computing technologies played an important role in the implementation of sustainable SDIs due to their ability to provide on-demand computational and storage capacities over the Internet. In this way - users can easily search - find and use data shared across different online platforms.\rMore specifically - infrastructures for image processing and analysis refer to the physical and organizational facilities that allow the storage - analysis and management of the available data and products. Traditionally - this infrastructure formed a digital image processing system consisting of computer hardware with special-purpose image processing software - and peripheral input-output devices (e.g. CD or DVD drives - internet access - printers/plotters). In recent years - Earth observation is undergoing a shift to online processing making use of data cubes and vast image archives - e.g. NSF EarthCube or Digital Earth Australia - the Swiss Data Cube - the EarthServer - the E-sensing platform or the Google Earth Engine. Available infrastructures aim at sharing remote sensing data and derived products following the FAIR metrics: Findable (F) - Accessible (A) - Interoperable (I) - Reusable (R). Thus - remote sensing data have to be documented using metadata that support FAIR data principles as follows: (1) Findable: remote sensing data are findable through data documentation - i.e. metadata - that needs to include a unique identifier of the described data. Metadata can be stored in a catalog compliant to one of the available data cataloging standards such as the  SpatioTemporal Asset Catalog (STAC) compliant catalog; (2) Accessible: all data have to be openly accessible and shared using interoperable formats that allow users to find - access and reuse them; (3) Interoperable: different standards - e.g. STAC specification - have to be used to document remote sensing data; (4) Reusable: metadata have to be comprehensive enough to allow users not only to assess the fitness for purpose (e.g. lineage) but also to provide them information about how to access the generated data.,REMOTE SENSING469,IP6,Image processing (value) chain,In an information value chain - one or more organizations perform a set of value-adding activities for creating and distributing information products and services. They support a user in decision-making and thereby benefit the user’s purpose. The information value chain is a tool for evaluating business management and profitability. It enables explaining the ultimate “value” of a product and the components along the value chain and consequently allows businesses to optimize their processes. \rThe value of EO data can be assessed by analysing the contribution of the data to a specific EO information product and its effective use in decision-making. The (share of) benefit attributable to the use of the given EO data is derived from the comparison of a decision taken using the EO product to a counterfactual situation where other types of information are used instead. Often - this compares the situation before a new  EO service was available to the situation afterwards. An ex-post analysis may reveal improved performances - e.g. gains in output - or productivity and/or reduced costs as compared to those occurring in absence of EO-derived information. This benefit resides with the user of the EO product and may be traced to societal and environmental benefits through impact chains.\rThe process of EO information production and distribution is integrated in the value chain and can be defined as the image processing chain. It comprises the value-adding activities of the organization(s) that lead up to the availability of an EO product for decision making. The nature and flow of these activities and the collaboration between organizations and among participants within organizations can be modelled with business process model and notation (BPMN). BPMN is a flowchart diagram that uses swimlanes representing different participants. Processes are assigned to participants and are connected with arrows into flow sequences. Further elements complete the choice of symbols for modelling a consistent flow - including a start event - end events - and branching options. They allow organizing the flow in parallel or iterative processes. Higher-level processes can be (de-)composed with sub-processes. Additionally - it is possible to use pools and message flows for explicitly modelling collaboration between participants (from different organizations).\rIn the image processing (value) chain - the sequence of processing steps begins with the acquisition of EO data - followed by steps of pre-processing and information extraction (or whatever steps are necessary) and ends with an EO information product being available to a user that uses it to make his decision. The collaborating stakeholders along the chain include EO satellite operators - EO data providers - EO information providers - and the users at the end of the value chain. The stakeholders along the processing chain each perform a dedicated subsequence of processing steps. Thereby - the stakeholders contribute their share of value to the data they deliver to the next stakeholder in the chain - ultimately arriving a the EO information product for the user. The EO data products that they hand on along the chain are often described with processing levels that provide different states of processing of EO data. They start with raw instrument data (level 0 and 1) that are followed by data converted into geophysical quantities that are geo-referenced and calibrated (level 2). Further levels are quality controlled data that has been mapped on a uniform space-time grid (level 3) and data combined with models or other instrument data (level 4). In addition - EO data providers use the term analysis ready data (ARD) that have been processed to allow direct data analysis - i.e. user processing effort is reduced to a minimum. Further - the standard EO products contain a categorizing element that is related to the image processing value chain. This categorizing element organizes the EO products along the sequences of processing - descriptive analytics - predictive analytics - prescriptive analytics - aggregation - visualization - and distribution. Thereby - the products ultimately contribute to the actionable EO information product for the use in decision-making.,NONE470,MDS,Multidimensional scaling,MDS is a dimensionality reduction technique. It can be divided into Metric multidimensional scaling - Generalized multidimensional scaling and Classical multidimensional scaling.\r\rGeneralized multidimensional scaling is an extension of metric multidimensional scaling - in which the target space is an arbitrary smooth non-Euclidean space. In cases where the dissimilarities are distances on a surface and the target space is another surface - GMDS allows finding the minimum-distortion embedding of one surface into another.\r\rClassical multidimensional scaling is also known as Principal Coordinates Analysis - Torgerson Scaling or Torgerson Gower scaling. It takes an input matrix giving dissimilarities between pairs of items and outputs a coordinate matrix whose configuration minimizes a loss function called strain.,NONE471,no,Mathematical models of uncertainty: Probability and statistics,Models that describe the basic principles of randomness and probability in spatio-temporal data.,NONE472,OI,Organizational and Institutional Aspects,This knowledge area considers the organizational and institutional aspects related to GIS&T. The focus of this knowledge area is on the organizations active in the GIS&T domain - and what happens within and between these organizations. The knowledge area is structured around five units. One unit considers the key organizations in the GIS&T domain - covering relevant public sector organizations at different administrative levels as well as organizations in other sectors of society. Among the organizational aspects covered in this knowledge area are all organizational issues related to the implementation - use and management of GI and GIS within organizations. While all topics related to the organizational structures - procedures and management of GI(S) are grouped into one unit - another unit focuses on issues related to the human factor of using GI and GIS - i.e. people - their skills and competencies - and the development and evaluation of these skills and competencies in the context of GIS&T training and education. The knowledge area includes also several inter-organizational and institutional aspects of GIS&T. Particular attention is paid to the concept of geospatial data sharing - which is about the creation of `spatial data` connections and relationships between different organizations in the GIS&T domain. Spatial data infrastructures are developed to promote - facilitate and coordinate the sharing of spatial data among data providers and data users - and consists of several technological and non-technological components. Many related topics are considered in the knowledge area GI and Society (WS) - which also addresses several non-technological aspects related to GIS&T. In addition to this - also the knowledge areas `Design and Setup of Geographic Information Systems` - `Geospatial Data' and Web-based GI` include several topics that are closely linked to the topics that are considered in this knowledge area. It can be argued that in order to fully master the knowledge and competencies that are presented in these knowledge areas - also basic knowledge and understanding of the organizational and institutional aspects is required.,NONE473,OI1-1,Organizational models for GIS management,The development of an appropriate organizational model - which establishes the basic character of GIS operations - is a crucial element of the GIS management. The appropriate GIS organizational model for any organization is based on its intended role.Alternative GIS organizational models are based on differing arrangements concerning the scope of GIS - the degree of integration of GIS into business operations - the degree of centralization of GIS operation and use - and the degree of centralization of management control. Although many variations can arise from different combinations of these factors - GIS organizational models can generally be classified into three types: (1) enterprise GIS - (2) GIS data and service resource - and (3) GIS as a business tool (Somers - 1998).,NONE474,OI1-2,Managing GIS operations and infrastructure,Management of GIS can be done in a more centralized or more decentralized manner. In a a so-called enterprise or information-framework GIS - an organizational unit may be established to manage the GIS environment and run the core system - whereas usage is decentralized. In environments where GIS is used occasionally by various users - it may be set up as a separate service with a designated group that manages the GIS and also controls users' applications services. A second decision that needs to be made after the choice between more centralized or more decentralized management of GI and GIS is about where to place the GI management. Alternative options are in a line organization - in a support area - or at the executive level - each with their own advantages and disadvantages.,NONE475,OI1-3,User roles,User roles describe the relationship between different users and the GIS in an organization. Each user role includes responsibilities (e.g. for modifying certain information) and privileges (e.g. for viewing specific information). Although many different roles can be defined - a basic distinction is made between users - who can only view certain information - and editors - who can edit certain information.,NONE476,OI1-4,Strategic planning,A GIS management strategy should be unique for each organization - as organizations have unique environments - characteristics - goals - GIS requirements. An important step in developing an effective strategy for an organization is to establish the strategic vision for GI and GIS in the organization and define its role and scope. Other elements that should be covered in the GIS Strategy are the degree of centralized management of the GIS - the placement of GIS management and support in the organization - involvement of users in GIS planning and implementation - coordination of users - organizational changes - preparation of users - personnel issues - transitions to GIS operations - integration into business operations - user support - data access - and integration of technology changes (Somers - 1998).,NONE477,OI1-5,Coordinating GIS Participants and Users,Committee and team approaches are frequently employed for coordinating participants and users in multi-participant GIS projects. The aim of creating such committees and teams is to ensure that the varied interests of participants are addressed - as participants bring many different interests - application needs - data needs - priorities - organizational issues - and political interests to a common project the GIS. Common models for coordinating participants recognize that participants have three levels of interest in the GIS: policy - technical development - and usage. Different bodies can be established focusing on these different levels of interest: a technical committee focusing on the design and development of the GIS - an management committee providing policy guidance and support and a user`s group.,NONE478,OI1-6,Ongoing GIS revision,After the development and implementation of a GIS within an organization - the challenge is to maintain the system and revise and update it when necessary. This means the performance of the GIS in terms of efficiency and effectiveness should be measured and monitoring - and feedback from users on the system and applications - on the data as well as on new needs should be collected. Particular attention should be paid to the maintenance of data sets.,NONE479,OI1-7,Organizational changes,The introduction of GIS into organizational environments should be seen as a complex process of mutual adaptation (Nedovic-Budic - 1997). These technologies changes the established organisational processes and structures - while on the other hand the organisational context and culture modify the technological set-up and use. Therefore - knowledge and understanding of the relationship between technologies and organizations is necessary to increase the success of GIS implementations in organizations. Successful GIS implementation and adoption often require some degree of organizational change. However - this can be very difficult to effect because organizations are naturally resistant to it (Somers - 1998).,NONE480,OI1,Organizational structures - procedures and management,GIS and T implementation and use within an organization often involves a variety of participants - stakeholders - users and applications. Organizational structures and procedures address methods for developing - managing - and coordinating these multi-participant users. The development of the appropriate organizational model for managing the GIS is crucial. In certain cases - changes to the organizational structure in place might be required. Strategic planning and the establishment of coordination structures can be considered as valuable instruments for managing and coordinating all involved users - while also the different user roles need to be assigned.,NONE481,OI2-1,GIS and T positions and qualifications,GIS and T professionals can be hired for a wide range of different job positions - for which the precise skills - competences and qualifications needed will vary. Typical examples of GIS and T positions are GIS&T project managers - technicians - system developers and analyst. The recognition and certification of the competences people have acquired in informal and non-formal learning contexts is important to know which skills and competences individuals have and whether they meet the qualifications required for a certain job position.,NONE482,OI2-2,GIS and T staff development and evaluation,Making sure staff members have the necessary skills and competences to perform geospatial activities is necessary for an effective implementation and operation of GI within an organizations. Several training methods can be adopted to ensure the development of skills and competencies of staff members. A distinction can be made between formal and informal training - but also between internal and external training programs. Another relevant issue is the assessment and evaluation of the skills and competences of staff members - to determine their future training and development needs.,NONE483,OI2-3,GIS and T training and education,Programs and courses on GIS and T and related subjects are provided by a wide range of institutions. While in recent years also the use and integration of GI and GIS in primary and secondary education has received significant attention - GIS and T education is mainly organized by institutions of higher education - especially universities but also other higher education institutions. Analyses of the higher education GIS&T programs and courses in Europe showed that the offer of courses is very diverse - in terms of size (ECTS) - educational level (EQF) and course content. Vocational training on GIS and T related topics is organized by different types of training providers - including the major GIS vendors - data and service providers - academic sector - professional organisations - but also the public sector.,NONE484,OI2-4,GIS and T curriculum and course design,A curriculum is a systematic description of a study program - in terms of learning goals - structure and sequence - learning - teaching and assessment strategies and content. A curriculum consists of both a set of related   required and elective - courses along with all direct and indirect skills - competences and learning outcomes resulting from these courses. In the process of curriculum design typically particular attention is assigned to objectives - teaching methods and educational strategies - while also attention should be paid to the content organization aspects and the global structure of the curriculum. The process of designing GIS&T curricula presents many challenges - as the design of the curriculum should be aligned to both the institutional context and the expected outcomes of the learning and teaching process (Prager - 2011).,NONE485,OI2-5,GIS and T teaching and learning methods,An important challenge in organizing GIS and T education and training is the choice and use of effective teaching and learning methods. These methods should follow recent technological developments and use the best technologies to help students acquire the necessary skills and competencies. Traditionally - most GIS and T programs and courses were taught in the context of a full-time - face-to-face setting - using traditional teaching methods such as lectures and lab-based computer practical sessions. In recent years - educational institutions and their teachers have been experimenting with more innovative teaching and learning methods - such as project-based and case-based learning - distance learning - integrated and inter-disciplinary lessons - collaboration with companies and other stakeholders - etc.,NONE486,OI2,GIS and T workforce themes,This unit addresses GIS and T staff and workforce issues within an organization - particularly as they relate to ensuring that GIS and T is appropriately used and supported. The focus of this unit is on the skills and competencies of professionals in the GIS and T domain: how can these skills and competencies be described and evaluated - and how can they be developed through training and education.,NONE487,OI3-1,Drivers and incentives for sharing geospatial data,Cost savings are an important driver or motivation for sharing geospatial data and information. As costs associated with collecting and maintaining geospatial data are high - sharing data means that users no longer need to duplicate data gathering and archiving - which leads to savings in terms of personnel - space/facilities - data acquisition and maintenance costs. One fundamental argument for sharing thus derives from scale economies in production. Because the cost of making data is high - there is a clear incentive to maximize the number of users of these data. Sharing allows data to be used repeatedly for many purposes - thus increasing their value without increasing their cost. Sharing data also leads to improved data quality. Moreover - in many cases - sharing data is the only way to get access to certain data sets - as the authority to collect and manage certain data lies with another public institution.,NONE488,OI3-2,Barriers to geospatial information sharing,Sharing of geospatial data can be hindered or inhibited by several types of barriers. These include technological barriers - such as a lack of common data definitions - formats and models or incompatibility of hardware and software. Among the non-technological barriers are organizational - political and legal issues and elements - such as misaligned organizational missions - diversity in organizational cultures - conflicting organizational priorities - lack of funding - lack of executive and legislative support; restrictive laws and regulations - copyright issues - data privacy and data ownership issues. However - it should be noticed that many of these barriers have been decreased or eliminated in recent years.,NONE489,OI3-3,Legal framework for geospatial data sharing,The legal framework for geospatial data sharing is very wide and diverse - involving rules on data - coordination - standards - funding - etc. Moreover - these rules and regulations can take many different forms: legal acts adopted by parliament - executive orders or decisions - cooperation agreements - memoranda of understanding - bilateral arrangements etc. From a data perspective - the legal framework can be distinguished into two main types of policies: those that promote and those that hinder the availability of spatial data. Policies that promote spatial data availability can focus on different types of users (public bodies - private companies - citizens) and different types of use (public access - commercial and non-commercial reuse - reuse for performing public tasks). Among the policies that hinder the availability of spatial data are those dealing with privacy - liability - and intellectual property. The legal framework also includes legislation that applies to data or information in general - such as open data legislation - which may also be applicable to spatial data (e.g. legislation on freedom of information - copyright - etc.). Moreover - also general legislation relating to any interaction between people or any situation in everyday life (e.g. liability - contract law - competition law - etc.) will apply to spatial data sharing.,NONE490,OI3-4,Legal instruments for sharing geospatial data,Several types of legal mechanisms for sharing geospatial data can be used. A data sharing arrangements can be formalized by a contract or agreement between the data provider and the data user. A particular type of agreement are the framework agreements - which are agreements between two or more organisations concluded prior to the datasets or services being required. These framework agreement can involve one or multiple spatial data sets or services. Partnership agreements are often used to formalize the data sharing agreements among a broader group of partners. Participation in such a partnership often means participants share their data with other participants and get access to shared data. Another relevant mechanism is the use of licenses - which are mechanisms to give organizations and people the permission to use spatial data sets and services. A license is legally binding - and defines the conditions of use of the related spatial data sets and services. In order to reduce the number of licenses used and ensure the harmonization of the terms in these licenses - the use of standard licenses is promoted. Also the use of open data licenses is promoted for sharing geospatial data - and strongly increased in recent years.,NONE491,OI3,Geospatial data sharing,Geospatial data sharing has become an essential element of the GI activities of organizations. Spatial data sharing can be defined as the electronic transfer of spatial data/information between two or more organizational units where there is independence between the holder of the data and the prospective user. Spatial data sharing has many advantages - but several technical and non-technical barriers must be overcome to put data sharing into practice. While the practice of spatial data sharing has substantially grown with the development of spatial data infrastructures - many consider data sharing as a crucial element for the success of these infrastructures.,NONE492,OI3b,Spatial Data Infrastructures,A Spatial Data Infrastructure can be defined as the collection of technological and non-technological components to facilitate and coordinate the exchange of and sharing of spatial data. The concept infrastructure is used to promote the concept of a reliable - supporting environment - analogous to a road or telecommunications network - that facilitates the access to spatial data. Data - metadata - access networks - standards - coordination - policies - funding - people and institutional frameworks are often considered among the key components of an SDI. \r\rSpatial data infrastructures often are defined and described as a complex and dynamic phenomenon. Among the main reasons for the complex character of these infrastructures are the many components a spatial data infrastructure consists of - the diversity of involved stakeholders - and the many different objectives and ambitions of these stakeholders. Technological advancements - such as the emergence of web 2.0 technologies - and societal changes - such as the increasing use of geographic information in everyday life - are often mentioned as important drivers behind the dynamic character of spatial data infrastructures. \r\rA key characteristic of spatial data infrastructures is the involvement of a large and diverse group of actors. Governments are often considered as the central actors in the development and implementation of spatial data infrastructure - since they are the major producers and users of geographic information. Governments at different administrative levels and in different thematic domains are involved in the creation - management - use and sharing of geographic data. But also private companies - non-profit organisations - research and education institutions and even citizens can participate in the development and implementation of a spatial data infrastructure. It is increasingly being argued that the involvement and engagement of each of these stakeholders group is essential to the realization of a successful spatial data infrastructure. \r\rSDIs have been developed in many countries worldwide at local - national and international levels. Often a distinction is made between a between the first generation SDIs that have data as their key driver and are based on a product model and second generation SDIs in which user needs are the key driver and that are based on a process or development model. The latest generations of SDI strongly focus on the inclusion and engagement of non-government actors and organizations in the development and implementation of the SDI.  Although SDI are by default distributed systems - involving many organisations - some SDI might be developed rather in an hierarchical way - while others are following a networked approach.,NONE493,OI4-1,Adoption and implementation of standards,The adoption and implementation of standards are two key phases in the standardization process - which starts with the definition of standardization requirements and the development of standards. The adoption and implementation of standards follows after the development phase. The distinction made between the adoption and implementation of standards is important: adoption entails the decision to apply standards - while the implementation relates to the integration of standards in software - in data development and in other processes. GI-Standards are one of the key components of each SDI - consist of both semantic and technical standards - and include standards related to the different architectural components of an SDI - i.e. standards related to spatial data sets and data products - web services - metadata and catalogues - encodings - etc.,NONE494,OI4-2,Policies,The SDI policy framework includes the set of policies - strategies - initiatives and projects aimed at increasing access - sharing - and effective use of spatial data. SDI policies can be divided into strategic and more operational policies. Strategic policies define the broader framework and formal structure within which the SDI initiative is developed. Operational policies provide more practical tools to facilitate access to and use of the SDI - and address specific topics related to the collection - management - use - access and dissemination of spatial data. These operational policies include a broad range of guidelines - directives - procedures and manuals that apply to the day-to-day business of organizations in developing - operating and using an SDI. To guarantee the success of an SDI - it is important to recognize the wider policy context in which these SDI`s are developed - and to link them to the overall policy environment in the jurisdiction in which they are implemented. These include policies on open government and open data - environmental policies - digital government or e-government policies and other.,NONE495,OI4-3,Coordination and organizational structure,If is often argued that SDI implementation requires coordination - because without coordination all other SDI components would not be developed or would be developed in a very fragmented and inconsistent manner. In general terms - coordination is about bringing into alignment the activities of different stakeholders in the SDI landscape. A typical instrument to realize coordinate in the context of SDI - is the establishment of an effective SDI coordination structure. The SDI coordination structure should ensure that all stakeholders are involved in the development and implementation of the SDI - through the participation in one or more coordination bodies. Another important element is the establishment of clear roles and responsibilities for the different involved organizations - making a distinction between data users - data providers - services providers and a geo-broker.,NONE496,OI4-5,Funding an SDI,Funding an SDI is about guaranteeing the long-term financial security of an SDI - by obtaining and formalizing financing for the implementation and maintenance of the different SDI components. An SDI funding model provides the answer to the central question of where and how to seek funding for implementing and maintaining an SDI. Within an SDI often different funding models will be combined - as the selection of the most appropriate funding model will be linked to different activities and the associated costs. Costs of an SDI include both set-up costs (one off costs) and maintenance costs (yearly) - of which certain costs need to be made for each data sets or each data provider and other costs for the infrastructure in general. The most commonly used SDI funding models are centralized government funding - decentralized government funding (e.g. for each data provider) - partnership funding - funding through revenues - and government funding based on donor agencies or on European projects.\r\rThe shift towards open data and the adoption of open data policies had an important impact on the funding model of many SDIs - as governments and organizations no longer could rely on revenues from selling their data and had to look for other funding models. As a result - new pricing strategies are employed - such as the provision of fee-based supplementary services - such as advice or tailor-made products based on open data. Also freemium/premium models - in which a basic version of the dataset is offered as open data (freemium) but the full dataset is available for a fee (premium) - were considered as an alternative approach. In many cases - the loss of revenues was compensated by other funding models - such as increased government funding.,NONE497,OI4-5b,SDI performance measurement and assessment,SDI performance assessment is about collecting - analyzing and providing information on the performance of SDI initiatives. Assessment and evaluations of SDIs are a useful tool for those organizations and people directly involved in these initiatives - but also for researchers - citizens - journalists and other stakeholders. Decision makers and practitioners can use assessments to monitor the progress against the objectives of their SDI initiatives and to identify areas where improvement can be achieved. Assessment also allows to compare and benchmark the performance of different organizations or countries - and to learn from best practices. Finally - assessment also is relevant for accountability - since it enables governments and agencies to be held accountable for their decisions - activities and the resources they have invested. Assessment of SDIs - which deals with the collection and supply of information on the performance of SDI initiatives - should be seen as the first step in a logical consequence of collecting data - integrating this data in policy and management cycles and actually using the information. \r\rIn the past twenty years - many different SDI assessment frameworks have been developed by researchers and practitioners around the world. Examples of such frameworks are the INSPIRE State of Play Study - the Clearinghouse Suitability Index - the Organisational Maturity Matrix - the SDI Readiness Index - and the INSPIRE Monitoring and Reporting approach. Each of these frameworks focus on particular aspects and components of SDIs. In line with the categorization of open data assessment - also SDI assessments can be divided into three main categories: (1) readiness assessments - (2) implementation or data assessments - and (3) impact assessments. Readiness assessments analyse whether conditions are appropriate - and whether necessary components are in place for developing an SDI. Implementation or Data assessments evaluate whether geospatial data are available and accessible. Impact assessments explore the extent to which SDIs lead to benefits for government - citizens - business and society in general.,NONE498,OI4-6,Next-generation SDIs,For a long time - SDI development has focused on the development and implementation of different components with the aim of facilitating the access to and sharing of spatial data. An key challenge in future SDI development will be the integration of these SDI`s in a wider context. In order to optimally take advantage of the data and services provided by an SDI - integrating these data and services into the processes and workflows of   public and private   organizations will be crucial. The concept of spatial enablement refers to the challenge of developing SDI`s in such a way that they provide an enabling platform that serves the wider needs of society in a transparent manner. Moreover - the diffusion of SDIs - together with the efforts to build a Global Earth Observation System of Systems (GEOSS) and other developments in industry and civil society should be considered as elements in a the realization of a vision on the next-generation Digital Earth.,NONE499,OI4-7,SDI governance,The effective implementation of SDIs requires governance - which includes the structures - policies - actors and institutions by which the infrastructure is managed pertaining to decisions made for accessing - sharing - exchanging and using the relevant available spatial information. While SDIs themselves are considered as initiatives contributing to good governance or effective governance - a key challenge in the establishment of SDIs is the governance of the infrastructure itself. Governance of SDIs is essential for the implementation of different SDI components in a coordinated and consistent manner. The central challenge of governance is reconciling collective and individual needs and interests of different stakeholders in order to achieve common goals. This aims to reduce gaps - duplications - contradictions and missed opportunities in the production - management - sharing and use of the information that tend to occur in a multi-stakeholder environment.\r\rGovernance can be facilitated through the use of appropriate instruments which extend to various levels of government and take into account the distribution of powers and responsibilities among different actors and institutions with an interest in the infrastructure. The governance instruments should coordinate the activities and contributions of - inter alia - data producers - users - added-value services providers - and other stakeholders. More complex and inclusive models of governance are required to cope with the multi-level nature of SDI implementations of the current generation of SDIs. Effective and inclusive SDI governance structures are needed - that are both understood and accepted by all stakeholders. Governance of SDIs also requires expanding the scope of stakeholders to include the private sector - research bodies and other actors outside the public sector including citizens - to actively promote bottom-up and participatory processes - and to find the appropriate mechanisms and instruments to enable the participation of these non-government actors.,NONE500,OI5-1,GI organization at the European Commission,Within the European Commission there are several key GI players. GIS activities in the Commission started since 1981 (e.g. DG REGIO - Eurostat - ) with the CORINE project - the creation of DG ENV and the creation of the European Environment Agency (EEA). Together with the DG Joint Research Centre (JRC) - DG ENV and EEA are in charge of the coordination of INSPIRE: DG Environment acts as an overall legislative and policy co-ordinator for INSPIRE - the JRC acts as the overall technical co-ordinator of INSPIRE and EEA is in charge of several tasks related to monitoring and reporting - and data and service sharing under INSPIRE. Also several other EC institutions are actively involved in GI(S) policies and activities (DIGIT - DG GROW - DG AGRI - DG MOVE and many others).,NONE501,OI5-2,Federal and national government organizations,Although there may be certain differences between countries - in most countries many key organizations in the GIS&T field will be active at the central/federal/national level of government. Especially the traditional institutions for surveying and mapping play a key role in geospatial policies and activities. Several public authorities at the federal level are in charge of the production and maintenance of key reference and thematic data sets. In many countries - these national data producers were the leading actors in the development of   national   spatial data infrastructures.,NONE502,OI5-3,Sub-national and local governments,Local and sub-national governments are often considered among the major users of geographic information in governments - as they often are involved in many different policy areas - in which many problems with a locational component need to be tackled. Geographic data produced and maintained by authorities at lower administrative levels are often more detailed and thus interesting for other users - both within and outside the public sector. As a result - local and sub-national governments are often involved in the establishment of these infrastructures because of the wide range of highly detailed geographic information they produce and manage. As many geographic data are linked to the activities and services of local organizations - the involvement of these organizations in the maintenance of data ensures that these data are up-to-date.,NONE503,OI5-4,Pan-European and global associations and professional organizations,The European GIS&T landscape consists of many pan-European organizations and associations promoting the interest of and representing certain stakeholder groups. While some of these organisations are dealing with all sectors and aspects of geographic information - others have a more thematic focus (e.g. remote sensing - topography - geosciences) or represent a particular sector (e.g. research - business). In some cases - their clearly is an overlap in the mission and objectives of different organizations - and some organizations are working in the same field of interest. Some examples of pan-European organizations and associations are AGILE - EuroSDR - EUROGI - and EuroGeographics. Also at international level several membership organizations and associations exist.,REMOTE SENSING504,OI5-5,The geospatial industry,The geospatial industry consists of companies working with location specific information or services. Within the geospatial sector - several areas of activities can be identified: 1) measuring - collecting and storing of data about geo-objects; 2) processing - editing - modelling - analyzing and managing that data; 3) presenting - producing and distributing the data; and 4) advising - educating - researching and communicating about processes and use of geo-information products and services. The sector consists of both small-and-medium-sized enterprises but also big companies - including surveyors - census hard-copy map providers - aerial photos providers - base map data providers - satellite and remote sensing imagery providers - software developers (GIS-related products and services providers as well as satellite image programming platform providers) and several others.,REMOTE SENSING505,OI5,Organizations in the GIS and T domain,Several types of organizations play a key role in the execution and coordination of geospatial activities in society. Typically - a distinction is made between data providers and data users - while coordinating organizations exist to coordinate and support the geospatial activities of professionals and entities using GIS&T. Governments are often considered as the major users and producers of spatial data and spatial information. Within the public sector - spatial data are collected and used in different thematic areas and at different administrative levels (from local to global). However - the needs - interests - and capacities of organizations at each of these levels will be different - as well as their role in the development of spatial data infrastructures - and the execution of geospatial activities in general. Also the geospatial industry will exist of both data providers and data users - but also of organizations delivering products and services to support the collection and use of spatial data. Other key organization in the GI domain are professional organizations and associations - bringing together and representing the needs of organizations of a particular sector and/or geographic area.,NONE506,PP,Physical principles,The knowledge of physical laws and principles regulating the emission of e.m. radiation and its interactions with the matter - as well the ones related to the design - setting-up and control of EO platforms and related instruments - are of paramount importance for a right interpretation of EO measurements in relation with the investigated Earth's phenomena and parameters. The most important physical fundaments regards: the theory of electromagnetic waves propagation described by the Maxwell's equations -  the theory of  e.m. radiation and of its interaction with the matter - the methods and instruments for e.m. radiation measurement and/or generation - the fundamentals of thermodynamics and of mechanics. As far as Earth Observation is concerned - further - specific topics have to be addressed which are related to: spectral-specific matter-radiation interactions - natural (e.g. Earth - Sun) and artificial (e.g. MW) sources of e.m. radiations - atmospheric physics and radiative transfer equations -  basic physics of e.m. - optical and MW - sensors and sources - theory of satellites orbits - theory of rockets - physical fundaments of interpretation of optical and MW data collected by passive and active techniques.,NONE507,PP1-1-1,Electromagnetic Waves and Photons,Electromagnetic radiation travels in wave form. All electromagnetic waves travel at the speed of 299.793 km/sec in a vacuum and very nearly the same speed in air. In quantum physics electromagnetic radiation is also described in terms of particles called photons whose energy is given by  the equation E = hf  where h is the Planck constant and f the frequency of corresponding wave.  Electromagnetic wave propagation is fully described by the Maxwell Equations that unified in 1860s the laws of electricity and magnetism.,NONE508,PP1-1-10,Solar constant - solar insolation - daily insolation,The solar constant S is a quantity denoting the amount of total (i.e. - covering the entire solar spectrum) solar energy reaching the top of the atmosphere. It is defined as the flux of solar energy (energy per unit time) across a surface of unit area normal to the solar beam at the mean distance between the sun and the earth. Solar insolation is defined as the flux of solar radiation per unit of horizontal area for a given locality. It depends primarily on the solar zenith angle and to some extent on the variable distance of the earth from the sun. It can be computed as a function of latitude and the time of year taking into account of the secular variations of Earth's orbit eccentricity e - the oblique angle ε - and the longitude of the perihelion relative to the vernal equinox ω.  The daily insolation is the total solar energy received by a unit of area per one day. It may be calculated by integrating total insolation over the daylight hours. It is particularly important - together with information on cloud coverage - in order to plan and manage solar power systems. Yearly total insolation together with average cloud coverage are among the most important parameters to be considered for the choice of the best (i.e. the ones promising the higher energy production) location of solar power plants. Modeled daily solar insolation together with short/medium-term forecast of cloud coverage are also fundamental for the management (e.g. for planning the suspension of activities for maintenance) of solar energy production plants .,NONE509,PP1-1-11,Earth's radiation (intensity - spectrum - etc.),Earth's itself represents the second (after Sun) most powerfull natural source of e.m. radiation for EO. Even if very less powerfull than Sun such a source is available for EO day and nigth. Its average emittance can be approximated by that of a blackbody at about 290 K.  The maximum of its emission - following the Wien's Law - falls then around 10 micron (in the Thermal InfraRed - TIR spectral range) being Earth's emission trascurable in the VIS-SWIR range.\rMost of Earth's thermally emitted radiation falls in the spectral range 8-14 microns where it benefits of a quite high atmospheric transmittance (TIR atmospheric spectral window) in standard atmospheric conditions. However thick clouds prevent TIR radiation to reach satellite sensors (adsorbing and/or reflecting backward the radiation leaving Earth's surface) so that ground resolution cells affected by clouds are usually identified (cloud-mask) in the image pre-processing phase and not considered for further elaboration devoted to investigate surface properties. Even if very low in intensity - Earth's emitted radiation  in the Far InfraRed (FIR) and in the MicroWaves (MW) spectral ranges are also used for quite important investigation related to the Earth's Energy balance (FIR) and for meteo-climatological applications. The complete transparence of Earth's atmosphere to the MWs - even in presence of meteorological (not precipitating) clouds make this Earth's emitted signal particularly important for application (e.g. climatological) requiring temporal continuity (all weather) of observations of Earth's surface properties like Temperature - Soil wetness - etc.. However - due to the weakness of the Earth's emitted signal in the MW ranges - such products can be achievable just at quite low spatial resolution (e.g. > 10km) by passive EO MW sensors,NONE510,PP1-1-2,Electromagnetic spectrum,In principle - the frequency f (and the wavelength λ=c/f)  of an electromagnetic wave can take any value and the whole range of possible frequencies is called the electromagnetic spectrum. Different regions of the spectrum are conventionally given different names (with associated spectral ranges smoothly depending on specific science sector): \rgamma-rays	 λ< 1 pm\rx-rays	1 nm >λ>1 pm\rUltraviolet  (UV) 400 nm >λ>1 nm\rVisible (VIS) 700 nm >λ> 400 nm (blue: 455 – 492 - green 492 – 577 - yellow 577 – 597 - red 622 – 700)\rinfrared (IR)	1000μm >λ> 0 -7 μm (Near-IR - NIR: 0 -7-1 -3;  Short-Wave IR SWIR: 1 -3-3; Medium IR - MIR: 3-6 - Thermal IR - TIR: 6-20; Far IR - FIR: 20-1000)\rRadio waves	 λ> 1 mm (Microwaves MW	1 m >λ> 1mm). Optical range (usually referring to  the  spectral range from VIS to TIR) and microwaves are the most important spectral region for remote EO systems.,NONE511,PP1-1-3,Maxwell Equations and EM waves' propagation,Maxwell equations are a set of coupled partial differential equations that contains the fundamentals of electricity and magnetism. These equations provide electromagnetic waves that propagate into the space at the speed of the light. Increasing the wavelength there are gamma rays - X-rays - ultraviolet - (visible) light - infrared - microwaves and radio waves.,NONE512,PP1-1-4,Planck law for the black body. Wien's displacement law,Planck's law is a mathematical relationship for the spectral radiance emitted by a blackbody (i.e. a body that absorbs all radiant energy falling on it) at a given temperature as a function of frequency or wavelength. From another point of view it can be used to define a black-body as a  body emitting radiation following Planck's law.  The model of black-body is fundamental to simplify the description of the radiation thermally emitted by a generic body at a pre-fixed temperature and wavelength as the product of its (specific) spectral emissivity and the value predicted (at the same wavelength) by the Planck's law for a black-body at the same temperature. This way the radiation thermally emitted by a generic body can be expressed just as a (specific - as modulated by the spectra emissivity) fraction of the one expected for a black-body. Wien’s displacement law is the relationship between the temperature of a blackbody and the wavelength at which it emits the most radiation. Wien found that the product of the peak wavelength and the temperature is an absolute constant. As far as the temperature T of the blackbody increase the intensity of the  emitted e.m. radiation  increases being - at whatever wavelength - grater than the one emitted by a blackbody  at lower temperature (Planck). As far as the blackbody temperature increases its maximum emission occurs at lower and lower wavelengths. Wien's law is fundamental both in the selection of the spectral bands more appropriate for  observing specific phenomena  as well as for remotely retrieve temperature of far objects  by the analysis of the emitted spectral radiances.,NONE513,PP1-1-5,Rayleigh-Jeans approximation. Wien's approximation,The Rayleigh–Jeans Law is an approximation of the Planck’s law for a blackbody that states that - under certain conditions - emitted radiance is directly proportional to the  blackbody temperature. Such an approximation -  fits quite well with measurements of radiation emitted by sources at around 300K of temperature (like - in average - for the Earth) at wavelengths higher than 1mm (microwaves).. Wien’s approximation can be used to describe the emission spectrum of a high temperature blackbody n the VIS-NIR spectral range lengths. The estimated errors is less than 2% at wavlengths less that 5microns when a blackbody at around 6000K (like the Sun photosphere) is considered. \rThe Rayleigh–Jeans approximation is widely used in the processing of satellite images collected by passive MW sensors. Its extension to the thermal infrared spectral range (TIR) is also used for calibrating TIR satellite images (in this case linearity can be guaranteed just by steps on different brigthness temperature intervals).,NONE514,PP1-1-6,Stefan–Boltzmann law. Kirchoff law,The total radiant intensity B(T ) of a blackbody at the absolute temperature T can be derived by integrating the Planck function over the entire wavelength domain from 0 to∞. Since blackbody radiation is isotropic - the flux density emitted by a blackbody is therefore F = π B(T ) which is proportional to the fourth power of the absolute temperature T through the Stefan-Boltzmann constant σ = 5.67 × 10−8 J m−2 sec−1 deg−4.\rKirchoff's law establishes that for a medium at the thermodynamic equilibrium - the spectral emissivity ε(λ) at a given wavelength λ - is equal to the its spectral absorbance - A(λ) at the same wavelength λ.   Hence ε(λ)=A(λ) at each fixed λ -  for a blackbody   ε(λ)=A(λ)=1 at whatever λ. Kirchoff's law is valid also in Local Thermodynamic Equilibrium (LTE) conditions as the ones  usually occurring in (small volumes of) the Earth's atmosphere even in the most turbulent conditions.\rKirchoff's law has important applications also for the study of spectral signatures of  mineral and rocks and - in general - of opaque - i.e. with spectral transmittance T(λ)=0 - bodies. In that case - the relation which relate the spectral reflectance R(λ) - absorbance A(λ) and transmittance T(λ) of a body: R(λ)+A(λ)+T(λ) =1\rreduce to R(λ)+A(λ)=1 and in LTE conditions - thanks to the Kirchoff's law: \rR(λ)+ε(λ)=1 which allows to obtain measurements of spectral emissivity indirectly through (more simple and stable) measurements of spectral reflectance:\rε(λ)=1-R(λ)\rRocks and mineral exhibit important (diagnostic/discriminating) signatures in their spectral emissivity in the thermal infrared (TIR) region. Measuring spectral emissivity in a laboratory (particularly if samples have to be characterized for their properties in natural conditions) is a quite difficult task due to the difficulty to insolate the sample from the lab environment (and instruments themselves) all emitting approximately at the same (environmental)  temperature. Kirchoff's law allows to obtain - for opaque bodies - spectral emissivities  from spectral reflectances measurements which are much easy to  realize in normal remote sensing labs.,REMOTE SENSING515,PP1-1-7,Concepts of Spectral Emissivity and Brightness Temperature.,All bodies at a temperature T>0 K emit electromagnetic radiation at all wavelengths (thermal emission).  Such emission at each wavelength is increasing with T and it is maximum for Black Bodies whose spectral emittance I(λ -T)  (at each prefixed T and wavelength λ) is defined by the Planck function B(λ -T). Generic bodies are expected to thermally emit less than a black body (having the same temperature T) at whatever wavelength. Spectral emissivity ε(λ) is defined as the ratio of the spectral radiance I(λ -T) emitted by a generic body and the one emitted by a Black Body at the same temperature - i.e. ε(λ)= I(λ -T) / B(λ -T).  By definition its value is less or equal (Black Body) than 1. The spectral emissivity concept allows to describe in a simple way the spectral radiance I(λ -T) thermally emitted by a body at a temperature T by I(λ -T)= ε(λ)*B(λ -T).  It is possible to invert the Planck Function to obtain from the emitted radiance at a prefixed wavelength the temperature T=f(B - λ) of the emitting Black Body. If in such expression the spectral radiance I emitted by a generic body is used instead than B - the resulting temperature - Tb=f(I - λ) - is named Brigthness Temperature being Tb<=T (with Tb=T in case the emitting body is a Black Body). The concept of Brigthness Temperature is substantially a different way to measure the spectral radiance of a generic body. It is usually preferred (for instance calibrating Thermal InfraRed – TIR – satellite images) because the interpretation of such a digital image is much more intuitive than when spectral radiances are used instead. In fact - as at each prefixed temperature generic bodies are less emitting than Black Bodies - wherever across a digital satellite image we consider the values of reported Tb - we can say that the actual temperature T of the corresponding emitting ground resolution cell is not less than Tb.,NONE516, , , ,NONE517,PP1-1,EM radiation,EM radiation is created when an electrically charge particle - such as an electron - is accelerated by a force causing it to move. The movement produces oscillating electric and magnetic fields which travel - as an harmonic EM wave - at right angles to each other. EM waves travel at 299 -792 -458 meters per second in a vacuum (the highest possible speed into the Universe - also known as the speed of light). \rThe electromagnetic field propagating through the space as EM waves is also referred as electromagnetic radiation. \rAn EM wave is characterized by a frequency (or by a wavelength) and by an amplitude (or by an energy). \rThe wavelength is the distance between two consecutive peaks of a wave. This distance is given in meters (m) or fractions thereof. Frequency is the number of waves that form in a given length of time. It is usually measured as the number of wave cycles per second - or Hertz (Hz). It is wave speed=frequency*wavelength so that - an EM wave traveling at the speed of light - can be equally identified by its wavelength or by its frequency. The amplitude (i.e. the maximum oscillation of the EM field) provide the intensity (i.e. the energy) of the EM wave.  \rThe classical theory describes the EM radiation as electromagnetic waves which represent the oscillations of electric and magnetic fields. In the quantum mechanics theory EM radiation consists of photons - quanta of the electromagnetic energy - responsible for all electromagnetic interactions.\rAs far as Earth remote sensing is concerned EM radiation represents the most important  vehicle of information.,REMOTE SENSING518,PP1-2-1,Atomic spectroscopy,The study of the absorbption/emission of electromagnetic radiation by atoms. Depending on the atomic number characteristic frequency or wavelength are absorbed or emitted. Since each element has a characteristic spectrum of absorbed/emitted wavelengths (spectral signature) - atomic spectroscopy allows the determination of elemental compositions even of remote objects (e.g. stars - galaxies - etc.).\rStarting from the simple Bohr’s model it is possible to predict quite exactly the frequencies of e.m. radiation selectively absorbed/emitted by all atoms. Depending on the atomic number Z - characteristic frequencies f are absorbed or emitted by atoms corresponding to the electronic transitions from different energetic (quantized) states following the Bohr’s condition: fab=(Eb- Ea)/h -  being Ei=-cost∙Z2/(ni)2 the electron energy corresponding to the state/level i (principal quantic number ni). By this way each atomic species has a characteristic spectrum of absorbed/emitted frequencies (atomic spectral signature) so that  atomic spectroscopy allows the determination of elemental compositions even of remote objects. By this way the existence of Helium was discovered in the 1968 by Jansen and Lockyer in the Sun photosphere well before its discover on the Earth - and the knowledge of the chemical composition of stars and galaxies was possible well before the end of XIX century. Atomic spectroscopy provides a simple and powerful introduction (through the explanation of the more complex interactions of e.m. radiation with molecules and solid matter) to the fundamental concepts of spectral signature (which is at the base of most of the applications of aerial remote sensing of the Earth’s surface) and atmospheric windows (important for the design of optical sensors devoted to remotely sense Earth’s surface) being moreover propaedeutic to the understanding of methods for the atmospheric vertical sounding based on the concepts spectral lines broadening and related weighting functions.,REMOTE SENSING519,PP1-2-10,The Rayleigh roughness criterion,The Rayleigh roughness criterion is a widely used means to estimate the degree of roughness of a considered surface. Considering the phase difference between two rays scattered from separate points of the surface - this depends on the roughness height - the incident angle and - inversely - on the radiation wavelength (λ). The Rayleight criterion states that a surface can be considered as smooth if the phase difference is less than π/2 radians.\rAs a consequence - in the case of normal incidence - irregularities must be less than λ/8 in height to have an effectively smooth surface. In particular: i) at optical wavelengths (e.g. 0.5 micrometers) - roughness height must be less than about 60 nm to have a specular reflection from a surface. Only certain man-made surfaces (e.g. sheets of glass or metal) may meet such a condition; ii) at VHF radio wavelengths (e.g. 3 m) - roughness height need only to be less than about 40 cm. Unlike the previous case - a number of natural surfaces may meet this condition.\rIt is worth noting that large values of the incident angle may satisfy the criterion more easily as compared with the normal incidence. This means that a moderately rough surface may be effectively smooth at glancing incidence. This condition may be easily experienced when eyes are struck by the glare of reflected sunlight from a low sun over an ordinary road surface.,NONE520,PP1-2-11,Bidirectional Reflectance Distribution Function (BRDF),The Bidirectional Reflectance Distribution Function (BRDF) is defined as the quotient between the spectral radiance reflected by a sample and the spectral irradiance from the source that illuminates it. It depends on both the incidence and viewing angles. From this point of view it represents an absolute definition of reflectance whose value - as is known - depends on the geometry of the illumination and observations directions.,NONE521,PP1-2-12,Bidirectional Reflectance Factor (BRF),Measurements of BRDF allow to compare spectral signatures obtained in different laboratories in an optimal way. However its measure require well calibrated sources and quite expensive laboratory equipments. The concept of BRF (Bidirectional Reflectance Factor) allows a more simple - indirect - measurement of BRDF by using a reference sample (highly reflective so usually named 'white reference WR') of known BRDF and two subsequent measurements of reflected radiance (one from the WR - one from the sample) obtained under identical illumination conditions. In these conditions  results BRDF(sample)=BRF(sample)xBRDF(WR),NONE522,PP1-2-2,Molecular absorption spectra,The molecular absorption spectral corresponds to the wavelengths from 190 nm up to 1000 nm and it interprets the measured absorption of radiation - when it is passing through a gas - a liquid or solid. Their absorbed energy in different states can be approximated by electronic - vibrational and rotational energy,NONE523,PP1-2-3,Line shape and (natural - pressure - Doppler) broadening,The spectral line is a result of interactions of photon with a quantum system - while it extends over a range of frequencies. The center wavelength of its energy levels may be changed due to Broadening - namely collisions of atoms and molecules or their differences in thermal velocities.,NONE524,PP1-2-4,Voigt's line profile,When the altitude ranges from about 20 to 50 km - spectral line shape is determined by both collisions (Pressure Broadening) and differences in thermal velocities (Doppler broadening). This shape is referred to as the Voigt profile and it satisfies the condition of normalization.,NONE525,PP1-2-5,Concepts of Transmittance - Absorbance - Reflectance - Scattering.,Radiation that is not absorbed or scattered in the atmosphere can reach and interact with the Earth's surface. There are three (3) forms of interaction that can take place when e.m. radiation strikes - or is incident (I) upon a surface. These are: absorption - transmission - and reflection. The total incident radiation will interact with the surface in one or more of these three ways. The proportions of each will depend on the wavelength of the incident radiation and the specific chemical/physical properties of the surface material. Absorption occurs when incident radiation is absorbed into the target - while transmission occurs when radiation passes through a target. Reflection occurs when radiation 'bounces' off the target and is redirected. The spectral reflectance  is defined by the ratio of reflected radiance to incident radiance  at a prefixed wavelegth . The spectral transmittance of a medium is defined by the ratio of the transmitted radiance  to the incident one  at a prefixed wavelegth . The absorbance of a medium or target is defined by the ratio of the absorbed radiance to the incident one   at a prefixed wavelegth . Conservation of energy require that - at a certain wavelenght: R+T+A=1. To express the circumstance that the reflection can occurre in different direction as the surface deviates from a specular one - becoming rough - the concept of surface scattering has been introduced (ref. [PP1-2-10] The Rayleigh roughness criterion).,NONE526,PP1-2-6,Concepts of Spectral Emissivity,The emitting capability of a body surface is described by the spectral emissivity - ε(λ) - a dimensionless value ranging between 0 and 1 and varying on the basis of the wavelength (λ) and the geometric configuration of the surface. Formally - spectral emissivity can be defined as the ratio of spectral exitance - M(λ -T) - from an object at wavelength λ and temperature T - to that from a blackbody at the same wavelength and temperature - MBB(λ -T).\rA blackbody is an ideal radiator that totally absorbs and then reemits all energy incident upon it. By definition the spectral emissivity of a blackbody is equal to one (the maximum) at whatever wavelength and temperature. A blackbody radiates a continuous spectrum. Real materials do not behave like a blackbody. Natural matter could radiates more in selected spectral region (like in the case of atomic or molecular gases) more frequently with a continuous spectrum (like in the case of solids) always with spectral emissivity minor or equal to 1. \rAnother important concept is the one related to the graybody. For gray bodies - the spectral emissivity value is constant for each wavelength value - as for black bodies - but is always less than 1. Therefore - for any given wavelength the emitted energy of a graybody is a fraction of that of a blackbody. This behavior could be quite important even for limited spectral ranges. For instance the spectral emissivity of  the sea in the TIR (Thermal InfraRed) spectral range 8-14 microns (TIR atmospheric window) can be assumed constant (about 0 -98) with significant simplifications in the determination of SST (Sea Surface Temperature) from satellite sensors operating in that spectral region.  \rAs said above - the emissivity of the most of the bodies present in nature varies depending on the wavelength.  These objects are referred to as selective radiators or as being selectively radiant. This means that some materials may behave as black bodies at certain wavelengths (ε close to 1) and may have reduced emissivity at other wavelengths.,NONE527,PP1-2-7,Complex dielectric constants and refractive indices,'Radiation that is not absorbed or scattered in the atmosphere can reach and interact with the Earth's surface. There are three (3) forms of interaction that can take place when energy strikes - or is incident (I) upon the surface.\r These are: absorption (A); transmission (T); and reflection (R). The total incident energy will interact with the surface in one or more of these three ways. The proportions of each will depend on the wavelength of the energy and the material and condition of the feature. Absorption (A) occurs when radiation (energy) is absorbed into the target while transmission (T) occurs when radiation passes through a target. Reflection (R) occurs when radiation\r ''bounces'' off the target and is redirected. The reflectance R is defined by the ratio of reflected radiant power to incident radiant power. The transmittance T of a medium is defined by the ratio of transmitted radiant power to incident radiant power. The absorptance A of a medium or target is defined by the ratio of absorbed radiant power to incident radiant power. Conservation of energy require that - at a certain wavelenght: R+T+A=1. To express the circumstance that the reflection can occurre in different direction as the surface deviates from a specular one - becoming rough the concept of surface scattering has been introduced. However - the concept of scattering concerns mainly atmopheric interaction with ELM and radar systems.',NONE528,PP1-2-8,EM rad. penetration in the matter: Attenuation Length,The complex part nc of the refraction index n determines how far an e.m. wave of wavelength λ can survive crossing a specific medium. The attenuation length la is the distance after that the amplitude of an e.m. signal reduces its value by an amount of 1/e. For instance the amplitude of the Electric field E(z) of an e.m. wave proceeding along the z direction is decreasing as exp(-z/la) being la=λ/(2𝜋 nc) the attenuation length associated to that specific material (nc) and wavelength λ. This way attenuation length in water can be of hundreds of meters in the visible range and just few microns in the microwaves. So that penetration of radiation in the matter depends on both -  the specific (dielectric) properties of the matter (through nc) AND the specific wavelength λ of considered e.m. signal.,NONE529,PP1-2-9,Scattering from rough surface: Lambertian and specular surfaces.,EM radiation impinging a rough surface is (partly) reflected back (scattering). Lambertian surfaces produce a diffuse scattering (i.e. radiation is reflected similarly in all direction) and then appear equally bright from all directions - whereas specular surfaces behave like a mirror - with reflected radiation all aligned in one direction - with the reflection zenith angle equal to the incident angle of incoming radiation. Generally - the degree of 'roughness' of a surface determines if it behaves like a Lambertian or a specular surface.,NONE530,PP1-2,Radiation - Matter interaction,E.M. Radiation can be absorbed - scattered - emitted and transmitted by the matter. The results of such interactions (i.e. the fraction of incident radiation that is absorbed - scattered or transmitted) or emission process (i.e. the fraction of actually emitted radiation in comparison with the one expected from a black-body at the same temerature) strongly depend on the radiation wavelength and on specific chemical (e.g. composing atoms and molecules as well as their arrangement within solid cristals) and physical (e.g. Temperature - Dimensions and Shape - Roughness) properties of the matter. In some case - the result of Radiation - Matter interaction is strongly affected by observational conditions. For instance - over some angular distance between the directions of incidence and the one of measurement of the radiation -  sun-glint can occur which completely mask any other results. A basic principle of the remote sensing put univocally in relation spectral absorbance - reflectance - transmittance and emissivity - curves achievable by multi-spectral EO measurements -  with matter having specific chemical/physical properties.  Theoretical models of radiation-matter interaction at the Earth's surface and through the atmosphere provide then suitable strategies for retrieving - from multi-spectral measurements of the radiation leaving the Earth - the most relevant chemical/physical properties of the matter composing its surface and atmosphere.,REMOTE SENSING531,PP1-3-1,Radiometric quantities: radiance - irradiance - flux - brightness - emittance - luminosity - etc.,The natural objects can either emit radiation (radiance - emittance) or be 'illuminated' by a source (irradiance). In the following a series of definitions for each of these terms is provided. \rThe first basic radiometric quantity is the radiance (Iλ) and it is defined as the ratio of the differential radiant energy (dE) to the product of effective area (dA) with the time interval (dt) - wavelength interval (dλ) and differential solid angle (dΩ). Iλ can be also referred as monochromatic intensity and it is expressed in units of energy per area per time per wavelength and per steradian (W m−2 sr−1). \rThe monochromatic flux density (Fλ) or the monochromatic irradiance of radiant energy is defined by the normal component of Iλ integrated over the entire hemispheric solid angle. It is expressed in units of energy per area per time per wavelength (W m−2). For isotropic radiation (i.e. - if the intensity is independent of the direction) - the monochromatic flux density is then Fλ = π Iλ. \rThe total flux density of radiant energy (F) - or irradiance - for all wavelengths (energy per area per time - i.e. - W) - can be obtained by integrating the monochromatic flux density over the entire electromagnetic spectrum.\rAll the above definitions refer to a point source of radiation. When the flux density or the irradiance is from an emitting surface (i.e. - an extended widespread source) - the quantity is called the emittance. When expressed in terms of wavelength - it is referred to as the monochromatic emittance. The intensity or the radiance is also called the brightness or luminance (photometric brightness). The total flux from an emitting surface is often called luminosity.,NONE532,PP1-3-2,Decay of the emittance with the square of distance from the source,The attenuation of radiation emitted from a source decreases with the square of the distance from its center based on inverse square law. It considers that the size of the sources increases with the square of their radius - causing the same rate of attenuation in flux density.,NONE533,PP1-3-3,Spectral Signatures of the matter,The relative amount of electromagnetic radiation reflected (absorbed - transmitted - emitted) by the matter at different wavelengths depends on its specific chemical composition and physical properties. The plots of corresponding physical quantities (reflectance - absorbance - transmittance - emissivity) against wavelength - are termed spectral signatures of the specific matter under study. In principle the analysis of spectral signatures obtained by multispectral EO sensors could allow us to identify/discriminate different cover types.\rThe interpretation of spectral signatures requires to well understand the e.m. radiation-matter interaction process. In very simple term we expect that incident radiation  I(λ)can be reflected - absorbed or transmitted by the matter so that for the energy conservation should be: \r\r\rI(λ)=I(λ -R)+I(λ -A) - I(λ -T) \r\r                                                       \rbeing I(λ -R) - I(λ -A) and I(λ -T) the reflected - absorbed and transmitted fraction of I(λ). From the previous relation descends (dividing both members for I) that:\r\r\r1=R(λ)+A(λ)+T(λ)\r\r\rbeing:\r\r\rR(λ)=I(λ -R)/I(λ) named Reflectance\rA(λ)=I(λ -A)/I(λ) named Absorbance\rT(λ)=I(λ -T)/I(λ) named Transmittance\r\r\rThey are all specific properties of the considered matter and are not independent each others.\rIn particular for an opaque medium with T(λ)=0 it is:\rR(λ)=1-A(λ),NONE534,PP1-3-4,Spectral Signature of Vegetation - Water - Soil,Vegetation - water and soil represent the most common cover types of Earth surface. Their reflectances in the VIS/NIR/SWIR spectral range - plotted against wavelength in the 0 -4-2 -5 micron - represent the most important (basic) spectral signatures for whatever application devoted to Earth surface study. Other spectral signatures (e.g. in emissivity) in the Thermal InfraRed range are particularly important to infer specific properties of Mineral and Rocks (ref. [PP1-3-5] Spectral Signature of Mineral and Rocks). In order to discriminate among such basic cover types - the (ref. [IP3-1-2-3]) NDVI (Normalized Difference Vegetation Index) is the most simple and powerful diagnostic tool in the VIS/NIR spectral range  \rNDVI values ranging between the values -1 and +1 - are higly positive for fully vegetated (up to NDVI=1) or partly vegetated (NDVI>0 -3) targets - still positive (>0) for bare soils - negative for water bodies. Values around zero are expected for clouds thanks to their similarly high reflectances both in the NIR and VIR spectral bands (ref. [PP1-3-6] Spectral Signature of Clouds).  \r\rVegetation. a) in the visible range most of the incomig radiation is adsorbed by the photosynthetic process - transmittance is very low. The residual reflected radiation has a small peak of reflectance around 0.5 microns which is responsible of the green colour associated to vegetation by the human vision sytem (limited to the VIS spectral range); b) in the NIR range vegetation exhibits its higher reflectance together its higher transmittance (very low absorbance) so that leaf density can be estimated thanks to the the contributes (decreasing with depth) of underlaying leaf layers; c) in the SWIR spectral range (in particular in the water bands around 1 -4 and 1 -9 microns) it is possible to appreciate the vegetation water content. As much it is - as more incident radiation is absorbed and less is the reflected fraction of radiation.\rBare Soil. Spectral reflectance is normally increasing moving from the VIS to the SWIR spectral region. Water features around 1 -4 and 1 -9 microns give information on soil water content (see before). Others specific features are described in [PP1-3-5] Spectral Signature of Mineral and Rocks\r\rWater. Spectral reflectance of clean deep water is quite low reaching quickly the zero value as soon as wavelengths passe  microns. However it is important to note that such a very low reflectance is due to a very high transmittance in the VIS range and to a very high absorbance in the NIR/SWIR regions (ref. [PP2-2-5-2] Attenuation Lenght and Penetration Depth). This means that water is quite transparent in the VIS spectral range (so that - in case of shallow waters - measured reflected radiance can be significantly increased by the contribution of bottom of the sea). Water is completely opaque - instead - in the NIR/SWIR. In this spectral region - even in presence of shallow waters - the presence of suspended matter (that increases the measured reflectance both in the VIS and NIR/SWIR ranges) can be better discriminated (than in the VIS) from the contribute of the bottom of the sea that - in this spectral range - is zero.,NONE535,PP1-3-5,Spectral Signature of Mineral and Rocks,Spectral signatures of rocks and mineral provide information on their chemical composition and crystal properties - grain size and roughness over a wide range of wavelengths from the visible to the thermal infrared.\rIn the Visible and Near-InfraRed (VNIR; 0.4÷1.0 µm) region - spectral features are dominated by electronic processes in transition metals - such as Fe - Mn - Cu - Ni - Cr - etc. Therefore - iron is the most important constituent having spectral properties in the VNIR - and the iron-rich minerals are characterized by low reflectance (high absorbance) below 0.7 µm.\rOther minerals - which represent the major part of the Earth's surface rocks - such us Si - Al and some anion groups (e.g. silicates - carbonates - oxides) hydroxides - have less spectral features in the VNIR region - but exhibit much more evidences in the Short-Wave InfraRed (SWIR; 1÷3 µm) region. In fact - spectral features of hydroxyls and carbonates mark the SWIR region.\rThe hydroxyl ion is a widespread constituent occurring in rock forming minerals such as clays - micas - chlorite etc. It shows a vibrational fundamental absorption band at about 2.74÷2.77 µm and an overtone at 1.44 µm.\rCarbonates - which are commonly in the Earth surface rocks in the form of calcite (CaC03) - magnesite (MgC03) - dolomite [(Ca-Mg) C03] and siderite (FeC03) - shows a typical absorbance feature around 2.3 µm - instead the water content can be instead evaluated by the depth of absorption at 1 -4µm and 1 -9 µm.\rThermal InfraRed (TIR; 1÷20 µm) region - from a geological point of view - is a particularly important spectral region for remote sensing aiming at compositional investigations of terrestrial materials. In fact - the fundamental vibration features of many rock-forming mineral groups (e.g. silicates - carbonates - oxides - phosphates - sulphates - nitrates - nitrites - hydroxyls) occur in the TIR region. Briefly:\ra) the silicates - which are most abundant group of minerals in the Earth's crust - shows vibrational spectral features due to the presence of Si04-tetrahedron around 8 µm to 12 µm; b) the carbonates show a weak feature around 11.3 µm that can be detected; c) the sulphates display bands near 9 µm and 16 µm; d) the phosphates also have fundamental features near 9.25 µm and 10.3 µm; e) the features in oxides usually occupy the same range as that of bands in Si-O - i.e. 8 µm to 12 µm; g) the nitrates have spectral features at 7.2 µm and the nitrites at 8 µm and 11.8 µm; h) the hydroxyl ions display fundamental vibration bands at 11 µm.,REMOTE SENSING536,PP1-3-6,Spectral Signature of Clouds,The determination of spectral signatures for scenes with a high degree of spatial complexity is considered as one of the most persistent problems in atmospheric radiation - especially at the surface - where satellite observations can only be used indirectly to infer energy budget terms. In the shortwave (solar) spectral range - it is especially challenging to derive consistent albedo - absorption - and transmittance from spaceborne - aircraft - and ground-based observations for inhomogeneous cloud conditions and is closely related to the long-debated discrepancy between observed and modeled cloud absorption.\rThe cloud spatial structure is revealed as a spectral signature in shortwave irradiance through the physical mechanism of molecular scattering. However - the study of specific mechanisms is rather complex since the satellite instruments cannot completely describe the spatial distribution of cloud and the variability of scattering and absorption properties.  For this reason - several studies deal with the problem described above - as a challenge for estimating spectrally the cloud optical properties (such as the albedo and transmittance) as well as scattering and absorption processes taking place in the cloud system with adequate resolution. Hence - the above mechanisms can be described using three dimensional (3-D) radiative transfer models. Those models receive auxiliary information from cloud imagery and radar observations. The molecular scattering (Rayleigh) was the only one directly dependent on the wavelength of the vertical radiative flux. Moreover - it was considered as a spectral perturbation of backtracked horizontal exchange of solar radiation due to the inhomogeneous distribution of cloud. The horizontal photon transport is highly correlated to its spectral dependence.\rConcerning the presence of cirrus or ice clouds - the effect of their phase function and the vertical distribution were evaluated on the scattering of far infrared radiation. Thus - the accurate reconstruction of the phase function of cirrus clouds potentially indicates the need for application of a radiative transfer model. This specific module necessarily includes scattering parameters - while the accuracy of its calculations needs to be verified against real measurements. \rFor several applications the preliminary detection of those portions of the scene affected by the presence of clouds (cloud detection) is mandatory. For studying properties of Earth's surface targets affected by the presence of clouds are flagged just to exclude them by further analyses. In some case clouds themselves are the object of interest. In both cases the identification of clouds (and their classification) is mostly done by using (combination of) specific spectral signatures. Generally speaking  clouds are highly reflecting VIS/NIR radiation showing (due to their heigth) brigthness temperatures (in the TIR region) lower than underlying surfaces. Thin or semi-transparent clouds are still detectable for their higher reflectance over the sea which represents a quite dark bacground in the VIS/NIR/SWIR region. Over land (much more reflecting) such a test is not more efficient and more sophisticated tests (e.g. Brigthness Temperature Difference in the split window bands around 11 and 12 microns) are required.  In presence of very cold - high reflective backgrounds (e.g. snow - glaciers - etc.) both tests on the VIS reflectance and on TIR brigthness temperature could fail. More specific tests exploiting the reflectance drop of snow in the SWIR (where clouds are still saving their higher reflectance) helps to discriminate the presence of clouds from clear sky conditions even over a snow background.  In the microwaves clouds are quite transparent except when coupled with coarse particles related to rain - snow - hailstones (precipitating clouds). In that case Mie scattering dominates strongly reducing the amount of radiance collected at the sensor (lower brigthness temperature in the microwave spectral range).,NONE537,PP1-3-7,Composition of spectral signatures (Linear Mixing),If the resolution is low enough that disparate materials can jointly occupy a single pixel - the resulting spectral measurement - made by the sensor - will be the composite of the individual spectra. Under the linear mixing model (LMM) - each observed spectrum in each pixel of a given image is assumed to result from the linear combination of the N endmember spectra present in the pixel. The reflectance spectrum of each endmember is weighted by the fractional area coverage of it in the pixel. \rHowever - if the components of interest in a pixel are in an intimate association - like sand grains of different composition in a beach deposit - light typically interacts with more than one component as it is multiply scattered - and the mixing between these different components are nonlinear. Such nonlinear effects have been recognized in spectra of: particulate mineral mixtures - aerosols and atmospheric particles - vegetation and canopy. In this case a non-linear mixing model (NLMM) should be applied. To summarize: Linear mixture model assumes that endmember substances are sitting side-by-side within the pixel; Nonlinear mixture model assumes that endmember components are randomly distributed throughout the pixel - causing multiple scattering effects. \rIn the linear mixing case - the basic premise of mixture modelling is that within a given scene - the surface is dominated by a small number of distinct materials that have relatively constant spectral properties. These distinct substances (e.g. - water - grass - mineral types) - characterized by a well-defined spectral signature are called endmembers - and the fractions in which they appear in a mixed pixel are called fractional abundances. Then - finding the endmembers that can be used to ‘unmix’ other mixed pixels becomes a crucial issue. \rIdentify fractional abundances of distinct substances from the spectral signal of a mixed pixel is one of the application in which hyperspectral images can provide an valuable support.,NONE538,PP1-3-8,Definition of active and passive remote sensing techniques,One of the most common ways to classify remote sensing systems consists in distinguishing them into the passive systems - which detect naturally occurring radiation - and the active systems - which emit radiation and analyse what is sent back to them. The passive systems can be further subdivided into those that detect radiation emitted by the Sun (this radiation consists mostly of ultraviolet - visible and near-infrared radiation) - and those that detect the thermal radiation that is emitted by all objects that are not at absolute zero (i.e. all objects). For objects at typical terrestrial temperatures - this thermal emission occurs mostly in the infrared part of the spectrum - at wavelengths of the order of 10 μm (the so called thermal infrared region) - although measurable quantities of radiation also occur at longer wavelengths - as far as the microwave part of the spectrum. Active systems can - in principle - use any type of electromagnetic radiation - resulting able to obtain measurements anytime - regardless of the time of day or season. In practice - however - they are restricted by the transparency of the Earth’s atmosphere at the specific spectral range considered. In any case they can be used for examining wavelengths that are not sufficiently provided by the sun - such as microwaves - or to better control the way a target is illuminated. Active sensors may be classified according to the use that is made of the returned signal. Two main methods have been identified to this aim so far: the Ranging technique mostly concerns with the time delay between transmission and reception of the signal - while the Scattering one is mostly focused on the strength of the received signal.,REMOTE SENSING539,PP1-3-9,Optical properties of water,Light has a key role for aquatic ecosystems - both in marine and freshwater. It penetrates underwater and interacts with dissolved and particulate water constituents - the optically active constituents (OACs). They absorb and scatter the light - giving water its characteristic colour and affect the light availability underwater. The three main OACs are phytoplankton - coloured dissolved organic matter (CDOM) and suspended particulate matter (SPM) and vary in time and space. Absorption and scattering represent the inherent optical properties (IOPs) of water and depend solely on the OACs present in the water. In addition - water bodies have apparent optical properties (AOPs) that depend both on OACs and the incident light field.\rThe chlorophyll in the phytoplankton absorbs blue and red wavelengths and reflects green. Therefore - the oceans appear blue-green depending on the concentration of phytoplankton. CDOM is primarily tannin-stained water released from decaying detritus. High CDOM concentrations appear yellow-green to brown. CDOM absorbs ultraviolet (UV) light in the surface waters which is harmful for phytoplankton but competes with phytoplankton for light. Inorganic suspended matter (ISM) is the suspended sediment in the water. It is a component of SPM and strongly scatters longer (red) wavelengths. High ISM concentrations give water a reddish-brown colour. Pure water - however - absorbs longer wavelength red light. As natural waters vary in their composition - oceanographers introduced ocean classification schemes based on the optical properties of water. The main differentiation is between Case 1 open ocean waters and Case 2 coastal waters. In open ocean waters - the optical properties are dominated by phytoplankton and covarying material. In coastal waters - optical properties are dominated by suspended sediments and CDOM that vary independently of phytoplankton.,NONE540,PP1-3,Sensing of EM radiation.,Measuring the signal emitted (received) by a radiation source  (detector),NONE541,PP1-4-1,General equation of radiative transfer.,Radiative transfer equation (RTE) is the governing equation of radiation propagation in a media - which plays a central role in the analysis of radiative transfer in gases - semitransparent liquids and solids - porous materials - and particulate media - and is important in many scientific and engineering disciplines. \rThe RTE states that when radiation (a light-ray) propagates through matter (gas - dust - liquid) - the incident radiation could be absorbed or scattered by matter - or radiation emitted from matter could append to the incident radiation. As a result - the intensity of radiation would change temporally - spatially - and directionally. The study of the propagating way of radiation in matter is the radiative transfer. In more detail - the radiation traversing a medium may be attenuated due to the density - mass scattering and absorption of material. In contrast - the radiation’s intensity can be strengthened by emissions from the material plus multiple scattering from all directions. All the above interactions are described mathematically by the general radiative transfer equation.\rThere are different forms of RTEs that are suitable for different applications - including the RTE under different coordinate systems - the transformed RTE having good numerical properties - the RTE for refractive media - etc.. Furthermore - several fundamental numerical methods for solving RTEs are proposed up to now focusing on the deterministic methods - such as the spherical harmonics method - discrete-ordinate method - finite volume method - and finite element method.,NONE542,PP1-4-10,Retrieval of atmospheric parameters by inversion of multi-spectral radiances,The inversion approach aims at retrievals of trace gas concentration and temperature profiles of atmospheric state - namely the modeled state vector - based on the measured radiance transmitted or reflected or scattered (SCIAMACHY spectrometer) by the Earth-Atmosphere system. Satellite instruments measure the radiance L that reaches the top of the atmosphere at given frequency v.  The measured radiance is related to geophysical variables of Earth's atmosphere  (e.g. temperature vertical profiles and chemical composition - aerosols - clouds - rain - etc.) and surface (e.g. temperature - spectral emissivity and reflectance - etc.) by the Radiative Transfer Equation (RTE). In RTE measured spectral radiances are assumed as the result of different contributions:\ra) thermal emission from the different layers (at heigt z) of atmosphere at temperature T(z) modulated by the atmospheric transmittance from z to the sensor heigt. It depends on both temperature profile T(z) and trace gas concentration along the optical path;\rb) Surface emission. It depends mostly on Eart's surface temperature T(0) and spectral emissivity\rc) Surface reflection/scattering. It depends on spectral reflectance and local properties like surface rugosity \rOthers - more complex contributions comes from: cloud/rain - aerosols - etc.\rIn its simplified form - terms a) and b)  dominate as far as InfraRed (IR) radiances are considered. Term a) can be neglected in those bands where atmosphere is transparent (atmospheric windows). Term b) can be negletcted in the IR spectral bands (sounding channels) where it is fully adsorbed by some specific constituent of the atmosphere.  Among the IR sounding channels some ones are selected being associated to atmospheric constituents (like CO2 or oxygen) whose mixing ratio in the atmosphere is known to be constant. For radiances measured in these bands term a) in RTE depends only on T(z) (through a Fredholm equation of the first kind) that can be then retrieved by inversion methods.  When T(z) are known trace gas concentrations survive as the only unknown of term a) and can be retrieved by inversion methods using radiances measured in their corresponding sounding channels. Similar inversion strategies have been suggested as far as radiances (emitted - transmitted - reflected - adsorbed) measured in different spectral ranges (from the Visible to the Microwaves) are considered.,NONE543,PP1-4-2,Cross Section of Extinction (Absorption - Scattering) per Mass Unit,In the field of radiation scattering and absorption - the cross-section - analogous to the shape of a particle - is used to determine the amount of energy diverted from the original beam by the particle. This parameter is called mass cross section - when it is in reference to unit mass (cm2g-1).,NONE544,PP1-4-3,Absorption Coefficient,When the mass cross-section is multiplied by the density of particle - the extinction coefficient is calculated - namely the sum of absorption and scattering coefficient - whose the units are related to length. Especially - the absorption coefficient (k (cm•atm)-1) is the product of strength of absorption with the Loschmidt’s number.,NONE545,PP1-4-4,Source Function (Coefficient),The source function - Jλ - has units of radiant intensity and it is defined as the ratio of the source function coefficient to the mass extinction cross section. The Jλ determines the intensity that are acquired in a homogeneous medium.,NONE546,PP1-4-5,Beer-Bouguer-Lambert law.,If the monochromatic beam (Iλ) of radiation attenuates due to absorption - but it remains unaffected from emission contributions and multiple scattering of homogeneous Earth-Atmosphere system - it can be expressed by Beer-Bouguer-Lambert law. This law also expresses the monochromatic optical depth (τλ) and transmissivity (Τλ) of the above system.,NONE547,PP1-4-6,Schwarzshild equation and its solutions,The Schwarzschild equation provides an interpretation for the infrared radiation that undergoes the absorption and emission processes simultaneously - while the scattering efficiency is considered negligible. Hence - its solution is obtained by the integrating of relationship that invokes Kirchhoff’s law and summing the two above processes along a ray path.,NONE548,PP1-4-7,Concepts of Optical path and Optical thickness.,The Atmosphere-Earth system that monochromatic beam (Iλ) of radiation travels - is called optical path. It expressed by optical path length - namely the product of geometric length and the refractive index of medium. It determines the optical thickness - namely a measure of the cumulative depletion of Iλ directed in straight-downward.,NONE549,PP1-4-8,Radiative transfer in presence of clouds,Radiative transfer is highly nonlinear and non-local against the cloud structure at a high spatial resolution. Hence - a Monte Carlo approach can be used for the representation of cloud structure and interactions between photons and clouds. This approach is more efficient than the method of representing clouds as horizontally homogeneous.,NONE550,PP1-4-9,Line-by-line radiative transfer models,The line by line radiative transfer model (LBLRTM) is an accurate and flexible model for the estimation of the spectral radiance and transmittance over the full spectral range (microwave to ultraviolet) - using a first-order perturbation algorithm. It is considered as the basic tool for the creation of retrieval algorithms employed by the ground-based and satellite instruments - while the latest updates in spectroscopic factors are derived from the high-resolution transmission molecular absorption (HITRAN) database. A LBLRTMs is continuously updated and validated against highly accurate spectral measurements. Its errors are related to uncertainties in line parameters and shape. The shape is a Voigt line which is a linear combination of approximating functions for the description of all atmospheric levels. LBLRTML is combined with the continuum MT_CKD (Mlawer - Tobin - Clough - Kneizys - Davies) model which in turn includes the atmospheric constituents of water vapor - carbon dioxide (CO2) - molecular oxygen (O2) - molecular nitrogen (N2) - and ozone (O3) - and the molecular extinction process (Rayleigh scattering). A recent version of LBLRTM calculates analytically the Jacobians equations for obtaining meteorological parameters. Also - this model version retrieves the optical parameters of clouds related to scattering and emissivity. The LBLRTM is widely used in radiation and climate applications. It is capable to calculate the absorption degrees of various atmospheric constituents which are utilized afterward from climate and weather prediction models for estimating the broadband solar irradiance and the heating rates. Additionally - the complex radiative transfer models with fast computational time are initiated and trained by the LBRTM - since they are used subsequently on numerical weather prediction (NWP) assimilation systems.,NONE551,PP1-4,Fundamentals of Radiative Transfer,Theory of radiative transfer describe the transmission of the electromagnetic radiation through a medium.,NONE552,PP1-5-1,Reflection - Refraction and Dispersion of the light,Light is the electromagnetic phenomenon we exploit for remote sensing. Its basic laws concerning the transmission through the interface of two different media are governed by reflection and refraction. Reflection governs the way light is backpropagated and refraction dictates how light is transmitted. Refraction is related to the real refractive index of a medium. Dispersion relates to the way the light of a given wavelength is transmitted. Since light of different wavelengths are transmitted at different angles - the phenomenon leads to the concept of dispersion. These three simple principles are at the core of the understanding technology of remote sensing.,REMOTE SENSING553,PP1-5-11,Einstein’s theory of radiation: photons - photoelectric effect - absorption - emission; Stimulated emission: the laser,The theory provides the bulk of physical explanation and related laws - which govern absorption - emission and spontaneous emission from the ordinary matter. Early laws about thermal radiation and the blackbody emission - such as Rayleigh-Jeans - Wien - Planck laws are cast in a single theory and formalism through the concept of quantized energy at the level of atoms emission/absorption of light. Explain the modern concept of quantum optics and their link to the design of modern devices for the measurements and/or production of coherent light.,NONE554,PP1-5-14,Electric conduction in solids: semiconductors - p-n- junction - diode and transistors,Solid state modern detectors rely on non-metal junction - which can be designed and operated to yield a bandgap energy according to the spectral range (infrared - visible - UV) to be detected. The basic principles of how these devices are designed and fabricated is important to develop and design new sensors useful for the various remote sensing applications.,REMOTE SENSING555,PP1-5-15,Photovoltaic and photoconductive detectors: MCT - InSb - bolometer - CCD devices,Modern detectors of electromagnetic radiation in the infrared - VIS - UV spectral regions are designed and fabricated based on suitable junctions or electro-optical devices. The performance of these systems needs to be assessed in terms of accuracy and precision. This is made through figures of merit such as Noise Power Spectral Density - Noise Equivalent Power. Detectors can be classified as photovoltaic or photoconductive devices - which allows to better classify the various noise sources: shot noise - 1/f noise - Johnson noise - generation-recombination noise.,NONE556,PP1-5-2,Interference and Diffraction.,Interference and diffraction are phenomena related to the wave nature of electromagnetic radiation. They explain how light propagates in presence of obstacles. These phenomena are largely used in the fabrications of optical systems for remote sensing: e.g. radiometers and spectrometers.,REMOTE SENSING557,PP1-5-3,Michelson Interferometer,The Michelson interferometer is the instrument that exploits and evidence the interference of light. A masterpiece of experimental physics - the Michelson interferometer is the key architecture of the modern optical interferometers - which make it possible to measure the emitted Earth spectrum with hyperspectral resolution.,NONE558,PP1-5-4,Special relativity; Electromagnetic fields equations and propagations,The celebrated principle of constant speed of light and independence of the reference frame is important to explain the basic principles of instruments such as the Michelson interferometer. The basic physics theory to explain how electromagnetic fields propagates and the inter-relationship between electric and magnetic fields.,NONE559,PP1-5-6,Helmotz’s equations; Scattering from inhomogeneous media.,Helmotz’s wave equation arises in light and acoustic scattering problem and yields the general framework to investigate and analyse the scattering of time-harmonic acoustic and electromagnetic waves by a penetrable inhomogeneous medium.,NONE560,PP1-5-7,Foundations of geometrical optics - geometrical theory of optical imaging,Geometrical optics is governed by the laws of reflection - refraction and dispersion. Its applications are relevant to many optical systems involving ray tracing - wavefront propagation - thin film calculators (which underly many optical engineering calculations).,NONE561,PP1-5-8,Elements of the theory of interference and interferometers,Optical interferometers are nowadays used to develop and implement Fourier Transform Spectrometers - which can measure the emission spectrum of a given source with high spectral resolution at a constant sampling. This instrumentation is now at the core of modern hyperspectral sounders from satellite and have opened the way to the sounding of the Earth atmosphere with unprecedented spatial vertical resolution.,NONE562,PP1-5-9,Elements of the theory of diffraction and grating spectrometers,Diffraction gratings and dispersive element are the basic ingredients for radiometers and grating spectrometers. They are in some cases preferred to Interferometer systems because the optical layouts can be designed and implemented with no moving part or components. Many of the today satellite instruments - including sounder and imagers - rely on diffraction and/or grating spectrometers,NONE563,PP1-5,Basics of Optics and Modern Physics of Sensors,This section describes the theoretical fundaments of Optics and Modern Physics of Sensors relevant to the Earth Observation.,NONE564,PP1-6-1,Structure and chemical-physical composition of Earth's atmosphere,The temperature and pressure profiles determine the atmospheric structure. The latter consists of four basic levels - considering the vertical variability of the temperature. These main four levels are troposphere - stratosphere - mesosphere - and thermosphere. In the troposphere (0-12km) - which is the lowest layer of the atmosphere - all the meteorological processes that affect our everyday life take place. The lowest part of the troposphere is known as the boundary layer (0-3km) - where all the surface-atmosphere interactions and exchanges take place. The troposphere concentrates the water vapor and 90% of atmospheric mass - while the chemical composition of all atmospheric layers consists of nitrogen - oxygen - argon and trace gases. The main parameters that characterize the atmosphere structure are pressure - density - and temperature. All the aforementioned parameters are related to the atmospheric composition and vary with altitude - latitude - longitude and season. Additionally - the stratosphere - which is the layer above the troposphere - contains almost all of the ozone abundance (~90%) of the atmosphere in a region named as ozone layer and traced between 15 and 35km. The interaction of the incoming solar radiation with ozone in this layer causes the reduction of the incoming harmful UV radiation provoking the temperature increase in the stratospheric layer. The 99.9% of total atmospheric mass is concentrated in lower atmosphere (<50km) with Nitrogen (N2 - 78.08%) - Oxygen (O2 - 20.95%) and argon (Ar - 0.93%) being the major constituents of the atmosphere. Water vapor (H2O) is considered as a significant factor - too. Despite the fact that it depicts a very small amount of total atmospheric mass - it’s one of the most important greenhouse gases - along with carbon dioxide (CO2) and methane (CH4) - absorbing the Earth’s longwave (infrared) radiation - affecting the energy balance of Earth-Atmosphere system. Furthermore - water vapor plays a decisive role in the formation of clouds and precipitation. Together with the basic chemical (atoms - molecules - ions) constituents of a 'standard' atmosphere - aerosols of natural and anthropogenic origin have to be considered too - as far as the interaction of e.m. radiation with atmosphere is concerned.,NONE565,PP1-6-10,Water vapour and Cloud formation,The water vapour is the major radiative and dynamic parameter in the atmosphere. Its concentrations vary highly in space and time - with the tropospheric water vapor being determined by the hydrological cycle processes - namely the evaporation - condensation and precipitation and by large-scale transport processes. Specific humidity decreases rapidly with pressure (following an exponential function) and with latitude. In particular - the variability of the H2O concentration shows a bimodal distribution: it’s very small in the equatorial region and poleward - relatively small in stratosphere and shows a maximum in the subtropics of both hemispheres. The concentration of H2O in the lower stratosphere is controlled by the temperature of the tropical tropopause - and by the formation and dissipation of cirrus. The water vapor can condense into water droplets when it has a particle to condense upon.  The atmosphere continuously contains aerosol particles ranging in size from ∼10−3 to ∼20 μm. These aerosols are known to be produced by natural processes (volcanic dust - smoke from forest fires - particles from sea spray - windblown dust - and small particles produced by the chemical reactions of natural gases) as well as by human activity (particles directly emitted during combustion processes and particles formed from gases emitted during combustion). Some aerosols are effective condensation and ice nuclei upon which cloud particles may form. For the hygroscopic type - the size of the aerosol depends on relative humidity. Thin layers of aerosols are observed to persist for a long period of time in some altitudes of the stratosphere. \rClouds are global in nature and regularly cover more than 50% of the sky. There are various types of clouds. Cirrus in the tropics and stratus in the Arctic - and near the coastal areas are climatologically persistent. The microphysical composition of clouds in terms of particle size distribution and cloud thickness varies significantly with cloud type. Clouds can also generate precipitation - an event generally associated with midlatitude weather disturbances and tropical cumulus convection.,NONE566,PP1-6-11,Radiative Equilibrium. Adiabatic lapse rate,The radiative equilibrium is the principle - where the radiative emission and absorption are in balance based on Kirchhoff’s and Planck’s law - resulting in the steady temperature of planet. The adiabatic lapse rate displays the decrease of vertical temperature of a parcel with rate higher than 1oC per 100 metres.,NONE567,PP1-6-12,The Carbon Cycle - Greenhouse Effect,The atoms of carbon are building blocks of living organisms and they can move among organisms as a part of carbon cycle. Their transport rate to the atmosphere as carbon dioxide is vital - because this gas trap heat in the atmosphere - increasing the Earth’s temperature and causing Greenhouse effect.,NONE568,PP1-6-2,Absorption and scattering of solar radiation in the Atmosphere,The atmospheric absorption can cause an excitation or falling into the energy state of a particle - while the scattering is related to absorption and re-emission of radiation at all directions without changes in its frequency. Particularly - the main contributors of the incoming solar radiation absorptions are various molecules like the nitrogen (N2) - oxygen (O2) - ozone (O3) - water vapor (H2O). Additionally - other constituents of the atmosphere such as CO2 and CH4 - and other trace gases - aerosols - and cloud droplets can also absorb significant portion of the incoming solar radiation. Generally - the absorption of solar radiation is related to the wavelength of the solar spectrum. For example - gases and specific type of aerosols (black carbon - BC) or elementary carbon (EC) absorb in the ultraviolet (UV) and visible (VIS) part of solar spectrum. On the contrary - cloud droplets which are suspended in the atmosphere mainly scatter in UV and VIS and absorb in the infrared. The absorption of the incoming solar radiation from the atmospheric constituents reduces the harmful UV radiation and it is considered as the driving of atmospheric photochemistry. Moreover - scattering in the atmosphere can be divided into two mainly categories - firstly - the Rayleigh scattering which is the scattering of radiation by gases (mainly N2 and O2) and - secondly - the Mie scattering which is the scattering by aerosol particles and cloud droplets. The main difference between Rayleigh and Mie scattering is the direction of the re-emission of the incident solar radiation. For example - in the Rayleigh scattering the light have symmetrical direction either forward or backward whereas in Mie scattering the light is mainly scattered in the forward direction - depending on the size of the particle.,NONE569,PP1-6-3,Mie Scattering in the Earth's Atmosphere,Mie scattering refers primarily to the elastic scattering of light from atomic and molecular particles whose diameter is similar or larger than the wavelength of the incident light. We can say that - when the particle has a diameter greater than about a tenth of the wavelength - we are in the field of Mie scattering.\rThis scattering produces a pattern like an antenna lobe - with a forward lobe sharper and more intense than the back one - the larger the particle size the greater the intensity and sharpness of the anterior lobe. Unlike Rayleigh scattering - Mie scattering is not strongly wavelength dependent. In this case the predominant component for the quantification of scattering (in addition to the particle dimension) is the direction of the incident solar radiation.\rMore specifically - the amount of scattering in the backward direction depends upon a wave relation tending to decrease in accordance with the growth of the particle size until it reaches a certain value for which the back scattering becomes a constant quantity. This condition is reached when the diameter of the particle is approximately equal to the wavelength of the incident radiation.\rIn the atmosphere the Mie scattering is commonly caused by particles (aerosols) floating in the atmosphere (due to Dust - smoke - fog - rain drop). \rIn nature it is possible to see the effects of Mie scattering - for example - in the evenings when there is a lot of fog and the dazzling headlights of our car do not allow us to see the road ahead. \rThe Mie theory provides the solution for the amount of scattering in case of a spherical medium due to an incident wave.,NONE570,PP1-6-4,Rayleigh Scattering in the Earth's Atmosphere,Scattering is a physical process by which a particle in the path of an electromagnetic wave continuously exstracts energy from the incident wave and reradiates that energy in all directions. In more detail - it occurs when a photon’s electromagnetic field hits a particle’s electric field in the atmosphere and is deflected into another direction. The Rayleigh scattering falls into the elastic scattering phenomena - in which the individual photon changes its direction of propagation but non its energy. The Rayleigh scattering involves air molecules (mainly N2 and O2) whose diameter (x) is much smaller (one-tenth at least) than the incident radiation wavelength (λ) (i.e. - x << λ). The amount of scattered intensity (I) depends on the incident light wavelength (λ) and the refractive index (n) of air molecules. However - the refractive index can be considered relatively negligible as compared to the explicit wavelength term. In this way - the intensity scattered by air molecules in a specific direction is strongly dependent on the wavelength (λ) - as expressed in the form Iλ~1/λ4. The inverse dependence of the scattered intensity on the wavelength to the fourth power allows at explaining the blue color of sky - caused by the scattering of sunlight off the atmosphere molecules. To better understand this phenomenon - it is worth considering that a large portion of solar energy is contained between the blue and red regions of the visible spectrum - where blue light (0.425 µm) has a shorter wavelength than red light (0.650 µm). Consequently - based on the above-mentioned equation - blue light scatters about 5.5 times more intensity than red light. For this reason - more blue light is scattered than red - green - and yellow - and so the sky appears blue - when viewed away from the sun’s disk. The Rayleigh scattering of unpolarized sunlight by air molecules has maxima in the forward and backward directions - whereas it shows minima in the side directions. Furthermore - the light scattered by particles is not delimited only on the incidence plane - but is visible in all the azimuthal directions. The derived scattering patterns are symmetrical in the three-dimensional space - because of the spherical symmetry assumed for air molecules.,NONE571,PP1-6-5,Thermal infrared radiation transfer in the atmosphere,When we talk about “thermal infrared (or terrestrial) radiation” we commonly refer to the energy emitted from the Earth-atmosphere system. Trapping of thermal infrared radiation by atmospheric gases is typical of the atmosphere and is therefore called the “atmospheric effect”. The atmospheric effect is sometimes referred to as the “greenhouse effect” because in a similar way glass - which covers a greenhouse - transmits short-wave solar radiation - however absorbs long-wave thermal infrared radiation. Imagine a beam of radiation travelling through a small section of air. The air is made up of changing concentrations of different species - with all molecules absorbing and emitting thermal radiation at different rates. As the radiation travels through different layers of the atmosphere - the intensity of radiation will constantly be modified by both absorption and emission processes as described by the Schwarzschild's equation. In case of a sensor on board of a satellite - the net radiation measured would be that which is attenuated through each layer (as small increments of absorption and emission) from the surface to the top of the atmosphere plus the radiation emitted directly from the atmosphere. In this case - this process can be described by the radiative transfer equation (RTE). \rThe equation of radiative transfer simply says that as a beam of radiation travels through the atmosphere - it loses energy to absorption - gains energy by emission - and redistributes energy by scattering. Many radiative transfer codes exist which are able - i.e. on the basis of known properties of the atmosphere - to computed the effect of the atmosphere on the thermal infrared radiation providing atmospheric transmittance (absorption) - atmospheric scattering and atmosphere path emission. Commonly - in satellite remote sensing - the thermal infrared region is defined as the region of the electromagnetic spectrum comprised between 8 and 14 micron. In an atmosphere free of particles (aerosols due to phenomena like fires - volcanic eruption - dust storm - etc.) the thermal infrared radiation is mainly affected by triatomic gases like water vapor - carbon dioxide and ozone.,REMOTE SENSING572,PP1-6-6,Light scattering by atmospheric particulates,Light scattering by particles is the process by which small particles cause optical phenomena - such as rainbows - the blue color of the sky - and halos. Mie scattering defines the interaction of light with particulate matter with a dimension comparable to the wavelength of the incident radiation. It can be regarded as the radiation resulting from a large number of coherently excited elementary emitters (molecules for example) in a particle. Since the linear dimension of the particle is comparable to the wavelength of the radiation - interference effects occur. The most noticeable difference to Rayleigh scattering is - generally - the much weaker wavelength dependence and a strong dominance of the forward direction in the scattered light. The calculation of the Mie scattering cross section - which involves summing over slowly converging series - is complicated even for spherical particles - it is worse for particles of an arbitrary shape. However - the Mie theory for spherical particles is well developed and a number of numerical models exist to calculate scattering phase functions and extinction coefficients for given aerosol types and particle size distributions.,NONE573,PP1-6-7,Earth's (standard) Atmosphere Transmittance,Each time radiation passes through the atmosphere it is attenuated to some extent. We refer to this attenuation with the term 'atmosphere transmittance'. The typical atmospheric transmittance between wavelengths of 250 nm and 2500 nm - i.e. in the ultraviolet - visible - near-infrared and short-wave-infrared regions of the spectrum is dominated bywater vapour - although methane - carbon dioxide and molecular oxygen are also responsible for a few absorption lines. The behaviour in the visible region is dominated by molecular Rayleigh scattering. At the short-wavelength end of the spectrum - in the ultraviolet - absorption by ozone becomes very significant. Above 2500 nm up to the upper limit (13500 nm) of the optical electromagnetic spectrum useful for Remote Sensing - the atmosphere transmittance is mainly affected by triatomic molecules (H20 - CO2 and O3). However - the atmospheric effects (transmittance) is strongly depending on the electromagntic wavelength. Remote Sensing exploits the region of relative atmospheric transparency called atmospheric windows.,REMOTE SENSING574,PP1-6-8,Atmospheric (spectral) windows for EO,With the term 'atmospheric windows' we refer to the regions of the electromagnetic spectrum where the interaction between the atmosphere constituents (i.e. - molecules - aerosols - and cloud particles) and the electromagnetic radiation is minimized - namely the mechanisms of scattering and absorption of the radiation are less relevant than the transmission one. Therefore - the radiation collected at the sensor in these spectral regions is strictly depending on the Earth surface features - allowing to infer information about the processes/phenomena there in progress at the time of the acquisition. There are three main spectral ‘windows’ in the Earth's atmosphere. The first of these includes the visible and near-infrared (VNIR) parts of the spectrum up to the medium infrared - between wavelengths of about 0.38 μm and 3.5 μm - although it does also contain a number of opaque regions. This spectral interval includes the small portion of the electromagnetic spectrum to which human eyes are sensitive to (i.e - the visibile region between 0.4 and 0.7 μm). The second is a rather narrow region between about 8 μm and 15 μm - in which is found the bulk of the thermal infrared (TIR) radiation from objects at typical terrestrial temperatures. In this region there is only a main opaque interval - around 9.6 μm due to the presence of the ozone band. The third more or less corresponds to the microwave region - between wavelengths of a few millimeters and a few meters. Therefore - each remote sensing instrument that should be able to fully penetrate the Earth’s atmosphere has to be designed to operate in one of these three ‘window’ regions.,REMOTE SENSING575,PP1-6-9,The Water Cycle,The water cycle is a continuous purification process of water on Earth due to the movement of water species among various reservoirs. This cycle is vital for Earth’s life - ecosystems - and living organisms. The water cycle includes mainly four processes. Water is evaporated from ocean and land surfaces driven by solar heating. The resulting water vapor rises upwards into the atmosphere - transported by the winds - cools - and due to low air temperature condensates into liquid droplets and ice crystals to form clouds. The ice or/and liquid droplets collide - increase their size - and precipitate as snow or rain to Earth’s surface and oceans. The subtraction of energy (latent heat of evaporation) at low latitudes related to the evaporation processes as well as its release (latent heat of condensation) at higher latitudes related to the condensation processes is a formidable way to guarantees the heat transport from the warmer part of the Earth to the colder ones mantaining local air temperature more compatible with the human life.  The starting point of the water cycle is not unique - but the oceans can be selected as the initial reservoir. Other important reservoirs are considered ice sheets - lakes - and rivers. \rThe hydrosphere is defined by the various water reservoirs which are characterized by different residence times – the time spends the water molecules in a reservoir. The water residence time – the rate at which the water comes out the reservoirs – varies for each reservoir extending from hundreds (Greenland Ice Sheet) or thousands of years (Antarctic Ice Sheet) to years and days for rivers and lakes - respectively. It also defines the energy transferred from the Earth to the Atmosphere which increases for short-term residence times. In long-term temporal scales - this energy is defined as the evaporation rate (E) and balances with the precipitation rate (P). This global energy balance breaks for shorter time scales depending also on the local and regional climate. For example - in regions located in the Inter-Tropical Convergence Zone (ITCZ) - the energy balance in the water cycle does not exist since the precipitation rate is much higher than the evaporation rate (P>>E) due to the horizontal movement of converging trade winds.,NONE576,PP1-6,Basics of Atmospheric Physics,Atmospheric Physics describe the processes affecting the physical - chemical and thermodynamic status of planetary atmospheres. In the context of EO sciences - it particularly refers to the physics of the interactions of e.m. radiation traveling across (or emitted by) the atmosphere as the main source of information collected by satellite (in general aerial) sensors.,NONE577,PP1-7-1,Temperature and heat,According to the second law of thermodynamics - heat is a measure of the movement or the flow of energy from hotter substances to colder ones and it is measured in Joules. In microscale - heat is known as internal energy. Two regions in thermal contact have the same temperature when there is no net exchange of internal energy between them. Heat is the net transfer of internal energy from one region to another - while temperature - which is the degree of hotness or coldness of an object - describes the average kinetic energy of molecules within substances. The faster the particles are moving - the higher their kinetic energy. Since the motion of the particles within an object is random - they do not move at the same speed and in the same direction - some of them move faster. Therefore - those particles have more kinetic energy than the others. Thermodynamic temperature can be defined for substances at (even Local)  Thermodynamic Equilibrium (i.e. in condition of density/pressure which allows an efficient equipartition of kinetic energy among molecules).  Temperature is then the measure of the average kinetic energy of such a system - and is usually expressed in Celsius (°C). When - particular conditions of very low pressure/density (like in the Earth's thermosphere) cannot guarantee energy equipartition among molecules (i.e. outside thermodynamic equilibrium) the concept of Kinetic Temperature should be used instead. The Celsius temperature scale is defined by international agreement in terms of two fixed points: the temperature of the ice point - which is defined as 0° Celsius - and the steam point as 100° Celsius. The Fahrenheit (°F) temperature scale is mainly used in the United States; on this scale - water freezes at 32 degrees Fahrenheit - and the temperature of boiling water is 212 F. The Kelvin scale (K) is the base unit of temperature in the International System of Units (SI). This temperature scale is obtained by shifting the Celsius scale by −273.15°; zero Kelvin is also called absolute zero.,NONE578,PP1-7-10,The constitutive equations of irreversible fluxes,Irreversible thermodynamics investigates the regularities in transport phenomena - namely heat and mass transfer - and their relaxation. It is based on the first law of Thermodynamics - which correlate the heat flow density with pressure and viscosity - and the second law that describe the temporal variations of local entropy for local continuous mass.,NONE579,PP1-7-11,Heat equation and special adiabatic systems - special adiabats of homogeneous systems,The Adiabatic process of homogeneous system occurs - when flow of heat is not exchanged across the boundaries of system and the system is characterized from uniform phase (solid or liquid or gases). In this case - the variations of entropy can be determined for some parts of system.,NONE580,PP1-7-12,Thermodynamics diagram - atmosphere static,The thermodynamic diagrams are used for the study of vertical structure and properties of the Atmosphere above a specific location. Especially - a static diagram represents a) an atmosphere with fixed potential temperature or b) a process curve of the change of variables of air parcel that rises adiabatically.,NONE581,PP1-7-2,Kinetic theory of gases,Kinetic theory of gases is based on a simplified molecular description of gases - from which the properties of volume - pressure and temperature can be derived. The assumptions of this theory are based on the random movements of molecules - their elastic collisions and the transfer of kinetic energy between them.,NONE582,PP1-7-3,Ideal gas laws,The ideal gas law or general gas equation describes the equation of state of hypothetical ideal gas. This equation correlates the pressure and volume with its temperature - while is characterized as a combination of the empirical laws of Boyle - Charles - Avogadro and Gay-Lussac.,NONE583,PP1-7-4,State function of ideal gases,The state functions of ideal gas are the pressure - volume - temperature - internal energy and entropy - which remain unchangeable in compared with the path. The internal energy is expressed through Joule’s law as a function of temperature of gas - while the entropy depends on the variation of volume and temperature.,NONE584,PP1-7-5,State function of the condensed gas phase,The phase rule for condensation is expressed as P+F=C+1. The terms of P - F and C describe the number of phases - minimum fixed variables and independent chemical species respectively. Concerning the condensed phases to distinguish the gases from liquids and solids - these are the density - molecular order - diffusion - etc.,NONE585,PP1-7-6,Thermodynamic process,When the system passes from initial to final state due changes in properties of temperature - pressure and volume - it is considered to have undergone thermodynamic process. The different types of thermodynamic processes are distinguished in the isothermal (fixed temperature) - adiabatic - isochoric (stable volume) - isobaric (stable pressure) and reversible process.,NONE586,PP1-7-7,Budget equations,Budget equations - namely heat - momentum and moisture budget - are interpreted through two frameworks - which are Eulerian and Lagrangian. Eulerian is utilized for the investigating of transfer of heat by the wind - while Lagrangian is concerned about the effects of ascending or descending airflows on the Earth-Atmosphere system.,NONE587,PP1-7-8,First law of thermodynamic,The First Law of Thermodynamics supports that the energy is conserved. Thus - the thermal energy is defined as the sum of warming or internal energy (microscopic effect) and work occurring per unit mass (macroscopic effect). For its application to the Atmosphere - the thermal energy input is given from the following mathematical expression: Δq=Cp·ΔT-(ΔP/ρ) - where Δq (J·kg–1) is the amount of thermal energy you add to a stationary mass m of air - Cp (J·kg–1·K–1) is the specific heat of air at constant pressure - ΔT (K) is the induced variation of temperature - so that  Cp·ΔT represents the heat transferred per unit air mass - ΔP (Pa = J·m-3) is the pressure difference and ρ (kg· m-3) is the air density.\rThe term Cp·T is defined enthalpy h - thus - the first term on the right side of eq. of thermodynamic first low for atmospheric applications - which is the corresponding enthalpy change is: Δh=Cp·ΔT. It is a characteristic possessed by the air.\rExpressing the first law of thermodynamics for atmospheric applications in conceptual form we can state that - given a quantity Δq of thermal energy added to a stationary mass m of air - a part of this energy heats the air - increasing its internal energy - but - as air heats up - its volume expands by an amount ΔV and pushes against the surrounding atmosphere - which responds with an equal and opposite pressure P that we can assume constant. Therefore - a part of the thermal energy introduced does not go to heat the air - but goes into macroscopic movement.,NONE588,PP1-7-9,Second law of thermodynamics,A natural process that starts from an equilibrium state and ends in another state - causing changes in direction of entropy (ΔS) or statistical disorder of the system - is interpreted by Second Law of Thermodynamics. This law is considered as an irreversible process and it is expressed as ΔS=Heat transfer/Temperature.,NONE589,PP1-7,Basics of Thermodynamics,Thermodynamics is the science of the relationships between heat - work - temperature - radiation - energy and properties of matter. These relationships are governed by the four laws of thermodynamics which allow a quantitative description - through measurable macroscopic physical quantities - of  processes that - at the level of microscopic constituents can be described by the statistical mechanics. Thermodynamics applies to a wide variety of topics relevant to EO science and technologies from atmospheric chemistry and meteorology up to sensor design and aeronautics.,NONE590,PP1-8-2,Equation of the rocket and launch of a satellite: payload determination,Starting from the standard Rocket Equation - assuming a relative speed of the burned (emitted) fuel  equal to 2 -4 km/s and zero initial speed - it is possible to evaluate (for a single-stadium rocket)  the mass percentage of payload that can be hosted on a platform depending on the final speed expected on the orbit. For instance a 28% payload is possible for a geostationary platform whose expected final speed on the orbit (radius 42.170 km) is 3 -7km/s. Instead for a polar platform at about 800km this percentage reduce up to the 4% being the final sped on the orbit expected to be 7 -5km/s.,NONE591,PP1-8-3,Real orbits. Life time of a satellite - orbit’s decay.,The orbit of a satellite is commonly defined through its so called Keplerian parameters. These parameters represent the trajectory that the satellite will follow if no-perturbation are acting on it. A series of forces act on the satellite to perturb it away from the nominal orbit. We can classify these perturbations - or variations in the orbital elements - based on how they affect the Keplerian elements. The actual orbit of a satellite will result from a combination of these perturbations. Periodic maneouvers are needed to bring the orbit back to nominal conditions. The lifetime of a satellite is defined as the time interval that it takes to decay from its initial altitude to an altitude causing the satellite reentry down to the atmosphere. Therefore lifetime of a satellite should not be confused with the time during which the satellite will provide useful information (this operational phase - in general - is designed to last 5 - 7 years). In fact - all satellite terminating operational phases in orbits passing through the LEO region should be de-orbited or - where appropriate - manoeuvred to an orbit with suitably-reduced lifetime - that is - should be left in an orbit where drag and other perturbations will limit lifetime. The actual duration of the satellite in orbit will depend from the intensity of the perturbations which will affect its orbit. In case of satellite on GEO orbit - at the end of the operational phases they will be located on a disposal orbit - that is an orbit which do not cross the protected region. The protected region is the altitude region ranging from GEO - 200 km to GEO + 200 km and inclination region between -15 deg and +15 deg. Satellites in low Earth orbit - with perigee altitudes below 1000 km - are predominantly subject to atmospheric drag. This force very slowly tends to circularise and reduce the altitude of the orbit. The rate of 'decay' of the orbit becomes very rapid at altitudes less than 200 km - and by the time the satellite is down to 180 km it will only have a few hours to live before it makes a fiery re-entry down to the Earth.,NONE592,PP1-8-4,Satellite orbits parametrization and choice,The choice of a satellite orbit mostly depends on its main application. From this point of view it represents a crucial part of a satellite mission design. The most important parameters to describe a satellite orbit are the inclination angle i (of the orbit plane respect to the equatorial plane) its eccentricity e and its height H from the Earth's surface. In principle whatever eigth H can be used - provided that the speed of the satellite on its orbit allows the centrigugal force to exactely compensate the gravitational one at that heigth. Polar (i close to 90°) and Geostationary (i=0 - H=35.800 km) orbits are the most common choices for EO satellites. In principle one single polar satellite can be sufficient to guarantee the global coverage of the Earth with equal quality of the images at all latitudes. All Geostationary satellites share the same circular orbit with H around 36000 km where the required speed exactely correspond to the one required to travel an entire orbit in 1 sideral day (orbital period P = 1 sideral day). This means that the satellite footprint is permanently in place over a specific Earth's location (e.g. for Meteosat 0°N - 0°E) allowing a quasi-continuous monitoring of a whole Earth's emisphere (with poor visibility of Earth's edges including Poles).  Polar satellites' heigths are usually in between 700-800 km - with orbital periods around 100min (i.e. about 14 -5 orbits/day) even if - lower orbits are also chosen particularly for very high spatial resolution payloads. Lower inclinations are also used (quasi-polar orbits) for specific applications. Due to the asphericity (and mass inhomogeneity) of the Earth - satellite orbit plane rotates around the Earth's polar axis with a period Pp producing (for elliptical orbits) the rotation of the orbit itself in its plane. A common choice for most EO polar satellites is to choose the orbital parameters in a way that Pp=1 year (Sun-Synchronous orbits).  Due to the synchronism between Earth's revolution around the Sun and the orbit plane precession around Earth' axis -  satellite passages happens at the same local solar time (similar illumination conditions) each time it flies over a specific region. This ensure repeatable sun illumination conditions facilitating image interpretation particularly for change detection or land monitoring applications. Other choices are possible when it is required to monitor with continuity high latitude regions.\r\rThis is the case of Molniya orbits which combine the continuity of observations typical of geostationary satellites with the possibility -  offered by polar orbits - to overfly the highest latitudes regions.  Its characteristics are: high eccentricity (e.g. e=0 -74 - axes 500 and 23.000 km) - P=1/2 sideral day (Geo-Synchronous) - inclination  (i=63 -4° or i=116 -6°) which guarantees the satellite footprint at the apogee remaining positioned on a fixed ground point  (non-rotating orbit). This way the satellite will spend more than 93% of its orbital period looking to the same emisphere even from a high latitude point of view.  \r\rSo called altimetric orbits respond to the specific needs of altimetry. In this case the orbital parameters are chosen in order to guarantee - for example: a) that the ascending and descending sub-satellite tracks intersect at roughly 90 degrees on the Earth’s surface (so that orthogonal components of the surface slope can be determined with equal accuracy; b) the possibility to monitor all phases of tidal effects on ocean surface.\r\rParticularly important for several applications (multi-temporal analyses - change detection - etc.) are the Exactly repeating orbits.\rThey are conceived in order that the sub-satellite track will repeat itself exactly after a certain interval of time. This allows images having the same viewing geometry during the satellite’s lifetime making moreover available a particularly simple method of referring to the location of images (navigation or geo-referenciation)  for example by referring to a ‘path and row’ system used for instance by the Landsat World Reference System (WRS). It is possible to arrange satellite orbits parameters in order to contemporary guarantee the sun-syncronism so that - not only satellite images collected on the same region can be easily super-imposed each-other but the same illumination and viewing geometry can be achieved. This is - for instance - the choice adopted for LANDSAT satellites whose images are typically available as a collection of scene of fixed dimension always similar each other when covering the same terrestrial area.,NONE593,PP1-8,Basics of Mechanics,Mechanics is the Physics branch dealing with the behaviour of physical bodies when subjected to forces or displacements. This section provides Mechanics basic elements necessary for determining the orbits of satellites and rockets. The different satellite trajectories will be illustrated with respect to their peculiarities,NONE594,PP1,Basics of Optical Remote Sensing,Optical Remote Sensing deals with those part of electromagnetic spectrum characterized by the wavelengths from the visible (0.4 micrometer) to the near infrared (NIR) up to thermal infrared (TIR - 15 micrometer). It regards the collection and interpretation of the e.m. radiation emitted - reflected - adsorbed and transmitted by the observed targets in order to derive their physical-chemical properties and related information. Such a possibility derives from the basic principle of (multi-spectral) remote sensing that is widely supported both theoretically (e.g. atomic and molecular spectroscopy) and experimentally (e.g. spectral signatures catalogues).     It states that - in principle (e.g. disposing of sensors with ideal spectral capabilities) the matter-radiation interaction depends on the wavelength of the  involved radiation and on specific (e.g. chemical/physical) properties of the matter that can be derived by the spectral analysis of the emerging (emitted - reflected - adsorbed or transmitted) radiation.  As far as Earth Observation is concerned - specific related concepts  have to be addressed like: the spectral  matter-radiation interactions (spectral signature concept) - natural sources (e.g. Earth - Sun) of optical e.m. radiation - theory of the Black Body - atmospheric physics and radiative transfer equations in the VIS-NIR and TIR spectral ranges - basic physics of e.m. optical sensors and image systems - physical fundaments of the interpretation of optical radiances collected by multi-hyperspectral passive  techniques.,REMOTE SENSING595,PP2-1-2-1,In-phase/Quadrature Component,A radar signal is a complex signal. It is represented by a real part - the in-phase component - and an imaginary part - the quadrature component. In-phase is usually annotated by “I” - and quadrature by “Q”. Considering single look complex data - each component is represented in a single image channel.,NONE596,PP2-1-2-2,Phasor,A phasor represents a complex number and its phase and amplitude equivalent. Considering a complex SAR image’s pixel - the real and imaginary part can be represented by a 2D vector in Cartesian coordinates. Its corresponding phase and amplitude information corresponds to the direction and length of the vector - respectively.,NONE597,PP2-1-2,Complex wave description,The signal emitted by a radar system is a microwave signal - which can be described using a complex wave representation. This implies that the signal can be entirely represented by a complex number - which characterizes both its magnitude and its phase at a certain moment of time. In the SAR context - the complex number is usually represented by a real part - the in-phase component (I) - and an imaginary part - the quadrature component (Q) - from which the corresponding magnitude and phase can be retrieved. In single look complex SAR data - each of these components is pictured in a single image channel. The terminology comes from electrical engineering - whereby the quadrature component is 90° out of phase with respect to the reference frequency and the in-phase component. This is necessary in order to retrieve the phase information during A/D conversion. The I component can be expressed as the signal amplitude multiplied by the cosine of the phase. The Q component corresponds to the amplitude of the signal multiplied by the sine of its phase. Using both components as input - the magnitude and phase for each signal echoes and location can be retrieved.\r\rThe relationship between I/Q terms and the magnitude and phase of the signal can be best represented using a phasor. A phasor represents a complex number and its phase and amplitude equivalent. It can be best illustrated by a 2D vector in a Cartesian coordinate system - which projections on the horizontal and vertical axes represents the real and imaginary part - respectively. The length of the vector correspond to the signal’s amplitude and its direction (angle between the horizontal axis and the vector) characterizes the phase of the signal. Using simple mathematical considerations - the relationship between I/Q and amplitude and phase can be established.\r\rEach signal echo and pixel of a complex SAR image can be represented with such a phasor and the necessary amplitude and phase information can be accordingly retrieved.,NONE598,PP2-1-4,Polarisation,Electromagnetic waves are polarized; the direction of the polarization corresponds to the direction of oscillation of the electromagnetic field. Typical and often used linear polarisations are: H (horizontally) and V (vertically) polarized waves of the plane of the electric field vector oscillations relative to the sensor coordinate system. The polarization state of a backscattered wave from a natural surface can be linked to the geometrical characteristics like shape - roughness and orientation and the intrinsic properties of the scatterer like moisture - salinity - density. The radar system is characterized by combination of polarization of transmitted and received pulse: HH - HV - VH or VV. Based on the polarization sent and obtained the radar systems are divided in three polarization modes. Single polarization refers to the same polarization transmitted and received; dual polarization - one polarization is sent and another received; or quad polarization - when system is able to transmit and receive all four types of polarization. When making a contact with a scatterer - the polarization of the EM-wave can change - depending on the geometrical and dielectrical properties of the scatterer. In order to get all necessary information about those changes - full polarimetric systems are required.,NONE599,PP2-1-5,Coherent,Property of signal or data set in which the phase of the constituents is measurable - and plays a significant role in the way in which several signals or data combine. Two waves with a phase difference that remains constant over time - are said to be coherent.,NONE600,PP2-1-6,Phase,In remote sensing - phase is the exact position within a periodic signal with respect to an arbitrary reference point. It is typically expressed as an angle and measured in degrees or radians - where one period corresponds to a phase of 360° or 2π - respectively. Mathematically - phase is the argument of a complex number - that is the angle between its geometric representation in the complex plane and the real axis. For this reason - complex algebra is often used in remote sensing to facilitate phase calculations. Due to its periodic nature - phase can only be measured unambiguously within one period. Consequently - phase measurements are commonly subject to 2π phase ambiguities. These ambiguities can often be resolved in a process called phase unwrapping - using a priori information about the signal - typically related to its continuity. Phase measurements are crucial for the creation of synthetic aperture radar (SAR) images - as well as for many SAR imaging techniques - including interferometric SAR (InSAR).,REMOTE SENSING601,PP2-1-7,Doppler effect,Shift in frequency caused by relative montion along the line of sight between sensor and the observed scene.,NONE602,PP2-1-8,Wave-particle dualism,The wave-particle dualism (duality) is a theory according to which all matter exhibits the attributes of waves and particles.,NONE603,PP2-1,Microwave portion of electromagnetic spectrum,The microwave portion of the electromagnetic (EM) spectrum ranges from 1 millimeter to 1 meter. Imaging radars are independent of weather conditions and can operate day or night. EM-waves are polarized. Normally only the horizontal (H) or vertical (V) linear polarizations are used. The radar system is characterized by combination of polarization of transmitted and received pulse: HH - HV - VH or VV. When making a contact with a scatterer - the polarization of the EM-wave can change - depending on the geometrical and dielectrical properties of the scatterer.The data can be acquired from both the ascending (northwards) and descending (southwards) satellite passes. Water clouds can interfere with the radars operating below 2 cm in wavelength. The effects of rain can be generally ignored at wavelengths above 4 cm. For longer wavelengths (above 20 cm) - an effect called Faraday rotation caused by the ionosphere - i.e. - free charges (electrons) and the Earth’s magnetic field - can lead to a rotation of the polarization plane. In the presence of Faraday rotation - the data - usually fully polarimetric - should be corrected. The radar systems operate in different bands that uses different wavelengths. The most common frequences/wavelengths (frequency = Speed of Light / wavelength) for environmental applications are X (5 -75-10 -90 GHz) - C-(4 -20-5 -75 GHz) - S-(1 -550-4 -20 GHz) - L-(0 -390-1 -550 GHz) and P-(0 -255-0 -390 GHz) band. The selection of SAR system for acquiring data depends on their application. Longer wavelengths are mainly devoted to communication and navigation purposes. Radars penetrate atmosphere and clouds. For example for forestry - longer wavelengths starting from C- or S-band are preferred.,NONE604,PP2-2-1,Diffraction,Diffraction is defined as interaction of waves with any solid object - not surfaces - and is not to be confused with refraction. More precisely - diffraction describes the phenomena of interaction of waves at an obstacle - such as an aperture - or an opening - such as a hole or an occurring space between two objects. Hence - diffraction is an essential form of scattering - describing ordered scattering at discrete boundaries. The effect of diffraction can be observed through extended interference patterns or simply by the bending of waves. In the field of microwave remote sensing - diffraction has the practical implication that it limits the spatial resolution of a microwave sensor since it acts on the ability of an imaging system to resolve details. This theoretical limit of resolution is called the diffraction limit. This means - the larger the aperture of the observing system compared to its employed wavelength (dependent on the frequency) - the finer the resolution of an imaging system. The diffracted field can be calculated with analytical models - such as the Fraunhofer diffraction approximation in case of far field conditions - where the object is far away and the incident waves are assumed to be plane waves - or the Fresnel diffraction approximation in case of near field conditions - where the waves are spherical.\rOne simple example of diffraction is the diffraction of sound - for example the possibility to hear sounds around corners.,REMOTE SENSING605,PP2-2-2,Scattering and emission,Scattering means the redirection of incident electromagnetic energy by an object. Similar to diffraction - scattering refers to the same physical process - the coherent distortion of an incident wave. However - diffraction as well as reflection can be regarded as essentially forms of scattering. Scattering explicitly describes the “random distortion of waves by elements that are similar in size or less than the wavelength” (Woodhouse - 2005). Thereby - scattering of the incident wave at an object can occur in any directions with varying strength - with the scattering pattern varying with the incident direction. Thus - the term scattering cross section - often denoted by σ - quantifies the effectiveness of a scatterer. In the field of active microwave remote sensing - the backscattering coefficient σ0 is known “as the ratio of the statistically - averaged - scattered power density to the average incident power density” (Fung - 1994). \rIn passive microwave remote sensing - radiometers measure the intensity of radiation emitted by a body - called brightness temperature TB. Since TB is always less than its physical temperature T - emissivity - defined as e = TB / T - is a measure of how strongly a body radiates at a given wavelength. It varies between 0 (metal) to unity (blackbody).\rEmission and scattering are complementary: surfaces that are good scatterers are weak emitters - and vice versa.,REMOTE SENSING606,PP2-2-3,Backscatter saturation,In climate change studies the carbon cycle with its crucial component the terrestrial biosphere is of great importance due to the ability of the biosphere to store environmentally harmful carbon dioxide. Radar sensors - especially SAR - can here provide a useful tool for quantifying and monitoring the biosphere. Hence - the relationship between biomass and radar backscatter responses has been studied in detail in recent decades. Results show that the sensitivity of measured radar backscatter coefficient decreases with increasing amount or density of present biomass. In the so-called saturation region - the radar backscatter saturates at a biomass depending on the employed wavelength. While for higher frequency bands like C-band (3.95-5.8 GHz) - biomass can be measured up to ~50 ton/ha - the amount of measurable biomass increases with decreasing frequency (due to the increasing wavelength) - such that at L-band (1-2.6 GHz) ~ 100 ton/ha and at P-band (0.23-1 GHz) ~200 ton/ha biomass can be measured. Further - the sensitivity of radar to biomass is different for co- or cross-polarized backscatter since the level of saturation depends not only on frequency but also on vegetation (e.g. - height - structure - density - moisture) and soil surface (e.g. - roughness - moisture) parameters. Overall - the saturation of radar backscatter depending on biomass has to be considered when analyzing SAR data.,NONE607,PP2-2-4-1,Radar equation,The radar equation is a measure of the received echo at the sensor. It defines what proportion of the transmitted energy is returned from a target. It is a function of the range between the antenna and the target - the antenna gain and the radar cross-section of the target. Mathematical expression that describes the average received signal level - compered to the additive noise level - in terms of system parameters. Principal parameters include: transmitted power - antenna gain - noise power - and radar range.,NONE608,PP2-2-4-2,Sigma nought,Coefficient sigma or sigma nought represents the average reflectivity of a horizontal material sample - normalized with respect to a unit area on the horizontal ground plane.,NONE609,PP2-2-4-3,Gamma nought,Gamma nought represents the average reflectivity of a horizontal material sample - normalized with respect to the incident area - orthogonal to the incident ray from the radar.,NONE610,PP2-2-4-4,Beta nought (brightness),Radar brightness coefficient represents the reflectivity per unit area in slant range.,NONE611,PP2-2-4,Radar cross-section,Measure of radar reflectivity. The Radar Cross Section (RCS) is expressed in terms of the physical size of an hypothetical uniformly scattering sphere that would give rise to the same level of reflection as that observed from the sample target.,NONE612,PP2-2-5-1,Material constants,A material constant is a physical or chemical property of a substance - which can be expressed in numbers. Giving a precise numerical value of a constant often requires determining the external conditions (e.g. temperature - humidity).  Material constants are factors that influence the interaction of microwaves with the target objects.,NONE613,PP2-2-5-2,Attenuation lenght and penetration depth,The complex part nc of the refraction index n determines how far an electromagnetic wave of wavelength λ can survive crossing a specific medium. The attenuation length la is the distance after that the amplitude of an electromagnetic signal reduces its value by an amount of 1/e. For instance the amplitude of the Electric field E(z) of an electromagnetic wave proceeding along the z direction is decreasing as exp(-z/la) being la=λ/(2𝜋 nc) the attenuation length associated to that specific material (nc) and wavelength λ. This way attenuation length in water can be of hundreds of meters in the visible range and just few microns in the microwaves. The opposite happens over solid land surfaces where optical waves can  penetrate from few microns up to few millimeters (moving from the VIS-NIR to the TIR spectral range) whereas microwaves can reach depths from  hundreds to towsands (as higher are their wavelength) meters allowing the exploration of subsoil and thick coulters of ice.,NONE614,PP2-2-5-3,Soil permittivity,Soil permittivity is a measure of the water content (soil moisture) in the soil and characterized by the metric of the dielectric constant of the soil. Soil moisture influences emission - absorption and propagation of microwave electromagnetic energy. Moisture decreases the ‘emissivity’ of soil - and thereby affects microwave radiation emitted from Earth’s surface. Dry soil has a low dielectric constant and low radar reflectivity. Moist and partially frozen solis have intermediate values. The higher the soil water content - the lower the radar signal penetration into the soil. In situ measurements of soil permittivity are a prerequisite for the calibration and validation of synthetic aperture radar (SAR) soil moisture retrieval algorithms. Soil moisture is a key variable in the hydrologic cycle and is recognized as an Essential Climate Variable (ECV).,NONE615,PP2-2-5-4,Plant permittivity,The complex relative permittivity of a plant is a function of its contained amount of water - solutes (mainly their salinity) and temperature in all plant compartments (including roots). The more water and the higher the salinity are in the plant compartments - the higher is the complex relative permittivity of the plant. The complex relative permittivity of a plant refers to the complex relative dielectric constant of the plant and can be subdivided into complex relative permittivity values for the different plant compartments (roots - stem/stalk - leaves - fruit -...). The complex relative dielectric constant or permittivity parameter has a real and an imaginary part indicating the moisture content and the conductivity (loss) of the plant medium. Models of plant permittivity consist mostly of a free-water and a bound-water part. In particular - plant water is a solute of nutrients and not all water-conducting plant cells are fully filled by water - but also with air. Hence - the estimation of one plant permittivity - especially including several plant parts can be challenging to assess - to understand and to model. To acknowledge this mixture of components - dielectric mixing models containing the single material components are normally developed and applied - representing an effective complex relative permittivity of all plant components. Concerning a vegetation canopy - electromagnetic waves interact with a more or less sparsely vegetation-filled volume unit of air.  A vegetation canopy represents a dielectric mixture of vegetation inclusions (leaves - twigs - branches - stems -…) distributed in a volume of air. Dielectric mixing models of canopies take this vegetation volume fraction into account.,NONE616,PP2-2-5,Dielectric Properties,The dielectric properties of any material can be described by the complex relative dielectric constant (complex relative permittivity) and contains of the real part (moisture content) and the imaginary part (conductivity/loss tangent). For instance: Reflectivity of a smooth surface and the penetration capabilities of microwaves into the material are determined by these two quantities. The complex dielectric constant changes mainly due to variations in water content - salinity - temperature of the material as well as due to the observing wavelength and polarization of the electromagnetic wave. It relates to the interaction of weakly-charged material components - like bi-polar water molecules - with irradiation of electromagnetic waves. The interaction increases with amount and charge of the material components. The complex relative permittivity is also linked to the complex index of refraction as being its square. In order to describe the complex relative permittivity of pure and saline water the single-relaxation Debye and the double-Debye dielectric model can be used. As the movement of bi-polar material components is significantly reduced when the material is put under freezing conditions (temperatures below 0 °C) - the permittivity falls to almost a constant. The real part of the relative permittivity of pure ice is almost constant - when ignoring a weak temperature dependence - and amounts to approx. 3.2. For heterogeneous (mixed) materials consisting of more than one component the equivalent dielectric constant is a function of the permittivity of the single components - their volume fractions - their distribution along space and the polarization and wavelength of the interacting electromagnetic wave.,NONE617,PP2-2-6-1,Vertical roughness component (RMS height),​The standard deviation of the surface height variation (or RMS height) - denoted by s (or hRMS) - describes the statistical variation of a random surface with height z(x). In case of an azimuthally symmetrical surface - the single-scale RMS height of the one dimensional case for discrete profile values is given by (1) - ​where N is the number of samples - and z ̅ the mean surface height (2). ​\rAs roughness depends not only on the soil surface properties but also the wavelength λ of the electromagnetic signal - the roughness parameters are scaled by the wave number k. Hence - the electromagnetic roughness ks for surface roughness parameter s is (2π/λ)*s (3). ​In order to determine if a random surface may be considered as electromagnetically smooth - one common definition is given by the Rayleigh roughness criterion - where s < λ / 8*cosθ - or ks < 0.8 - at incidence angle θ = 0. This criterion has been revised for the microwave region - where the wavelength is usually of the order of the RMS height - called the Fraunhofer roughness criterion - where s < λ / 36*cosθ - or ks < 0.2 - at incidence angle θ = 0. Additionally - surfaces are considered as electromagnetically rough for 1 < ks < 3.,NONE618,PP2-2-6-2,Horizontal roughness component (correlation length),The surface correlation length - denoted by l - is defined as the displacement ξ at which the surface correlation function p(ξ)= 1/e. Thus - l can be seen as the reference length up to which two points of one soil surface can be regarded as statistically independent from each other. If we imagine a perfectly smooth soil surface - l=∞ since every point on that surface correlates with all other points and can therefore be regarded as dependent from each other.\rAs roughness depends not only on the soil surface properties but also the wavelength λ of the electromagnetic signal - the roughness parameters are scaled by the wave number k. Hence - the electromagnetic roughness kl for surface roughness parameter l is kl=(2π/λ)*l.\rExperimental results indicate a weaker influence on the radar backscatter compared to the RMS height s.,NONE619,PP2-2-6-3,Surface correlation function,The surface correlation function p(ξ) determines the degree of correlation between two lateral separated locations of one surface. Thereby - ξ is defined as displacement between two locations - (x - y) and (x' - y') on the surface and given by (1).\rWith increasing separation between two locations on the surface p(ξ) decreases - and at a certain distance - the surface correlation length l - the heights at the two locations are considered statistically uncorrelated.\rThe surface scattering of electromagnetic waves can be simulated with various models. Depending on the observed roughness scale multiple surface scattering models are valid for specific roughness conditions. For example - one of the first surface scattering models for slightly rough surfaces - the small perturbation model (SPM) - deals with roughness scales that are small relative to the wavelength and hence has validity conditions for ks < 0.3 - kl < 3 - and m < 0.3. Since then - various surface scattering models for computing the scattering and emission behavior of natural surfaces in the microwave region have been proposed - such as the Kirchhoff scattering model (KH) - the geometric optics model (GO) - the physical optics model (PO) - or the integral equation model (IEM) - to name the most common used in literature. For simulations of EM scattering at soil surfaces - assumptions of the functional forms of p(ξ) have to be made. The two most common forms for mathematically describing the surface correlation of natural surfaces are the exponential pE(ξ) and the Gaussian pG(ξ) correlation functions - defined by (2) and (3).\rFor some mathematically sophisticated surface scattering models - an x-Power correlation function p(x-Power)(ξ) can be assumed (4) - with x as value between 1 and 2.\rIn literature - rather smooth surfaces are characterized by an exponential surface correlation function - while rather rough surfaces are characterized by a Gaussian surface correlation function.,NONE620,PP2-2-6-4,Surface roughness slope,The root-mean-square (RMS) slope m of a one dimensional height profile for one random surface is given by (1) - with s as the standard deviation of the surface height variation (or RMS height) - and p''(0) as the second derivative of the surface correlation function p(ξ) - evaluated at ξ=0. Since p(ξ) is an even function - p''(0) is a negative quantity.\rFor modeling of electromagntic scattering at soil surfaces - assumptions of the functional forms of p(ξ) have to be made. The most common known forms are the exponential and Gaussian correlation functions. Additionally - some models allow the assumption of a x-Power correlation function - with x as value between 1 and 2. For the varying surface correlation functions - the RMS slope m is given by (2)-(4).\rIn literature - for L-band - the slope m should be lower than 0.3 or 0.4 in case of single scattering and bare soil surfaces with moderate RMS heights.,NONE621,PP2-2-6-5,Single-scale & multi-scale roughness,In reality - one random surface has multiple roughness scales - since the commonly used surface description based on single-scale roughness parameters does not comprise all the properties of natural surfaces relevant for describing wave scattering. Depending on the wavelength λ of the microwave sensor the dimension of the surface roughness parameters s and l correspond to specific roughness scales. \rIn case of multi-scale roughness - the equivalent RMS height is a composite of the individual RMS heights at different roughness scales (1).\rA three-scale surface - as shown in Fig. 1 - for example consists of a small-scale high-spatial frequency variation (c) ‘riding’ on top of the larger scales - the medium-scale perturbation (b) and the large-scale undulation (a).\rAt microwave frequencies - the centimeter scale is the scale of roughness of primary importance - since λ is on the order of centimeters to a few tens of centimeters. For natural surfaces it is very difficult to measure millimeter-scale roughness.,NONE622,PP2-2-6,Surface roughness,Surface roughness defines the geometry between the pedosphere and the atmosphere (soil-air boundary).\rIn the field of microwave remote sensing - surface roughness affects scattering and emission characteristics of natural surfaces. The degree of roughness of a random surface is determined by statistical parameters - measured by the units of wavelength of the observing sensor. The two fundamental surface roughness parameters are the standard deviation of the surface height variation (RMS height) s - with its related surface correlation function p(ξ) - and the horizontal surface correlation length l. Additional - a third roughness parameter - the root-mean-square (RMS) slope m - is important for some surface scattering models to simulate electromagnetic wave scattering of surfaces.\rSurface roughness determines the variation of surface height within an imaged resolution cell. The transition from smooth to rough is qualitative - and is function of both wavelength and incident angle. With decreasing frequency the soil surface appears rather smooth to microwave sensors. This results in the fact - that while one surface appears smooth when sensed at L-band (λ ≈23 cm) - the same surface appears rough when sensed at X-band (λ≈3 cm). Hence - in the field of microwave remote sensing - the ‘effective’ surface roughness parameters are scaled by the wave number k= 2π/λ. Surface roughness can be observed at single or multi-scale.,REMOTE SENSING623,PP2-2-7-1,Stokes Vector,The Stokes vector is a four-element vector containing real-valued polarization combinations and is an alternative form of representing a full (=quad) polarimetric dataset - besides the complex-valued scattering matrix. Stokes vectors can be measured as real quantities and are preferred over the complex-valued Jones vector formalism when a coherent (phase-preserving) measurement system is absent. Stokes vectors can be used to form the 4x4 Mueller matrix for target scattering analyses - mostly used in the field of optics. First component of the Stokes vector is the sum of the co-polar fields and represents the total energy of the wave. Second component is the difference of the co-polar fields. Thrid component is the real part of the cross-correlation of the fields and fourth component is the imaginary part of it. The different polarization states can be represented by the Stokes vector and an O(3) elliptical transformation can be used to change the polarization basis - similar to the Jones vector where the SU(2) elliptical transformation is used.,NONE624,PP2-2-7-2,Scattering matrix,The scattering matrix is a 2x2 square matrix containing four complex-valued polarization measurements (amplitude & phase) forming one full (= quad) polarimetric set of coherent observations. An often recorded set of polarizations is the combination: HH (horizontal receive - horizontal transmit) - HV (horizontal recive - vertical transmit) - VH (vertical receive - horizontal transmit) & VV (vertical receive - vertical transmit). The scattering matrix is fully suficient for describing scattering from coherent targets (dominating the resolution cell) - but not for incoherent tragets (mix of scattering contributions in the resolution cell). For the latter - the coherency and the covariance matrices are the more appropriate descriptions of scattering from incoherent targets.,NONE625,PP2-2-7-3,Covariance/Coherency matrices,The covariance and coherence matrix are two 4x4 square matrices - which can be built out of the scattering matrix by a lexicographic and a Pauli target scattering vector. They are an alternative representation of a full polarimetric dataset allowing the analysis of incoherent targets (more than one dominant scatterer in the resolution cell)  and the phenomenon of depolarisation (transformation of incoming fully polarised wave into a partially polarised wave by creating a variety of different types of polarizations during media interaction). These matrices can be converted into each other without loss of information (by unitary transformations) - but not turned back into the scattering matrix due to averaging operations during formation of coherency or covariance matrices.,NONE626,PP2-2-7-4,Polarimetric decomposition techniques,Polarimetric decomposition techniques allow signal unmixing by polarimetry in order to separate different scattering contribution within one resolution cell - e.g. from soil & vegetation or snow - ice & bedrock. They can be either applied for the scattering matrix (coherent form - one dominant scatterer in the resolution cel) or for the covariance/coherency matrix (incoherent form - more than one dominant scatterer in the resolution cell). Decomposition techniques can be model- (physics) or eigen- (mathematics)-based. The eigen-based decomposition allows to diagonalize the coherency or covariance matrix in a diagonal eigenvalue matrix and a matrix of column eigenvectors. From eigenvalues and eigenvectors the polarimetric entropy - the scattering alpha angle and the polarimetric anisotropy. The polarimetric entropy is a matric for the degree of depolarization of the scattering event. The scattering alpha angle is an intrinsic scattering mechanism indicator. The polarimetric anisotropy informs about secondary scattering mechanism in evironments with high entropy. If the anisotropy is high only one secondary scattering mechanism is present - if it is low - more than one will occur.,NONE627,PP2-2-7-5,Orientation polarisation of media,All bi- or multi-polar (non-inert) media have the tendency to orient themselves in 3D-space if an external non-ionizing electro-magnetic field is excited on them. This orientation polarization is caused by negatively and positively charged areas within the media - for instance due to charges of the different molecules and atoms building up the media - under the premise that the media is able to rotate (partly) freely and is not completely fixed. Molecules of liquid water are a prime example. Here the two positively charged hydrogen atoms are oriented in a 105-degree configuration to the negatively charged oxygen atom - forming a slightly charged bi-polar medium that orients itself under electromagnetic radiation treatment - especially at the frequency range of microwaves and millimeter-waves.,NONE628,PP2-2-7-6,Polarimetric coherences,Polarimetric coherences are complex-valued polarimetric correlation coefficients assessing the redundance between different polarimetric observations informing about their divergence in information. They can be formed among mutual polarimetric observations showing their degree of correlation. The polarimetric coherence consists of a magnitude - ranging between zero (no correlation) and one (identical) - and a phase information - running from -180° to 180°. Typically polarimetric coherences are calculated between the co-polarimetric (HH - VV) channes - as well as the cross-polarimetric channels (HV - VH). The latter polarimetric coherence assesses the system noise inherent in the recorded polarimetric data - if a monostatic systems (transmitting and receiving sensor on the same sensing platform) is used for acquisition.,NONE629,PP2-2-7-7,Polarisation ellipse / Jones vector formalism,The polarisation ellipse and the Jones vector formalism are the geometrical (three real-valued angles) and algebraic (amplitude & phase) formalisms to describe polarisation states of an electromagnetic wave. The ellipse has an orientation - an ellipticity and absolute phase angle. The three angles are integrated in one mathematical ellipse formulation that can represent linear - elliptic and circular polarisation states. The Jones vector formalism is an algebraic formulation allowing all calculus available in linear algebra.  Both representations (polarisation ellipse & Jones vector) can be converted into each other seemlessly with a simple elliptical basis (special unitary SU(2)) transformation.,NONE630,PP2-2-7-8,Polarisation synthesis,The concept of polarisation synthesis is based on the mathematical fact that a set of polarimetric measurements in one basis - e.g. H -V - can be converted into any other polarimetric basis - by a mathematical transformation. A basis set is a set of four polarisations. Each set is orthogonal - like LC (left-circular) - RC (right-circular). The striking point is that only one set of polarimetric measurements in one basis needs to be recorded and the transformation in other polarimetric bases is done in a post processing step afterwards. There is no need to measure all bases - which is quite complicated in terms of engineering for elliptical and circular polarisation states.,NONE631,PP2-2-7,Polarimetry,Polarimetry is the technique to evalute the physical phenomenon of polarisation including the measurement - the processing and the interpretation of the polarisation state of an electromagnetic wave. Polarization states are described by the scattering elipse and the Jones Vector formalism. Especially the polarization states after interaction with the media under investigation are mostly investigated to estimate media properties and states. The mostly observed fully polarimetric observation basis is H -V up to now with the single observations: HH HV - VH - VV. The concept of polarization synthesis allows to acquire fully polarimetric observations in one basis (e.g. H -V) and transform them into any other orthgonal basis (e.g. left - right circular) by a mathematical transformation in post processing. Polarimetric States are stored in different mathematical formats: Scattering matrix - polarimetric coherences  - Stokes vector - Pauli-vector - lexicographic vector - coherency and covariance matrices. These mathematical representations can be decomposed according to the contained elementary scattering mechanisms in the recorded signal. The so-called polarimetric decomposition technique allow signal unmixing for differnt scattering components (e.g. from soil & vegetation). The techniques range from mathematics-based until physics-based concepts and are developed since decades starting with Huynen in 1970.,NONE632,PP2-2,Interaction of microwaves with matter,A number of interactions are possible when electromagnetic energy encounters matter - whether solid - liquid or gas. In Earth Observation there are two main interactions: atmospheric and with target. Atmospheric interaction: In radar remote sensing - atmospheric interactions are limited due to the long wavelengths compared to the size of the atmospheric particles. The fact that microwaves interact with object at least as big as the wavelength is one of the greatest advantages of microwave remote sensing - since at larger wavelengths atmospheric particles are almost transparent to the signal and microwave sensors are independent from the time of day (day or night) and weather conditions. Water clouds can interfere with the radars operating below 2 cm in wavelength. The effects of rain can be generally ignored at wavelengths above 4 cm. For longer wavelengths (above 20 cm) - an effect called Faraday rotation caused by the ionosphere - i.e. - free charges (electrons) and the Earth’s magnetic field - can lead to a rotation of the polarization plane. Target interaction: The radar interaction with the object is a result of both radar system parameters (frequency - polarization - acquisition geometry) and the physical properties of the object (dielectric constant - i.e. - water content; geometrical properties - i.e. - the roughness - shape and orientation of the scatterer). Overall - various types of interactions can be distinguished – scattering - diffraction - and reflection – all describing the same process of wave interaction but at different scales.,REMOTE SENSING633,PP2-3-1-1,Antenna gain,The goal of an radar antenna is to direct and receive the transmitted and backscattered signal in a specific angular direction. The antenna gain describes the directional sensitivity of the antenna. It is a dimensionless quantity that is constant for a specific antenna.,NONE634,PP2-3-1-2,Antenna pattern,The antenna radiation pattern shows the direction in which the antenna transmits and receives the energy in space - as well as the strength of this radiation. It is a function of angles and consists of different lobes - in which the signal is directed and received. There are two principal representation of the antenna patterns: field and power patterns - which are a function of the electric and magnetic fields of the energy being radiated.,NONE635,PP2-3-1,Radar antennas and antenna calibration,Antenna is a device that radiates electromagnetic energy and collects it during reception.,NONE636,PP2-3-10-2,Radargrammetric equation,The radargrammetric equation follows a similar principle as the stereoscopic equation - except that it uses the radar geometry. The radargrammetric observation equation allows the retrieval of 3D information about a target - based on the determination of the sensor-object stereo model. It estimates the coordinates the intersection of the two radar rays coming from the two different sensor positions with different look angles - using the coordinates of the satellites position and satellite velocity. The radargrammetric equation can be adapted in order to retrieve 3D information in layover areas (e.g. urban areas).,NONE637,PP2-3-10,Radargrammetry (same-side and opposite-side),Radargrammetry is the technique for extracting three-dimensional information from radar images. It applies photogrammetric principles to synthetic aperture radar (SAR) images. By viewing an object from different positions separated by a baseline - the appeared object position will vary slightly (denoted parallax). The disparities for each position on the object are related to its x-y-z coordinates. In radargrammetry - such disparities are computed for an entire image. The result is the terrain elevation from the measured parallaxes between two (or more) images - acquired at different angles. Radargrammetry requires at least two SAR images acquired from different positions - normally across-track due to the configuration of a side-looking SAR. Same-side stereo-pairs with intersection angles in the range of about 10 – 20° have been a feasible compromise between reasonable geometric disparities and the accuracy of estimated heights. In general - the disparities can be estimated with higher accuracy as the angle of intersection increases (as the stereo exaggeration factor increases). However - the same points must be recognized in all images - and it is hence required that the images are as similar as possible. This improves the image matching and it is best achieved with small intersection angles - which furthermore decreases radiometric differences. \rA general procedure for generating an elevation model from stereo-pairs is applicable for radargrammetry when optical stereo images are replaced with the backscatter intensity of SAR images. One image is selected as reference and the other(s) is coarsely registered to the reference - e.g. - by using the attached meta-data. The same points are then located in both images using image matching. A common matching criterion is the cross correlation coefficient. Then - spatial point intersections are computed - which is the least square approach to find the intersection points of SAR range circles as defined from the matched image pixels. The computed intersections result in a point cloud that finally is interpolated to a consistent elevation raster. The entire process is extensive and computationally expensive - and normally a dedicated software is required. \rRadargrammetry with images acquired from opposite sides have been little investigated - and was first limited to stereoscopic viewing. Some opposite-side research was later presented with limited outcomes under certain conditions. Most applications today will not consider opposite-side radargrammetry - since the alternatives are usually better. Same-side radargrammetry performs better than opposite-side - while interferometric SAR that is based on phase differences - may be even more accurate. One advantage of radargrammetry is however - that it remains less affected by atmospheric disturbances compared to interferometric SAR - because it is using the amplitude images.,NONE638,PP2-3-11-1,Differential Synthetic Aperture Radar Interferometry (DInSAR),Differential Synthetic Aperture Radar Interferometry (DInSAR) aims the determination of deformation of the Earth’s surface that happened between two or more complex-valued SAR acquisitions.\rThe phase of an interferogram issued from the complex multiplication of a SAR image with the complex conjugate of a second SAR image contains five distinct components - or layers of information: (1) Two phase components arise from the geometrical baseline (slightly different position of both sensor positions): (1a) a topographical information representing the surface relief - (1b)  “flat earth” pattern coming from the orbital distance of both sensor positions.\r(2) Two phase components result of the temporal baseline (time between both acquisitions): (2a) a deformation component - representing a possible displacement of the Earth’s surface between both acquisitions - (2b) an atmospheric component coming from different atmospheric conditions between both acquisitions. (3) A phase component corresponding to intrinsic sensor noise \r\rBoth parameters related to the temporal baseline can be retrieved using DInSAR on repeat-pass acquisitions. DInSAR cannot be used with single-pass interferometry (e.g. both acquisitions acquired at the same time).\rThe deformation component of the interferometric phase corresponds to the modification of the phase of the second SAR image compared to the first due to an additional range difference between the sensor position and the Earth’s surface that is induced by the motion of the Earth’s surface towards or away from the initial sensor position.\rUsing DInSAR - the phase components related to the geometrical baseline can be eliminated from the interferogram using an existing DEM and orbit information - or an additional interferogram showing no deformation. After DInSAR processing - neglecting the remaining sensor noise - only the deformation and atmospheric components remain. The resulting deformation image is called differential and is characterized by color bands - or fringes - from whom the amount of the displacement can be retrieved. \rDInSAR can be used for mapping displacements and deformations due to earthquakes - landslides - or other geophysical processes inducing deformation of the Earth’s surface.\rUsing only one differential interferogram - mainly sudden and large scale changes between two acquisition can be mapped and quantified. However - the atmospheric phase component remains and may induce interpretation errors if it is not possible to eliminate it through e.g. precise weather models. Techniques of differential interferogram stacking (e.g. Persistent Scatterer Interferometry and Small-Baseline Subset) have been developed for long-term deformation monitoring which allow to filter the atmospheric phase component out.,NONE639,PP2-3-11-2,Permanent Scatterer Interferometry (PSI),The Permanent or Persistent Scatterer (PS) approach allows the estimation of deformation time-series related to point-wise - high coherent scatterers on the ground based on processing long sequences of SAR data.\rPersistent Scatterer Interferometry (PSI -sometimes also called Permanent Scatterer Interferometry) is a particular DInSAR technique. It exploits multiple SAR images acquired over a specific area in order to retrieve the deformation phase component over time. In general - a minimum number of 15 SAR acquisitions is needed for PSI processing. Due to the large number of necessary acquisitions - the deformation component of the interferometric phase observations can be estimated very precisely (in the order of a few mm/yr) and other phase contributions such as atmospheric disturbances and topographic height differences can be better estimated and removed.\rPSI rely on so called Persistent Scatterer that are targets showing coherent phase behavior in time. Such targets are usually found on man-made structures such as buildings or bridges - or very stable features such as rocks. PSI is a technique that is therefore mainly used over urban or semi-urban terrain. Usually - PSs are selected based on their amplitude and phase power spectrum stability over time.\rThe main outcomes of a PSI analysis are a deformation velocity map and the displacement time-series of the single point targets - or PSs. The velocity map represents the deformation rate of the detected PSs in Line-of-Sight of the sensor - generally in mm/yr. Usually - subsidence - e.g. target moving away from the sensor - is represented in red - stable PSs in green and uplift - e.g. PSs moving toward the sensor in blue. The displacement time-series show for each PS the amount of the deformation - usually in mm - over the whole period of observation. Different phase model can be defined in order to retrieve the best possible estimate of the deformation - considering also seasonal displacements or breakpoints in the time-series.\rPerforming PSI analysis in both ascending and descending directions allows the fusion of the results in order to retrieve vertical and East-West component of the deformation. North-South deformation components cannot be retrieved due to the orbit configuration of the SAR satellites.\rPSI finds use in a large range of thematic applications related to subsidence and long-term change monitoring - such as infrastructure monitoring - groundwater reservoir monitoring - monitoring of mining areas - landslide inventory and monitoring - as well as volcanology.,NONE640,PP2-3-11-3,Along-Track Interferometry,Along-track InSAR (AT-InSAR) is a special mode of interferometric SAR (InSAR) where the individual SAR images have been acquired from the same flight track. With virtually identical geometric configuration of the individual SAR images - the measured phase difference is dominated by temporal changes occurring between the acquisitions. Consequently - AT-InSAR can be used to measure the displacement and/or radial velocity of targets on the ground - with the temporal offset between the acquisitions determining the time scale of the measurements. AT-InSAR can be implemented using one or more SAR sensors - in both single-pass and repeat-pass configurations - accommodating various needs. Using at least two sensors in a single-pass configuration allows the measurement of relatively high velocities - e.g. - for vehicles and ocean waves. Conversely - using at least one sensor in a repeat-pass configuration allows the measurement of low velocities or displacements - e.g. - for glaciers and due to volcanoes - earthquakes - subsidence - and landslides.,NONE641,PP2-3-11-4,Across-Track Interferometry,Across-track InSAR (XT-InSAR) is a special mode of interferometric SAR (InSAR) - where the individual SAR images have been acquired from slightly different look directions. The measured phase difference contains information about the elevation of the targets on the ground - but it can also be affected by temporal changes between the individual SAR images. XT-InSAR can be implemented using one or more SAR systems in both single-pass and repeat-pass configurations. To mitigate temporal change between acquisitions - the XT-InSAR configuration is selected based on the intended application and frequency used by the system. If a single SAR sensor is used in the repeat-pass mode - temporal stability can be achieved either by a selecting a lower frequency and focussing on the larger - more stable targets (e.g. - P-band - 435 MHz InSAR in forests) or by selecting a higher frequency and focussing on already stable environments (e.g. - X-band - 9.65 GHz XT-InSAR in urban environments). Using two or more SAR sensors in a single-pass - tandem configuration - it is possible to measure elevation of temporally instable targets using higher frequencies - as demonstrated by the SRTM and TanDEM-X systems over vegetated areas and ocean.\rReferences: bamler/hartl - one on SRTM or TDM for DEM - one on BIOMASS for forestry - one on Sentinel-1 for urban areas - one on TDM on vegetation,NONE642,PP2-3-11-5,Small Baseline Subset,Small Baseline Subset (SBAS) is a well-known technique of differential synthetic aperture radar (SAR) interferometry for the generation of surface deformation time-series by processing large sequences of SAR data acquired over the same region on Earth. \rThe method requires the preliminary generation of pairs of SAR images collected by slightly different orbital positions at different acquisition times. The phase difference of the interferometric SAR data pairs is extracted. The two-dimensional phase maps contains different contributions - but principally a component due to the terrain height of the observed area. The DInSAR technique relies on the estimation of the deformation of the terrain between the two interfering SAR images (i.e. - the so-called master and slave images). To achieve this task - the phase contribution related to the terrain height is simulated and subtracted to the interferometric master/slave phase difference. The obtained differential SAR interferometric phase contains a direct information on the occurred deformation. Once a sequence of interferometric SAR data pairs is selected - the SBAS technique allows generating the time-series of the deformation of the terrain. The processing steps are essentially: i) the extraction of the full phase of the DInSAR interferograms - i.e. - the phase unwrapping steps of the DInSAR interferograms - ii) the inversion of the sequence of unwrapped DInSAR phases - iii) the geocoding of the deformation maps from radar coordinates to geographical coordinates.,NONE643,PP2-3-11,Principles of Synthetic Aperture Radar Interferometry (InSAR),Synthetic aperture radar (SAR) interferometry - or simply InSAR - is a remote sensing technique utilising the phase difference between two or more complex-valued SAR images. Most modern SAR systems are capable of measuring both the intensity and the phase of the reflected signal - where the latter carries information about the distance travelled by the signal. Consequently - the different of phase information of two successive SAR images over a specific area contains a distance information. \r\rThe phase difference measured between two SAR images is called the interferometric phase. The interferometric phase image is an interferogram. The interferometric phase is a function of the geometry and timing of the individual SAR acquisitions. Different geometric and temporal configurations enable different applications. \r\rIf the SAR acquisitions are made from different angles and without significant temporal change of the scene - InSAR can be used to create digital elevation models (DEMs) of the Earth - as demonstrated by the NASA/JPL Shuttle Radar Topography Mission (SRTM). This configuration is called across-track interferometry. If the individual SAR acquisitions are made at different times in the same geometric configuration - i.e. in an along-track or differential interferometric configuration - then InSAR can be used to measure radial velocity of targets and to assess displacements caused by - e.g. - volcanoes and earthquakes. The variation of the temporal baseline allows determining velocities ranging from several meters per second to a few millimeters per year. While standard differential interferometry can be used to retrieve changes that happened between two SAR acquisitions - differential interferometric stacking techniques - such as Persistent Scatterer Interferometry (PSI) and Small Baseline Subset (SBAS) - are used to monitor deformation over a longer period of time by stacking multiple differential interferograms and filtering out the atmospheric phase contribution in order to retrieve very accurate deformation of the ground and its infrastructures.,REMOTE SENSING644,PP2-3-12,Synthetic Aperture Radar (SAR) tomography,Synthetic Aperture Radar (SAR) tomography uses the principle of the azimuth synthetic aperture in the elevation direction. Instead of using different positions of the radar sensor along the flight path in order to increase the aperture length - SAR tomography uses multiple passes of the radar sensor over the same area at different elevation positions - i.e. orthogonal to the azimuth-range plane - on different orbits.  Similar to the synthetic aperture in azimuth direction - a larger aperture in cross-range elevation direction allows increasing the resolution in the elevation direction. Therefore - the echoes are focused in the whole 3D space (azimuth - range and elevation) - and scattering contributions can be separated at different heights - even if they are situated in the same azimuth-range cell.\rSAR tomography exploits therefore these multiple passes of the radar sensor at different orbit positions (orbits heights) in order to retrieve 3D information about volumetric targets - where the 2D SAR signals often overlaps due to the typical side-looking geometry. \rThe result of tomographic processing is a tomogram - i.e. it is a hologram of a specific area of interest - usually represented as a tomographic profile along a particular direction. Using polarimetric data - the different scattering mechanisms happening at different heights can be represented in the profile - allowing a full understanding of the volumetric information and backscattering processes.\rUnlike the azimuthal aperture - the tomographic aperture is achieved by repeat-pass acquisitions - the antenna having to come back over the area. An important parameter is therefore the target coherence - that may decrease by longer repeat-pass cycles. In general - a 1-4 day revisit cycle is preferred for tomographic applications.\rSAR tomography finds applications in the imaging and monitoring of cities and single buildings - as well as in height and biomass estimation of forest stands. The use of longer wavelength that guaranty the penetration into canopy volumes allows a better retrieval of the complete forest structure and its undergrowth.,NONE645,PP2-3-13,Active-Passive microwave imaging,Historically imaging in the microwave frequency domain was done either using passive imaging techniques (with solely recording capacities of the sensor) or using active imaging techniques (with transmitting and recording capacities of the sensor). Both imaging modi were developed in parallel for a long time in electrical engineering of microwave sensors for space-borne missions - but are combined in more recently launched missions.\rWith the concept of active and passive microwave imaging - both techniques are fused to record electromagnetic waves in an active (sending & receiving) and a passive (only receiving) mode either simultaneously on one carrier platform or with negligible time lag on different platforms.\rThe active sensor is normally a Real Aperture Radar (RAR - scatterometer) or Synthetic Aperture Radar (SAR) - while the passive sensor is a radiometer or synthetic aperture radiometer. Both acquisition modes can be operated on a single platform or on different platforms depending on monolithic or distributed platform systems. The benefit of fusing both modi is in the higher spatial resolution of the active imaging modes combined with the higher sensitivity of the passive modes for intrinsic (non-structural) media properities - like permittivity or salinity.\rSatellite missions with active-passive imaging capabilities are the NASA missions AQUARIUS (operation started in 2011 terminated in 2015)  and SMAP (operation started in April 2015 and ceased for active sensor in July 2015). Currently (2021) - no dedicated active-passive microwave satellite mission is operating in orbit.,NONE646,PP2-3-2,Coherent and active systems,Systems measuring both amplitude and phase of the incident electromagnetic radiation.,NONE647,PP2-3-3,Passive microwave imaging,This acquisition mode records only the incoming electromagnetic radiation emitted from the Earth. Radiometer instruments conduct passive microwave imaging. The energy budget of emitted radiation (from Earth) is significantly smaller than from instrument-generated - transmitted electromagnetic waves - used in the active microwave imaging mode. Hence - the signal to noise ratio is significantly worse for passive microwave imaging forcing a longer intergration time for robust signal recording. This results in a coarse spatial resolution of radiometer images (in the order of kilometers).,NONE648,PP2-3-5,Real Aperture Radar (RAR),There are two types of imaging radar apertures: real (usually called RAR or SLAR for side-looking airborne radar or SLR for side-looking radar) and synthetic aperture radar (SAR). The SLAR imaging system uses a long antenna mounted on a platform. The synthetic aperture is used in space remote sensing applications. RAR is a radar system where the antenna beamwidth equals to the physical length of the antenna. It operates in a side-looking configuration - left or right with reference to the flight direction. It is an active - all-weather - day/night remote sensor onboar an airborne platform. Both Real Aperture and Synthetic Aperture Radar are side-looking systems having antennas aimed to the right or left of the flight path. The length of the antenna together with wavelenght determines the resolution in the azimuth direction - i.e. it is proportional to the distance to the object and inversely proportional to the length of the radar antenna.,REMOTE SENSING649,PP2-3-6,Principles of Synthetic Aperture Radar (SAR),In contrary to a real aperture - a synthetic aperture results from an aperture “synthesis”. Synthetic aperture were built in order to overcome the limitation of real aperture and therefore enhance the resolution in azimuth direction. It uses the subsequent positions of a real aperture sensor during its forward motion along the azimuth direction to create a synthetic longer antenna. Via the analysis of the Doppler shift induced by the different echoes of the illuminated objects in the different positions of the real aperture - the azimuth resolution can be improved.,NONE650,PP2-3-7-1,Azimuth direction,In navigation - the azimuth corresponds to an angle measured from a north reference or a meridian - usually in clockwise direction. In SAR terminology - the azimuth direction corresponds to the direction in which the radar platform moves. The azimuth direction is also called along-track direction and is parallel to the flight path of the radar instrument. In a SAR image - the azimuth position of an object corresponds to its relative position in the field of view of the antenna following the radar’s line of flight. The azimuth direction is perpendicular to the range direction - which corresponds to the look direction of the radar antenna. The azimuth plays an important role in the definition of the azimuth resolution of a SAR sensor. Contrary to the range resolution - the azimuth resolution is independent of the distance between sensor and illuminated area and is constant. The azimuth resolution of a radar system corresponds to the beam width of the antenna on the ground - but can be improved using multiple successive real aperture acquisitions in order to form a longer - synthetic - aperture. This implies that an object on the ground is illuminated for a longer time and from different platform positions along the azimuth direction - inducing a Doppler frequency shift at the target. The use of specific synthetic aperture acquisition modes that steer the antenna along the azimuth direction - such as Spotlight mode - improve additionally the resolution in azimuth direction.,NONE651,PP2-3-7-2,Range direction,The range direction corresponds to the direction perpendicular to the flight direction of a radar system. It is also called across-track direction. One distinguishes between slant range - i.e. range in a radar geometry - and ground range - i.e. range projected onto the Earth's surface - and between near and far range (situated farther away from the sensor and showing shallower looking angle than in near range due to viewing geometry).,NONE652,PP2-3-7-3,Incidence Angle,The incidence angle is the angle between the incident radar beam on a surface and the normal to a reference surface. Generally - it is distinguished between the local incidence angle and the incidence angle to the ellipsoid. The local incidence angle considers the normal to the surface at target location - i.e. it considers the local topography. The incidence angle to the ellipsoid corresponds to the angle between the incident radar beam and the normal to the local ellipsoid - regardless of the local slope and terrain. \r\rFor a flat surface and neglecting the Earth’s curvature - the incidence angle corresponds to the angle between the incident radar beam and the vertical - and it equals the look angle of the sensor - which characterizes the angle between the nadir view and the radar beam. Considering a flat surface - the incidence angle varies continuously within a SAR scene: it increases from near to far range. Depending on the considered sensor and acquisition modes - variations of the incidence angle up to 20° can be observed between near and far range.\r\rThe incidence angle has an influence on the radar backscatter intensity. Considering a surface with diffuse reflection - increasing incidence angles lead to decreasing backscatter intensities. This effect is less pronounced for rough than for smooth surfaces. A change in incidence angle may also induce a change in the occurring backscattering mechanisms or geometric distortions of the image. For example - for high incidence angles - terrain distortion due to the side-looking geometry is reduced. Due to the high dependency of the radar backscatter from the incidence angle - the choice of the optimal configuration should happen depending on the application. For example - whereas low incidence angles are more sensitive to biomass in forestry applications - higher incidence angle are preferred for distinguishing different forest types due to their structural characteristics.,NONE653,PP2-3-7-4,Antenna footprint,The beam sent out by the radar antenna (SLAR for side-looking airborne radar or SLR for side-looking radar) illuminates an area on the targeted object. The footprint of an antenna is traditionally defined to be the area on the surface within the field of view subtended by the beamwidth of the antenna gain pattern.,NONE654,PP2-3-7-5,Synthetic Aperture Radar (SAR) spatial resolution,The spatial resolution of a synthetic aperture radar (SAR) system is the maximal distance between two targets - which are indistinguishable in the SAR image. SAR spatial resolution is determined individually in the two principal SAR image directions: ground range and azimuth (along-track).  Ground range resolution for a SAR system is derived from slant range (across-track) resolution - by projecting it onto the ground surface using the incident angle - i.e. - the angle between the line-of-sight and the ground surface normal. It is thus range-dependent - with finer resolution available in far range. Assuming adequate signal processing - slant range resolution of a SAR system is proportional to the speed of light and inversely proportional to the system bandwidth - i.e. - the width of the used frequency interval. This caused by the fact that each individual frequency provides an independent measurement of the slant range - so a larger bandwidth implies more independent measurements contributing to the final slant range estimate. Similar principles apply to the azimuth direction. Assuming adequate signal processing - the SAR azimuth resolution is proportional to the along-track velocity of the SAR sensor and inversely proportional to the pulse repetition frequency (PRF) of the system. A lower interval between the consecutive pulses (higher PRF) results in better azimuth resolution due to faster sampling - but at the cost of range ambiguities occurring when echoes from one pulse are recorded after the next pulse has been transmitted.,NONE655,PP2-3-7,Synthetic Aperture Radar (SAR) geometric configuration,The Synthetic Aperture Radar (SAR) sensor is usually mounted on an aircraft or satellite. The instrument altitude above a reference surface stays constant over time - a condition that is easier to achieve for satellite sensors that stay on the same orbit than for aircrafts that are subject to atmospheric conditions. The sensor moves on a straight flight path - which is called the azimuth direction. It corresponds to the flight direction.\rSAR systems acquire information in oblique view - the antenna pointing sideways down to the ground. Most satellite systems use an antenna looking to the right side of the instrument. The ground area illuminated by the radar beam is called antenna footprint. As the sensor moves along the azimuth direction (along-track) - the continuous strip of the ground area represented by the successive antenna footprints is called swath. \rThe looking direction of the SAR antenna is called range direction. It is often perpendicular to the azimuth direction (i.e. across-track) - but can also present slightly differences depending on the acquisition mode. The angle between the nadir view and the range direction is called incidence angle.\rThe original SAR image is displayed in what is called slant-range geometry - i.e. - it is based on the actual distance from the radar to each of the respective features in the scene. In the slant range direction - each point target’s backscatter is represented as a function of the time delay between the transmission of the electromagnetic pulse and its reception back at the sensor. This range depending representation induces geometric distortions in the SAR image. One distinguishes between near and far range: targets situated in near range are closer to the nadir direction and closer to the sensor than targets situated in far range. The image representation of targets is also more compressed in near range than in far range.\rThe slant-range representation can be converted in ground range representation - by projecting the image features orthogonally to a ground reference - allowing a proper planimetric position of the targets relative to one another.\rThis acquisition geometry allows the distinct mapping of scatterers corresponding to their respective distance to the sensor. It causes also geometric distortions in the radar image - i.e. - relief displacement (foreshortening and layover) and shadow.,NONE656,PP2-3-8-2,Local Incidence Angle,The local incidence angle is the angle between the incident radar wave and the normal to the scattering surface at target location. In case of a flat terrain - the local incidence angle equals the incidence angle. For a terrain with local slope - the local incidence angle differs from the incidence angle (for slopes facing towards the sensor - it is smaller than the incidence angle).,NONE657,PP2-3-8-3,Foreshortening,Foreshortening is a geometric distortion occurring in the SAR image due the side-looking geometry of imaging radar sensors. It occurs principally in SAR images of mountainous areas - on slopes oriented towards the sensor. These slopes appear in the radar image as if being compressed. Due to the side looking geometry and the mapping of the SAR image based on range and time measurement - the distance in the SAR image between two points situated on a slope facing the sensor appears smaller than it is in the reality and than the same distance between two points situated in flat area. This results in a compression of the radiometric information of the slope. The resulting foreshortening area is brighter in the SAR image than its surroundings - as it compresses in a few pixels the backscatter information of the whole slope. \r\rForeshortening occurs for slopes whose inclination is smaller than the look angle of the radar antenna. Due to the variation of the look angle in the SAR image - the foreshortening is more pronounced in near range than in far range. Foreshortening is therefore greater for small incidence angles. The extreme case of foreshortening happens when the slope inclination is equal to the look angle: in this case - the whole slope is mapped in one pixel of the SAR image - which results in a very bright line. When the slope inclination becomes higher than the look angle - layover occurs.,NONE658,PP2-3-8-4,Layover,Layover is a geometric distortion occurring in the SAR image due the side-looking geometry of imaging radar sensors. It occurs principally in SAR images of mountainous areas - on steep slopes oriented towards the sensor. These slopes appear in the radar image as if being flipped over. Due to the side looking geometry and the mapping of the SAR image based on range and time measurement - the summit of a mountain is closer to the sensor that the foot of that same mountain - on the side facing the sensor. The signal from the top comes back to the sensor before the signal from the foot and is therefore mapped in nearer range than the foot of the mountain. Making an analogy to sound waves - an echo from the top of the mountain will arrive sooner at the sensor than an echo from the bottom of the mountain. Due to this “leaning over” effect - the sensor facing slope signal usually overlaps with ground signal - and a “ghost” effect appears as both signals overlap. The resulting layover area is usually very bright in the SAR image - as it superimposes backscatter signals from the slope of the mountains and the ground before it. When considering SAR images of urban areas - even up to three signals may overlap in the layover area: ground - building façade and (part of the) roof area.\r\rLayover occurs for slopes whose inclination is larger than the look angle of the radar antenna. Due to the variation of the look angle in the SAR image - layover occurs more often in near range than in far range. Layover is therefore greater for small incidence angles. It represents the extreme case of foreshortening - when the slope inclination becomes higher than the look angle.,NONE659,PP2-3-8-5,Shadow,Radar shadow is a geometric distortion occurring in the SAR image due the side-looking geometry of imaging radar sensors. It occurs principally in SAR images of mountainous areas - on steep slopes oriented away from the sensor. In optical imagery - a shadow area is an area characterized by less sun illumination whose reflection is therefore weaker. In SAR imagery - shadow areas receive no signal. It occurs for example at the backside of mountains or buildings. The areas facing away from the sensor are not illuminated by the SAR sensor - as they are “hidden” from it. Also - ground area situated behind high object with respect to the sensor position are not illuminated and are situated in the radar shadow. They receive no signal information and send no information back to the sensor.  Those areas are therefore very dark in SAR images. The size of the shadow area in range direction corresponds to the time delay between the last echo from the top of the mountain and the first echo of the far edge of the shadow region - where the area is not hidden from the sensor anymore.\r\rRadar shadow occurs when the slope inclination of the slope facing away from the sensor is larger than 90° minus the antenna look angle. As for the other geometric effects - the size of a shadow area for the same object depends on its situation in the image. But - unlike as for foreshortening and layover - shadow is more pronounced in far range than in near range - i.e. large incidence angles produce more shadow.\r\rA SAR image may show a return signal in a shadow area: this is principally due to internal sensor noise and does not correspond to any target return signal.,NONE660,PP2-3-8,Terrain reflectivity and geometric distortions,Synthetic Aperture Radar (SAR) backscatter is determined both by dieletric and geometric properties of the illuminated target. While the water content of the target plays an important role - its surface roughness determines the scattering mechanisms and the amount of incoming signal sent back to the sensor.\rDepending on its characteristics but also on the considered wavelength - a surface appears more or less rough. On smooth surfaces - specular reflection occurs - meaning that most of the incoming signal will be reflected away from the sensor. For rough surfaces - diffuse reflection occurs - meaning that part of the signal is scattered back to the sensor - the amount of it depending on different surface roughness parameters. \rDepending of the observed target and surface - single or multiple scattering mechanisms occur. A particularly important scattering mechanism is the double bounce - which occurs generally at two perpendicular surfaces (e.g. ground and building wall). Through two successive specular reflections - the whole signal comes  back to the sensor.\rDue to the side-looking geometry of SAR systems and the range dependent image representation - specific additional effects occur and affect the backscatter intensity. Whereas a flat terrain only appears more compressed in near range and more stretched in far range - larger geometric distortions appear for terrain with more topography (e.g. mountains) or high objects (e.g. trees - buildings). This relief displacement is caused by the target’s elevation. A high elevated object is closer to the sensor than the ground below it. Due to the image formation in range direction depending on the distance between sensor and targets - its signal comes back sooner to the sensor and it is represented in the SAR image in nearer range than the ground below it. High objects in the SAR image are therefore displaced horizontally toward the radar antenna. This horizontal displacements contrast with the radial displacement observed in optical imagery due to central projection. Furthermore - such objects hide part of the ground below them - which do not receive any signal and cannot scatter information back. Three particular geometric distortions exist: foreshortening - layover and shadows.\rDepending on the illuminated target - different scattering mechanisms occur in combination with geometric distortions - which makes the interpretation of the SAR image challenging. A good example are buildings - where layover - shadow and single- and double-bounce occur.,NONE661,PP2-3-9,Speckle Formation,A typical “salt-and-pepper” noise-like physical phenomenon that is not a noise but a deterministic property of SAR imagery is the so called speckle. It appears when a resolution cell of a SAR system contains more than one scatterer. In that case - the total scattering from the resolution cell is a coherent sum of the backscatter originating from the different scatterers. In order to reduce this effect - speckle reduction methods can be applied.,NONE662,PP2-3,Detecting microwaves,Microwave remote sensing systems detect and quantify the electromagnetic radiation arriving at a detector - this radiation being either emitted (passive sensors) or scatterered back (active sensors) from the objects.\rThree properties of the recorded electromagnetic signal are of particular interest: its intensity - its phase and its polarization. The specific quantification of each properties allows signal interpretation - as they depend on the roughness and dielectric characteristics of the surface (intensity and polarization) as well as of the range between target and sensor (phase).\rThe detection of the microwaves is operated through two principal sensor elements: an antenna and a receiver. The antenna collects the incoming radiation and the receiver measures the collected electric signal.\rAs active microwave systems produce their own electromagnetic radiation - they are equipped with two additional elements: a pulse generator and a transmitter. Usually - transmitter and receiver are situated on the same antenna.\rA simple detector system only detects the intensity of the signal and amplifies it. Coherent systems measure both the amplitude and the phase of the incident electromagnetic radiation.\rMicrowave systems can be categorized in two different types: imaging and non-imaging sytems. Whereas for non-imaging systems each echoe (collected signal) provides a single measurement - imaging systems collect a sequence of echoes that generate a two dimensional image.,REMOTE SENSING663,PP2,Basics of microwave remote sensing,Microwave remote sensing operates in the microwave portion of the electromagnetic spectrum - generally using wavelengths greater than 3 cm and up to 1 m. \rMicrowaves are sensitive to different physical parameters than other regions of the electromagnetic spectrum. Microwaves interactions with objects are governed by geometric (structure - size - shape) and dielectric (water content) properties - whereas other regions of the electromagnetic spectrum reacts e.g. to object temperature or “color” (amount of reflection or absorption of the Sun light by a particular object).\rAs a general rule - microwaves interact with object at least as big as the wavelength. Smaller objects will therefore be transparent for the signal. Due to the large wavelengths - atmospheric particles are almost transparent to the signal and microwave remote sensing can penetrate clouds. Under very dry conditions - microwaves can even penetrate up to a few meters the top soil layers - therefore providing information that is not visible in other regions of the electromagnetic spectrum. Depending on the considered wavelength - microwave can also penetrate vegetation layers to different amounts.\rIn microwave remote sensing - three characteristics of the electromagnetic wave play an important role: its amplitude - its phase and its polarization. Depending on the application - either one characteristic or a combination of them is used to retrieve information.\rThere are two main types of microwave sensors: active RADAR systems and passive radiometers. RADAR is an acronym for RAdio Detection And Raging. An active radar system sends out pulses and records the echoes scattered back by the objects (scatterers) to the sensor. The systems use the two-way travel time of the radar pulse to determine the distance (range) to the illuminated object. Its backscatter intensity is determined by the radar system and object properties and depends on the quantity of energy coming back to the sensor. Active radar systems transmit a signal and record the amount of energy that is scattered back and depends of both dielectric and geometric properties.  Passive radiometers record microwave energy - which is emitted by the Earth’s surface.\rDepending on the type of system - microwave remote sensing can be used in multiple applications. Active sensors are principally used for diverse land cover mapping applications based on the particular backscattering mechanisms and characteristics of the objects on the Earth’s surface. Using multiple acquisitions - they are also favored for topographic - deformation and velocity mapping. Passive sensors are preferred for the determination of hydrologic variables such as soil moisture - precipitation - ice water content and sea-surface temperature.,REMOTE SENSING664,PS,Platforms - sensors and digital imagery,Remote sensing - i.e. the process of obtaining information about an object or area from a distance - is not possible without remote sensing sensors that collect this information and the platforms on which the sensors are installed and which are used to move them. Remote sensing sensors collect data by detecting energy that is reflected or emitted from Earth. There are different types of remote sensing sensors. The interaction between the sensor and the Earth's surface has two modes: active or passive. Passive sensors use solar radiation to illuminate the Earth's surface and detect reflection from the surface or measure the emitted energy. They usually record electromagnetic waves in the visible (˜430–720 nm) and near infrared (NIR) (˜750–950 nm) through short infrared (SWIR) (˜1.500-2.500 nm) to thermal infrared (TIR) (8.000-14.000 nm) ranges. The power measured by passive sensors is a function of surface composition - physical temperature - surface roughness and other physical properties of the Earth. Active sensors provide their own energy source to illuminate objects and measure their properties. These sensors use electromagnetic waves in the visible and near infrared range (e.g.laser altimeter) and radar waves (e.g. synthetic aperture radar (SAR)). As sensor technology has advanced - the integration of passive and active sensors into one system has emerged. Alternatively - remote sensing sensors can be classified into imaging sensors - i.e. that produce an image of an area - within which smaller parts of the sensor's whole view are resolved (pixels) - and non-imaging sensors - i.e. that return a signal based on the intensity of the whole field of view. In terms of their spectral characteristics - the imaging sensors include optical imaging sensors - thermal imaging sensors - and radar imaging sensors. These sensors can be on satellites - mounted on aircraft - unmanned aerial vehicle (UAV) -  drone or ground. The collected information can be transformed into an image or set of points (e.g. cloud points) - which can be further processed and analyzed to obtain the necessary information - e.g. agricultural field development phase - level of air pollution - etc.\rA digital imagery of Earth observation sensors is a two-dimensional representation of objects on Earth. Current images collected from different levels of acquisition - from ground to satellite - with the help of electronic sensors are examples of digital images. There are different aspects and characteristics of remote sensing data and images - such as - for example - data formats and processing levels - data storage - data properties.,REMOTE SENSING665,PS1-1,History of remote sensing sensors,Remote sensing sensors has its roots in the 19th century in the development of photography. Photography was an invention that made it possible to acquire a permanent image. The first photographic image was taken in 1826 by Joseph Nicephore Nieppce. While the first aerial photograph was taken in 1858 by Felix Tournachon - known as Nadar - from a tethered baloon over Biévre Valley in France. In 1907 Julius Neubronner developed a light miniature camera that could be fitted to a pigeon's breast. It can be said that the construction camera + pigeon was the precursor of today's unmanned aerial vehicle (UAV) or drone. Further developments focused on developing new sensors (analog vs. digital frame cameras) and how to save and store images (e.g. photographic emulsions - films). The origin of other types of remote sensing can be traced to World War II - with the development of radar - sonar - and thermal infrared detection systems. Since the 1960s - sensors were designed to operate in virtually all of the electromagnetic spectrum. Both civil and military aerial photography have long been widely used in cartography to create maps. Specialized large format cameras (looking vertically down - assuming the plane is flying horizontally) were developed. Such cameras have been specially designed to perform almost vertical sequences of bird-eye exposures during aircraft flight. Hence for a long time remote sensing consisted of aerial photography and photogrammetry using analogue mechanical or optical equipment. Everything has changed with satellites and the space race. The first real success of remote sensing satellites in serious scientific work was in meteorology - weather satellite TIROS-1 - launched by NASA on April 1 - 1960. \rToday a wide variety of remote sensing instruments are available as data source for use in different applications for land - water and atmosphere monitoring.,REMOTE SENSING666,PS1-2-1-1-1,Along track scanners,Along track scanner - also known as a pushbroom scanner - is an optoelectronic device that obtains images with a multispectral imaging system. The scanners are used for passive remote sensing. It records electromagnetic energy that is reflected (e.g. - blue - green - red - and infrared light) or emitted (e.g. - thermal infrared radiation) from the surface of the Earth. The scanners are mounted on space- or aircrafts. \rA two-dimensional image is created (line by line) by exploiting the platform motion along the orbital track. The data are collected along track using a linear array of detectors arranged perpendicular to the direction of travel. The array of detectors are pushed along the flight direction to scan the successive scan lines - and hence the name pushbroom scanner. \rThere are no moving parts on a pushbroom sensor - hence - the scanning speed can be increased compared to across track systems. A longer dwell time over each ground resolution cell increases the signal strength (high radiometric resolution - no pixel distortion). Additionally - finer spatial and spectral resolution can be achieved as the size of the ground resolution cell is determined by the Instantaneous Field of View (IFOV) of a single detector. The systems are designed for high-resolution imaging. However - a very large number of detectors is needed for high resolution images. It is a complex optical system. In addition - the pushbroom scheme requires a wide Field of View (FOV) optics system to obtain the same swath as for a corresponding whiskbroom (across track) scanner. It has narrow swath width.     \rThe detector arrays with such a line-scanning pushbroom system are usually of the type Charge-Coupled Device (CCD).\rThe MultiSpectral Instrument (MSI) on board the Sentinel-2 satellite (Copernicus mission) uses a pushbroom concept.\rMultispectral imaging systems building the final image (line by line) exploiting the platform motion along the orbital track. No rotating mechanical part required - usually based on a CCD matrix (high spectral resolution but just up to 1 micrometer) - e.g. Sentinel-2 MultiSpectral Instrument (MSI) - Sentinel-3 Ocean and Land Colour Imager (OCLI).,REMOTE SENSING667,PS1-2-1-2-1,Digital Frame Camera,The cameras - usually a charge-coupled device (CCD) or Complimentary Metal Oxide Semiconductor (CMOS) - that convert light into electrons that can be measured and converted into radiometric intensity value.,NONE668,PS1-2-1-2,Area Arrays,2-D systems with the ability to observe in two dimensions simultaneously.,NONE669,PS1-2-1,Line detector arrays,A type of a spectrometer. It is in principle - one-dimensional systems - whisk- or pushbroom - that form an image on a line-by-line basis in the scan direction.,NONE670,PS1-2-2-1-1,Thermal Radiometers,Thermal radiometers are radiometers with the capability of measuring the spectrum of infrared emission. As such - they are characterized by a relatively high spectral resolution (normally better than 1 cm-1 in wave number units). Modern Spectrometers on board satellites have a spectral resolution better than 0.7 cm -1 in order to properly resolve CO2 lines used for the retrieval of the atmospheric temperature profile. Based on the optical layout they are further classified in grating spectrometers and Fourier Transform Spectrometers or FTIR.,NONE671,PS1-2-2-1-2,Passive Microwave Radiometers,Passive microwave radiometers are radiometers that measures energy emitted at millimetre-to-centimetre wavelengths at 0.15 - 30 cm (frequencies of 1–200 GHz). Example of a sensor: SMOS Microwave Imaging Radiometer with Aperture Synthesis (MIRAS) - which aims at measuring land soil moisture and ocean salinity.,NONE672,PS1-2-2-1-3,Hyperspectral Radiometers,An advanced multispectral sensor that detects hundreds of very narrow spectral bands throughout the visible - near-infrared - and mid-infrared portions of the electromagnetic spectrum.,NONE673,PS1-2-2-1-4,Spectroradiometers,A radiometer that measures the intensity of radiation in multiple wavelength bands (i.e. - multispectral). Example of a sensor Moderate Resolution Imaging Spectroradiometer (MODIS),NONE674,PS1-2-2-2,Atmospheric passive sounders,Provide information about vertical profiles of temperature and molecular consistuent concentrations in the atmosphere (atmospheric sounders).,NONE675,PS1-2-2,Radiometers,Radiometers are instruments which measure radiative intensities within a particular frequency window. A radiometer is further identified by the portion of the electromagnetic radiation it covers - usually the infrared or microwave regions. Normally the spectral range extends from the longwave (14-15 micron) to the shortwave (3-4 micron). This range overlaps much of the emission spectrum of Earth. The technology is classified in broadband radiometer of spectral radiometers depending on the spectral resolution. A radiometer measures the intensity of the radiative energy - but does not differenciate between the different registered wavelengths or their respective amplitude.  In other terms - it provides a single value as combined result of all wavelengths within the considered frequency window.,NONE676,PS1-2,Passive vs. active sensors,Passive remote sensing systems record electromagnetic energy that is reflected (e.g. - blue - green - red - and infrared light) or emitted (e.g. - thermal infrared radiation) from the surface of the Earth. Passive sensors therefore rely on an external energy source (e.g. sun illumination - Earth heat emission). Contrary to passive sensors - who detect naturally occurring radiation - active sensors emit radiation and collect and analyze the signal that is sent back by the Earth’s surface or atmosphere. Active remote sensing systems produce therefore their own electromagnetic energy. They transmit and receive the radiation that is reflected or backscattered from the illuminated target. They do not necessitate an external source of radiation (e.g. Sun or Earth). Contrary to most passive sensors that are bound to detecting either the reflected Sun radiation or emitted radiation by the Earth’s surface in ranges from the ultraviolet to the thermal infrared - active sensors can use any radiation from the electromagnetic spectrum - the only limitation being the transparency of the Earth’s atmosphere. They often use wavelengths that are not sufficiently provided by the Sun - e.g. microwaves. \rActive systems can be categorized either according to their imaging capability - or according to the considered emitted wavelength - or also according to the way they use the returned signal. For the last category - it is generally distinguished between ranging systems - which use as principal information the time delay between transmission and reception of the electromagnetic radiation at the sensor - and scattering systems - which consider the strength (also called magnitude or intensity) - of the returned signal. Some systems also register both information.\rAs active sensors produce their own radiation and do not rely on e.g. Sun radiation - they are daytime independent and can also retrieve information about the Earth’s surface by night. Furthermore - depending of the considered wavelength - active sensors are weather independent. For longer wavelengths of the microwave domain - clouds are transparent - as the transmitted wavelength is larger than the water particles constituting the cloud and do not interact with them. \rActive sensors can control the direction of their illumination to a specific target to be investigated - but require in general more energy than passive sensors as they “actively” illuminate the Earth’s surface.,REMOTE SENSING677,PS1-3-1-1,Imaging Radar,Imaging radar is an active radar system that sends out pulses and records the echoes scattered back by the objects (scatterers) to the sensor. Imaging radars are independent of weather conditions and can operate day or night. It uses microwave wavelengths - radar bands from X- to P- or VHF-band - in four polarisations to illuminate an area on the ground. Normally only the horizontal (H) or vertical (V) linear polarizations are used. The radar system is characterized by combination of polarization of transmitted and received pulse: HH - HV - VH or VV. A typical radar system measures the strength and roundtrip time of the microwave signals that are emitted by a radar antenna and reflected off a target area. An imaging radar is therefore both and imaging and a ranging system. The illuminated objects are mapped in the radar depending on their backscatter intensity and respective range to the sensor.\rImaging radar can be mounted on aircraft or satellite. It operates in a side-looking configuration - left or right with reference to the flight direction. This acquisition geometry allows the distinct mapping of scatterers corresponding to their respective distance to the sensor. It causes also geometric distortions in the radar image - i.e. - relief displacement (foreshortening and layover) and shadow. The radar sensor operates not in the real aperture of the radar antenna - i.e. - real spatial width - radar (RAR) mode but in the synthetic aperture radar (SAR) mode. Synthetic aperture is possible to set up through the forward motion of the spacecraft - which enables to “extend” the real size of the radar antenna. With a SAR - each object on the ground is sampled at several antenna positions along the flight path - i.e. - as long as the antenna beam is illuminating it.\rImaging radar can be used for a different of land and water applications.,NONE678,PS1-3-2-1-1,Laser profiler,Laser profilers measure 2D range profiles and operate in different environments - like spaceborne - airborne and indoor. It is the simplest application of the LIght Detection And Ranging technique. It transmits a short pulse of energy (visible or near-infrared radiation) and detects 'echo' - by measuring the time delay. Knowing the speed of propagation of the pulse (speed of light) - the range from the instrument to the surface can be measured.\rLaser profiling uses successive reflectorless laser range measurements (1D distance measurement) on adjacent points along a path - which results in a 2D profile or cross-section of the ground. A laser profiler can be terrestrial - or ground-based - or it can be mounted on an airborne or spaceborne platform. In the case of ground-based measurements - the platform is fixed but the angle of illumination changes - allowing for the cross section of the terrain to be mapped. An airborne laser profiler can transmit a continuous stream of pulses along its flight path. As a result - if the position of the platform is known - e.g. from GPS/IMU system - a surface profile along the flight path can be reconstructed using the successively recorded vertical distances between the platform and the points on the ground. The use of an additional rotational mirror allow to scan the Earth in an additional dimension - providing 3D information of the mapped surface. This is the principle of a laser scanner.\rThere are two principal types of laser profiling techniques: the first one is based on analog detection and the second on photon counting. In analog detection - the signal power is converted into an output voltage providing a signal strength as function of time. The analog-to-digital conversion yields either a full waveform that allows retrieving the entire time-structure of the return signal strength- and therefore the full vertical structure of the target- - or discrete returns when the signal strength exceed a certain threshold. The full waveform information is especially useful when analyzing vegetation - as every vegetation layer (canopy - stems - branches) and the ground return pulses - allowing the determination of e.g. canopy height - ground surface topography but also a deeper analysis of the canopy structure. Photon counting techniques record the arrival of single photons. The counting of photons is combined with their time-of-flight. The accumulation of single photons at a specific range is similar to the signal strength of analog detection and allows retrieving the height and structure of specific targets.\re can be measured.,NONE679,PS1-3-2-1-4,Radar altimeters,A radar altimeter is an active - non-imaging remote sensing device. It measures the height of the terrain along the track beneath an air- or spaceborne platform using electromagnetic radiation from the microwave region of the electromagnetic spectrum. Radar altimeters operate similar to laser profilers. Both emit a short pulse of electromagnetic radiation towards the Earth’s surface and detect the time delayed echo. By measuring the time delay and knowing the speed of propagation of the pulse - the range (distance) from the instrument to the surface can be determined. By using the forward motion of the altimeter platform and transmitting a continuous stream of pulses a profile can be built up. If the exact location of the platform as a function of time is known - a surface profile can be generated. \rFor a high accuracy of the range resolution - a narrow antenna beam is required - which can be achieved either by using large antennas or short radar beams. In the first case - the radar altimeter is beam-limited; in the second case it is pulse-limited. As large antennas are not practical in space - pulse-limited systems are used for space-borne platforms. Pulse-limited altimeters use frequency modulated (chirp) pulses generated by a chirp generator. The accuracy of the measurements also depends on atmospheric transmission effects - as the speed of the electromagnetic radiation traveling at the speed of light will be delayed when passing through the ionosphere and the atmosphere twice. In general - the range resolution of radar altimeters is in the order of a few centimetres. \rIn the beginning - radar altimeters were used for measurements of surface profiles of the ocean topography to get information about currents - ocean circulation - wind and waves. Another basic application of altimetry were measurements over ice sheets and glaciers - e.g. for mass balance determination. Further application domains are geoid measurements also revealing deep sea trenches and the precise monitoring of satellite orbits.,REMOTE SENSING680,PS1-3-2-1,Laser altimeter,Laser altimeters historically were the first active sensing devices used on airborne platforms - measuring range information in form of single distances since the mid-1960s.  \rEven though laser scanners made it possible to retrieve information in a more rapid and denser coverage since the mid-1990s - laser altimeters remain of importance in the scientific community. Especially - the mapping of ice-covered surfaces - water bodies and flat land areas is still performed using laser altimeters.\rLaser altimeters are either airborne or spaceborne and are often used together with microwave (radar) profiler in order to calibrate the radar instruments. Whereas airborne laser altimeters are preferred for forestry application - e.g. for analyzing vertical vegetation structure - spaceborne laser altimeters are additionally used for multiple other applications. In particular - spaceborne laser profiler are of high interest for studying surface roughness of ice sheets or for mapping desert topography. Furthermore - spaceborne laser profilers are also useful in atmospheric science for retrieving cloud structure and analyzing different aerosol layers. The requirements for airborne and spaceborne laser altimeters are different. In particular - for spaceborne altimeters - both the distance travelled by the laser pulse and the platform speed are much higher than for airborne instruments - inducing the need of larger optics and more powerful laser instruments. First spaceborne laser experiments were conducted onboard the space shuttle in the mid-1990s - first aiming atmospheric research with a near infrared laser. After successful trial - the space shuttle laser altimeter was fine-tuned and follow-up missions focused on mapping terrain relief and vegetation canopies. Later missions - such as GLAS (IceSAT) - ATLAS (IceSAT-2) and GEDI (ISS) - used either near-infrared or green (or both) laser light and focused on improving ground coverage while allowing smaller footprints of the laser beam on ground. The revisit cycle of spaceborne laser altimeters allow the determination of regional elevation changes - e.g. monitoring of ice–sheet thickness or vegetation height - which is highly relevant for the scientific community and climate modelers.,NONE681,PS1-3-2-3,Ranging camera,By a ranging camera the simultaneous capturing of range measurements in the form of a range image for an extended area of dynamical 3D applications is given. Applications are building surveillance - traffic monitoring - and driver assistance.,NONE682,PS1-3-2-4-1,Spaceborne Laser Scanning,Spaceborne Laser Scanning (SLS; e.g. Geoscience Laser Altimeter System - GLAS - Global Ecosystem Dynamics Investigation - GEDI) provides mainly global - depending on the platform (GEDI mounted on International Space Station (ISS) provides measurements over the Earth’s surface between 51.6° N and 51.6° S) - measurements of the Earth's surface - with the potential on capturing additionally clouds and atmospheric aerosols. The spaceborne measurements allow to globally observe ice sheet and land elevations - approximate sea ice thickness - changes in elevation through time - vegetation coverage for biomass estimation - and height profiles of clouds and aerosols.,NONE683,PS1-3-2-4-2,Airborne Laser Scanning,Airborne Laser Scanning (ALS) systems allow a direct and illumination-independent measurement from 3D objects in a fast - remote and accurate way. Beside basic range measurements - the current commercial ALS developments allow to record the waveform of the backscattered laser pulse. Latest trends in sensor developments focus on single-photon detection. Different applications are of interest - like urban planning - forestry surveying - or power line monitoring. Further to describe the 3D scene - products like digital terrain models (DTMs) - digital surface models (DSMs) - or city models are provided.,NONE684,PS1-3-2-4-3,Mobile Laser Scanning,A mobile laser scanning or LiDAR system (MLS) consists of a moving vehicle equipped with one or more usually side-looking laser scanners to capture information about the local 3D geometry.,NONE685,PS1-3-2-4-4,Underwater Laser Scanning,Underwater Laser Scanning is applied in deep-sea as well as in shallow water regions. The ranging distance is close range and the measurement principle relies on triangulation by laser light - comparable with structured-light-projection. More recently - companies started to develop Time-of-Flight (ToF) underwater laser scanners.,NONE686,PS1-3-2-4-5,Bathymetric Laser Scanning,For Bathymetric Laser Scanning System the utilized green laser light with its potential penetration capabilities in water is essential.  For water surface mapping the electromagnetic radiation of the laser penetrates into the topmost layer of the water column and can also be used for mapping the water surface and shallow water bathymetry. Area-wide water surface heights and depths are required for many disciplines such as hydrology - hydraulic engineering - flood risk management - ecology - climate change - etc.,NONE687,PS1-3-2-4,Laser scanner,Laser scanners capture data by successively considering points on a discrete - regular (typically spherical) raster - and recording the respective geometric and radiometric information.\rThere are different types of laser scanners depending on their application and the platform on which they are mounted: spaceborne - airborne - terrestrial - mobile - underwater - bathymetric.,NONE688,PS1-3-2,LiDAR (Light Detection and Ranging),The main idea of LiDAR (Light Detection and Ranging) technology is based on actively scanning the scene by involving a device which emits electromagnetic radiation in the form of modulated laser light. \rGenerally - such scanning devices illuminate a scene with modulated laser light and analyze the backscattered signal. More specifically - laser light is emitted by the scanning device and transmitted to an object. At the object surface - the laser light is partially reflected and - finally - a certain amount of the laser light reaches the receiver unit of the scanning device. The measurement principle is therefore of great importance as it may be based on different signal properties such as amplitude - frequency - polarization - time - or phase. \rMany scanning devices are based on measuring the time t between emitting and receiving a laser pulse - i.e. - the respective time-of-flight - and exploiting the measured time t in order to derive the distance r between the scanning device and the respective 3D scene point. Alternatively - a range measurement r may be derived from phase information by exploiting the phase difference Δφ between emitted and received signal. According to seminal work - respective scanning devices may be categorized with respect to laser type - modulation technique - measurement principle - detection technique - or configuration between emitting and receiving component of the device. \rIn order to get from single 3D scene points to the geometry of object surfaces - respective scanning devices are typically mounted on a platform which - in turn - allows a sequential scanning of the scene by successively measuring distances for discrete 3D points.\rLiDAR technology is used for a diversity of applications such as autonomous driving - forestry - biomass estimation - precision farming - archaeology - city mapping - terrain modelling - and metrology.,NONE689,PS1-3-3-1,Sonar,Sonar - also called ultrasonic sensing - is one the principal sensors for mapping sea-floor - i.e. bathymetry. It transmits sound waves through water and records the amount of backscattered energy. It uses frequencies higher than normal hearing. A sonar can be either passive or active. Active sonars are also called echosounders.,NONE690,PS1-3-3-2,Seismic sensor,A seismic sensor is also called seismometer and measures the motion of the ground when it is shaken by a perturbation such as an earthquake - be it a large displacement or a microquake. The physical variable associated to the measurement of a seismometer is dynamic. It can be either the amplified ground motion - the velocity or acceleration. Current seismometers transform one of these three parameters into a voltage measurement. Usually - three seismometers are needed to retrieve the three components of the displacement. As for other sensors - there exists many types of seismic sensors - and they can be distinguished in active and passive sensors as well.,NONE691,PS1-3-3,Sonic sensors,Instruments that measure vertical distribution of precipitation and other atmospheric characteristics such as temperature - humidity - and cloud composition.,NONE692,PS1-3-4-1,Radar Scatterometers,Radar scatterometer is a calibrated radar designed to measure the radar backscatter cross section of a target - generally an area on the earth’s surface. Surface backscatter is measured as a function of the frequency - polarization - and illumination direction of the sensing signal (microwaves).,NONE693,PS1-3-4-2-1,Differential Absorption Lidar,Differential Absorption Lidar (DIAL) is a laser remote sensing technique that is used for range and/or profile measurements of atmospheric gas concentrations and constituents.,REMOTE SENSING694,PS1-3-4-2-2,Doppler Wind LiDAR,Doppler Wind LiDAR or Cloud-Aerosol Lidar with Orthogonal Polarization (e.g. CALIOP) is a two-wavelength polarization-sensitive LiDAR that provides high-resolution vertical profiles of atmospheric aerosols and clouds to enable an greater understanding of our climate.,NONE695,PS1-4,Imaging vs. nonimaging sensors,There are different ways to classify sensors used in remote sensing. One of them is the division into imaging and non-imaging sensors. Imaging sensors typically employ optical imaging systems (from VIS to TIR). They operate primarily at window frequencies - where atmospheric absorption is low and surface features can be imaged or measured. Non-imaging sensors include microwave radiometers - microwave altimeters - magnetic sensors - gravimeters - Fourier spectrometers - laser rangefinders - and laser altimeters.,REMOTE SENSING696,PS1-5-1-2,Across track scanners,Across track scanners - known as whiskbroom electromechanical scanners - are multispectral imaging systems building the final image (ground cell by ground cell) by combination of the platform motion along the orbital track with a mechanical rotation of the collecting optic in the across track direction. Opto-mechanical are typically multi-spectral radiometers (no limitation on bands) - whiskbroom systems are usually CDD spectrometers (high spectral resolution but just up to 1 micrometer). Examples of the sensors: Landsat Multispectral Scanner (MSS) - Landsat Thematic Mapper (TM).,NONE697,PS1-5-1,Speckle-pattern based sensor,Speckle-pattern based sensors operate with a spatial neighborhood codification strategies to exploit a unique pattern. The label associated to a pixel is derived from the spatial pattern distribution within its local neighborhood. Thus - labels of neighboring pixels share information and provide an interdependent coding. Representing one of the most popular devices based on structured light projection - the Microsoft Kinect exploits an RGB camera - an IR (infrared) camera - and an IR projector. The IR projector projects a known structured light pattern in the form of a random but unique speckle dot pattern onto the scene. As IR camera and IR projector form a stereo pair - the pattern matching in the IR image results in a raw disparity image which - in turn - is read out as depth image.,NONE698,PS1-5-2,Multi-temporal pattern based sensor,A multi-temporal (sequential) binary coding uses black and white stripes to form a sequence of projection patterns for each point on the surface of the object. Binary coding technique is very reliable and less sensitive to the surface characteristics - since only binary values exist in all pixels. Thus - each pixel may be assigned a codeword consisting of its illumination value across the projected patterns. The respective patterns may - for instance - be based on binary codes or Gray codes and phase shifting. To achieve high spatial resolution - a large number of sequential patterns need to be projected. All objects in the scene have to remain static. The entire duration of 3D image acquisition may be longer than a practical 3D application allows for. These sensors are utilized in industrial environment.,NONE699,PS1-5-3,Multi-spectral pattern based sensor,For a multi-spectral pattern based sensor - various continuously varying color patterns to encode the spatial location information are utilized.,NONE700,PS1-5,Structured-light-projection camera,A structured-light-projection camera emits active optical radiation in the form of a coded structured light pattern in the visible or infrared spectrum - or electromagnetic radiation in the form of modulated laser light. Via the projected pattern - particular labels are assigned to 3D scene points which - in turn - may easily be decoded in images when imaging the scene and the projected pattern with a camera. The procedure reminds to conventional stereo processing - where corresponding features must be extracted from a pair of stereo images to derive the spatial information. In contrast - such synthetically generated features allow to robustly establish feature correspondences - and the respective 3D coordinates may easily and reliably be recovered via triangulation. Generally - techniques based on the use of structured light patterns may be classified depending on the pattern codification strategy.,NONE701,PS1-6,Ground penetrating RADAR (GPR),Ground penetrating radar is a non-intrusive measurement technique that uses radio waves to probe the ground. It is used to analyze and locate targets buried in the sub-surface. It transmits low-power electromagnetic energy into the ground and receives weak signals from a low-loss dielectric or conductor material. It is principally used for archeology and geology. Typical penetration depths are between a few centimeters up to 4m.,NONE702,PS1-7,Optical spectrometers,An optical spectrometer is an instrument used to detect - measure and analyze the spectral content of the incident electromagnetic field (narrow-band - VIS - NIR - SWIR and TIR). It breaks down the incoming light spectrum so the whole wavelength range is mapped and each wavelength can be analysed individually. Usually - a distinction is made between optical and mass spectrometers.\rOptical spectrometers depict the intensity of the incoming light in function of the wavelength. Considering all wavelengths - each object has a specific spectral signature and the analyse of their particular spectrum allows the deduction of their composition ( e.g. pigments) or health.,NONE703,PS1,Types of remote sensing sensors,Remote sensing sensors acquire information about objects situated on the surface of e.g. the Earth remotely - e.g. from a distance - without any physical contact. They detect and measure the changes that the object imposes on its. \rRemote Sensing sensors are characterized according to several different properties:\r	Depending on the interaction between the sensor and the Earth’s surface - one distinguishes between active (e.g. radar) and passive (e.g. optical imagery) sensors. Some systems use both kind of sensors simultaneously.\r	Depending on the mapping process of the information - it can be distinguished between imaging and non-imaging sensors. Imaging sensors produce an image of an area of interest - e.g. give a spatial information about the incoming information. Spatial relationships between objects can be identified and used for visual interpretation. Non-imaging sensors register usually single response values for a specific area - and do not record how the incoming information varies across the field of view. They can be used to characterize the interaction between the received information and illuminated target.\r	Depending on the platform on which the instrument is deployed - one speaks either of ground based (e.g. terrestrial laser scanner) - airborne (e.g. plane - drone) - or spaceborne (e.g. satellite) sensor. For spaceborne sensors - the orbit geometry (e.g. geostationary - equatorial - sun-synchronous) and altitude (high - medium and low Earth orbit) play an important role - as it most often determines the application of the satellite in combination with the deployed sensor (weather satellites or Earth observation satellite). \r	Depending on the observed portion of the electromagnetic spectrum (e.g. optical - infrared - thermal - microwave). \r	Depending on the instrument (e.g. imagers - altimeters - spectrometers - radiometers). \r	Depending on the instrument precision - e.g. in terms of spatial resolution very high  vs. low resolution sensors; in terms of spectral resolution narrow band (hyperspectral sensors) vs. broad-band sensors (mono- and multispectral sensors); in terms of radiometric resolution very high vs. low resolution sensors. Some applications do not require very high precision instruments - e.g. sea surface temperature measurements - while other - e.g. for vegetation monitoring - require high spectral and radiometric resolution for good data interpretation and  analysis.   \rOther categorization would include the specific applications of each sensor (weather - environment - urban - land - water - mapping - photogrammetry - structure-from-motion - etc.) and if is financed and used for scientific - commercial or military goals.,REMOTE SENSING704,PS2-1,History of Remote Sensing Platforms,This topic covers information on the first remote sensing platforms that were used to obtain aerial photos. The first-known aerial photo was obtained in 1858 by Gaspard Felix Tournachon (Nadar). Afterwards - different platforms were used to obtain the information from above. The history of the development of remote sensing platforms includes platforms such as baloons - kites - rockets - pigeons - gliders - etc. to recent low-cost femtosatellites - e.g. for solar radioation pressure measurements. Historically - the main developments of the platforms as well as sensors was associated with military operations in the XXth century. Remote sensing data was used as part of photo- or/and satellite reconnaissance - i.e. aerial photos or satellite imageries used for the military purposes - mainly to make accurate maps and based on that to prepare a military strategy.,REMOTE SENSING705,PS2-2-1,Unmanned Aerial Systems (UAS),An unmanned aircraft system (UAS) includes an unmanned aerial vehicle (UAV) - an aircraft without a human pilot on board - a ground-based controller - and a system of communications between the two. The system includes a full range of size classes from very small hand-launched drones to the large high-altitude observational systems.,NONE706,PS2-2-2-1,Mission planning,Mission planning depends on the selected system of acquisition (sensor and platform). A detailed planning of a mission is a fundamental prerequisite for a successful acquisition of remote sensing data. Planning of an aerial photography mission (manned or unmanned) takes into account several parameters such as time of day/sun angle - weather conditions - flightline - platform. Planning and implementation of a spaceborne Earth Observation mission involves several successive life cycle ‘phases’ of conception - development - production and testing - utilization and support - and retirement - as part of an iterative and recursive process - until the satellite (space segment) is delivered and launched into orbit - and the data are exploited in the ground segment.,REMOTE SENSING707,PS2-2-2-3-2-3-1,Stripmap,Stripmap is an acquisition mode of Synthetic Aperture Radar (SAR) data. It is the most simple - common acquisition mode of the SAR satellite sensors. In this mode - the antenna of the radar system is pointed in a fixed direction related to the flight direction. The displacement of the illuminated footprint corresponds to the displacement of the sensor along the orbit. This results in a continuous acquisition strip parallel to the flight direction. The ground coverage and resolution varies depending on the considered sensor and technical requirements. For X-band spaceborne sensors - a spatial resolution of 3 m can be achieved with a swath width in range direction of 30 km - e.g. for TerraSAR-X. In C-band - a spatial resolution up to 5 m is achieved e.g. by Sentinel-1 with a swath width of 80 km. For L-band spaceborne sensors - the spatial resolution achievable in stripmap mode varies between 3 and 10 m - with a swath width of 50-70 km - e.g. ALOS PALSAR2. \r\rContrary to other acquisition modes - no antenna steering is needed in azimuth direction and the elevation beam is fixed in a specific range direction. This allows for an uninterrupted coverage along the flight direction.\r\rStripmap data show high resolution with sufficient coverage for regional applications and can therefore be used for e.g. detailed land cover analysis at regional scale such as the mapping of urban footprints. Furthermore - it can be used for the mapping of small island or to support emergency actions.,NONE708,PS2-2-2-3-2-3-2-1,Staring Spotlight,The Staring Spotlight mode is only available for a few sensors. It follows the same principle of antenna steering in azimuth direction as the standard Spotlight mode - except that the rotation center of the antenna for steering is situated at a nearer range position - within the illuminated scene. This induces that the illuminated antenna footprint stays almost the same during the whole acquisition. Contrarily to the Spotlight mode - the antenna footprint does not slide along the azimuth direction during the SAR acquisition. Additionally - the steering angle is higher for the Staring Spotlight mode than for the standard Spotlight mode - increasing therefore the length of the synthetic aperture and leading to an even higher resolution in azimuth direction.\rThe Staring Spotlight mode is implemented on the X-Band sensor TerraSAR-X since 2013 and achieves an azimuth resolution up to 0.25 m. Similar to the standard Sportlight mode - this happens to the detriment of the coverage. The scene size is highly dependent of the incidence angle and varies from 7.5 km to 4 km in range and from 2.5 to 2.7 km in azimuth direction. A larger coverage is obtained for smaller incidence angles.\rDue to their extremely high resolution - staring spotlight acquisitions are principally used for the observation and/or monitoring of small scale objects and phenomena - e.g. small landslides - or for tomographic analysis.,NONE709,PS2-2-2-3-2-3-2,Spotlight,Spotlight is a SAR acquisition mode that allows increasing the illumination time of a particular area of interest by steering the antenna beam in azimuth direction. In this mode - the beam elevation is fixed - but the antenna is steered in azimuth direction - increasing therefore the length of the synthetic aperture. The rotation center of the antenna for steering is situated behind the scene at far range. The antenna footprint slides slightly forward over the scene in the azimuth direction during acquisition - but slower than in Stripmap mode - due to the antenna steering. The longest illumination time in azimuth direction results in an azimuth resolution that is highly enhanced compared to e.g. the Stripmap or the ScanSAR acquisition modes. However - this improvement is done to the detriment of the coverage. As for the other acquisition modes - the ground coverage and resolution depends on the considered sensor. For TerraSAR-X - a minimum coverage of 10 km in range and 5 km in azimuth direction is achieved in the Spotlight mode - with and azimuth resolution of about 1 m. The L-Band sensor Alos 2 also allow Spotlight acquisition mode - with a coverage of 25 km in both directions and a resolution of 1 m in azimuth direction - and down to 3 m in range direction.\r\rDue to the very high resolution achieved in both directions - this acquisition mode is particularly usefull for urban area analysis as it allows for the detection of small objects. Therefore - Spotlight data are often used for the detection and recognition of man-made structures and objects - such as roads - buildings and even vehicles.,NONE710,PS2-2-2-3-2-3-3-1,Interferometric Wide Swath Mode,The Interferometric Wide Swath Mode is a particular acquisition mode of the C-Band satellites Sentinel-1 which implements the TOPS (Terrain Observation with Progressive Scan) method. It combines an antenna steering in elevation - as in ScanSAR mode - with a counterrotation of the antenna beam from backward to forward steering - opposite to the steering happening in Spotlight mode. The data is acquired in bursts by cyclically switching the antenna beam between multiple adjacent sub-swaths.\r\rThis opposite steering direction of the antenna along the azimuth leads to a shorter target illumination and induces a decrease of the resolution - but a cyclically continuous coverage in azimuth direction. The principal difference to the other acquisition modes is that this acquisition mode implies a shrinking of the antenna footprint virtually to a ground target instead of slicing it to retrieve the target.\r\rThe Interferometric Wide Swath Mode (IW) was originally designed to solve Signal-to-Noise heterogeneities and azimuth ambiguities appearing in the ScanSAR mode.\r \rFor Sentinel-1 - the IW mode provides a coverage of 250 km in range direction with an azimuth resolution of 20 m and incidence angles ranging from 29.1° in near to 46° in far range. \r\rStandard Single Look Complex Sentinel- 1 IW products contain three sub-swaths in range direction - with nine burts in azimuth direction.\r\rThe IW mode is the standard acquisition mode of the Sentinel-1 C-Band satellites and is acquired continuously over all land surfaces. The application are very diverse - ranging from agriculture and forestry to urban deformation monitoring and ship surveillance.\r\rSimilar to the IW mode - the Extra Wide Swath Mode (EW) of Sentinel-1 uses the same TOPS technique - but covers even wider areas up to 400 km in range direction - to the detriment of the resolution which decreases to 40 m. The EW Mode principally finds application in maritime applications such as artic and sea-ice monitoring - analyses of marine winds and oil pollution monitoring.,NONE711,PS2-2-2-3-2-3-3-2,Extra Wide Swath Mode,The Extra Wide Swath Mode is an acquisition mode of the Sentinel-1 satellites. It is primarily designed and used for wide area coastal monitoring - such as ship traffic - sea-ice monitoring and oil spill detection. It uses the TOPSAR technique with a swath width of 410km and a spatial resolution of 20 m by 40 m.,NONE712,PS2-2-2-3-2-3-3,ScanSAR,In the ScanSAR acquisition mode - the antenna beam is successively steered to different elevation angles. This results in adjacent - slightly overlapping stripes - or sub-swaths along the range direction - parallel to the azimuth direction - each stripe having a different incidence angle at its center. During antenna steering in elevation - transmitter and receiver are off. Therefore - each stripe is illuminated for a shorter time as for the StripMap mode - leading to a degradation of the azimuth resolution. However - ScanSAR allow a larger coverage in range direction than the other imaging modes.  Each sub-swath is illuminated for a shorter time than in the Stripmap case. The timing is adjusted though - such that the time-varying antenna footprint repeat cyclically. Similar to the other acquisition modes - the achievable resolution and coverage of ScanSAR products depends on the considered sensor and its properties. For X-Band - e.g. for TerraSAR-X - a total swath width of 100 km in range direction can be achieved using four adjacent sub-swaths or - using a Wide ScanSAR mode with six adjacent sub-swaths - a swath width up to 270 km can be achieved. A Wide ScanSAR scene shows incidence angles ranging from 15.6° in near to 49° in far range. The azimuth resolution varies between 18.5 m and 40 m - for ScanSAR and WideScan SAR modes respectively. For the L-Band sensor ALOS-PALSAR 2 - a swath width up to 40 km can be achieved - with incidence angles ranging from 8° to 70° and an azimuth resolution of 60 m. \r\rThe ScanSAR mode is well suited for large-area monitoring - e.g. for sea ice or glacier monitoring - as well as for mapping large-scale disasters - such as oil slick - or areas devastated by forest fires. Using interferometry - topography mapping and deformation monitoring is also possible.,NONE713,PS2-2-2-3-2-3-5,Stereoscopy,A stereoscopy acquisition mode collects remotely sensed data where each location on the ground (or the imaged objects) is covered multiple times (at least twice) - from different perspectives. Stereopairs and stereoscopic coverage enable the extraction of 3D representations of the environment from remotely sensed imagery. Most aerial photographs are taken with frame cameras along flight lines - or flight strips. [...] Successive photographs are generally taken with some degree of endlap [ - i.e. overlap]. Not only does this lapping ensure total coverage along a flightline - but an endlap of at least 50 percent is essential for total stereoscopic coverage of a project area. Stereoscopic coverage consists of adjacent pairs of overlapping vertical photographs called stereopairs. Stereopairs provide two different perspectives of the ground area in their region of endlap [overlap]. When images forming a stereopair are viewed through a stereoscope - each eye psychologically occupies the vantage point from which the respective image of the stereopair was taken in flight. The result is the perception of a three-dimensional stereomodel. As an input to photogrammetry analysis procedures - stereopairs from flight strips enable the extraction of digital elevation models (DEM) - orthophotos - thematic GIS data - and other derived products through the use of digital raster images and relatively sophisticated analytical techniques. With the availability of close-range UAV and terrestrial hand-held camera data - 3D reconstructions of buildings (even indoors) and other objects on the terrain surface become possible.,NONE714,PS2-2-2,Airborne platforms and systems,Since the 1940s aerial imagery has been the primary source of detailed geospatial data for extensive study areas. Photogrammetry is the profession concerned with producing precise measurements from aerial imagery. Aerial imaging and photogrammetry represent a major component of the geospatial industry. The topics included in this unit do not comprise an exhaustive treatment of photogrammetry - but they are aspects of the field about which all geospatial professionals should be knowledgeable.,NONE715,PS2-2-3-1,Earth observation missions,Earth observation (EO) missions are gathering information about the physical - chemical - and biological systems of the planet via remote-sensing technologies - supplemented by Earth-surveying techniques - which encompasses the collection - analysis - and presentation of satellite data.,NONE716,PS2-2-3-2,Types of satellite orbits,There are essentially three types of Earth orbits: high - medium and low Earth orbit. Satellites that orbit in a medium (mid) Earth orbit include navigation and specialty satellites - designed to monitor a particular region. Most scientific satellites - including NASA’s Earth Observing System fleet - have a low Earth orbit. On which orbit a satellite will be launched to - depends mainly on its application. The orbit types can be categorized according to their height.\rThe orbit height of a satellite corresponds to the distance between the Earth’s surface and the satellite. It determines its speed as it rotates around the Earth. Due to Earth’s gravity - the pull of gravity is stronger for lower orbits than for higher orbits. Therefore - a satellite situated on a lower orbit will circle the Earth faster than a satellite situated on a higher orbit.\r	High Earth orbit: it describes orbits situated at about 36000 km above the Earth’s surface (42164 km from the Earth’s center). At this exact distance - the speed of the satellite on the orbit matches the Earth’s rotation - i.e. the satellite needs 24 hours to complete a full rotation on the orbit - when the orbit is situated exactly above the equator. Such orbits are also called geosynchronous orbits - as the satellite moves at the same speed than the Earth and seems to stay in place over a specific location. Those orbits are mainly used for weather and communication satellites\r	Medium Earth orbit: it describes orbits situated at about 20200 km of the Earth’s surface - or 26560 km of the Earth’s center. At this height - a satellite rotates twice around the orbit during one Earth’s rotation. This orbit is also called semi-synchronous and this is the orbit type used by Global Navigation Satellite Systems such as GPS and GLONASS. A further important medium Earth orbit is the Molniya orbit which allows the observation of the poles - otherwise nearly impossible with equatorial geosynchronous orbits.\r	Low Earth orbit: this type of orbits are used from almost all dedicated scientific Earth Observation satellites. Most of them use a particular - nearly polar orbit inclination - meaning that the satellite rotates around the Earth nearly from pole to pole (instead of around the equator as it is the case for geosynchronous satellites). This rotation takes about 99 minutes - depending of the specific orbit inclination. During one half of the orbit - the satellite views the daytime side of the Earth - i.e. the illuminated side. At the pole - satellite crosses over and views the nighttime side of Earth. Back to the daylight side - the satellite can view the area adjacent to the region flown over in the last orbit path - due to the simultaneous Earth’s rotation. In 24 hours - satellites situated on these orbits view almost all the Earth twice - for optical satellites once in daylight and once in the dark. Radar satellites seen each Earth region twice - from two different illumination directions. These specific polar-orbits are called sun-synchronous - as the local solar time stays the same each time a satellite flies over a specific region. This has the advantage of providing an almost constant angle of sunlight for each region on the Earth’s surface viewed by the satellite over time and ensure repeatable sun illumination conditions; the angle will only vary seasonally due to the Earth revolution around the sun. Due to this consistency - images of a specific region would not show much illumination changes due to shadows or sunlight and image interpretation over time such as change detection or monitoring approaches are possible. Because a sun-synchronous orbit does not pass directly over the poles - there is a data gap over both poles where no data is acquired.,NONE717,PS2-2-3-3,Synthetic Aperture Radar (SAR) acquisition modes,An imaging SAR system can generally make acquisitions in different modes. Which acquisition mode to choose depends of the application but also on the desired coverage and data resolution. Even if technically all acquisitions modes can be used everywhere on the Earth’s surface - specific modes are preferred for ocean applications that are different from the ones used in land applications.\rThe different acquisition modes can be defined either by their geometrical or by their temporal properties.\rThe geometrical properties refer to the geometric configuration of the SAR antenna. Usually looking sideways down in a direction perpendicular to the flight direction (Stripmap mode) - the antenna can also be steered around the nadir axis in order to look at a specific target for a longer time during pass-by (Spotlight mode). This configuration allows to rachieve higher azimuth resolution but reduces coverage. It is rather used for very local application where a precise information about specific targets is needed. Other geometric configurations steer the antenna around the flight direction (ScanSAR mode) - yielding to a larger swath on the ground. The distance between near and far range is increased - as well as the range of incidence angles within one acquisition. Whereas it increases the area of the scene - it comes generally with a decrease of the spatial resolution in the azimuth direction. Depending on the sensors - the name of the acquisition modes as well as particular technical properties can differ. Sentinel-1 uses a TOPS configuration (Terrain observation with Progressive Scan) - which combines the antenna steering properties of both ScanSAR and Spotlight modes. \rThe temporal properties refer for specific techniques to the time interval between several acquisitions of the same area. Either these acquisitions are taken simultaneously in one pass over the area of interest (single-pass) - or they are taken at different times - needing several passes over the area (repeat-pass).\rSpecific SAR techniques such as InSAR and Tomography - while relying on those geometric and temporal properties - have additional acquisition configuration characteristics. For example - the interferometric mission TanDEM-X has three acquisition modes defined by the number of satellite emitting or receiving the signal (pursuit monostatic mode - bistatic mode - alternating bistatic mode) - which allows phase referencing. Tomographic SAR uses multi-baseline observations - i.e. the antenna passes several times over an area but at different heights - allowing via different incidence angles the retrieval of structural information of specific targets.,NONE718,PS2-2-3-4,Swath,Swath width refers to the width of the ground that the satellite collects data from on each orbit. The area imaged on the surface - is referred to as the swath. Imaging swaths for spaceborne sensors generally vary between tens and hundreds of kilometres wide.,NONE719,PS2-2-3,Spaceborne platforms and systems,Spaceborne platforms and systems are present at a great height from the earth surface. The altitude of platforms range from few hundred kilometers to several thousand kilometers. A large area can be captured in a single scene depending on altitude of sensor. The platforms can have different characteristics.,NONE720,PS2-3-1,Field spectroscopy and portable spectroradiometers,Field spectroscopy generally refers to the use of non-imaging spectrometers near the ground surface and it is usually aimed at evaluating spectral reflectance of the investigated target. For this purpose - consecutive measurements of total incident solar irradiance and of radiance or irradiance upwelling from the target are collected by an operator - or more recently by new instruments for long-term and unattended field spectroscopy measurements. The incident irradiance is usually computed by measuring the radiance upwelling from a white calibrated panel which represents the ideal Lambertian surface. Upwelling fluxes are instead usually collected holding the sensor vertically over the surface (nadir view) - although spectral libraries collected observing the target from different viewing angles are also available. \rField spectrometry is also referred to as ‘proximal sensing’ to underline that spectra are collected with portable spectroradiometers in the vicinity of the target - in contrast to ‘remote sensing’ - which is instead usually performed with satellite or airborne sensors.\rField spectroscopy is therefore an in-situ method for characterising the reflectance of natural or artificial surfaces and thereby provides reference data for the calibration or validation (cal/val) of airborne and satellite sensors. This method provides a means of scaling-up measurements from small areas (e.g. leaves - rocks) to composite scenes (e.g. vegetation canopies) - and ultimately to pixels.\rField spectroscopy is used in different applications - for example - soils - rocks - vegetation and chlorophyll fluorescence - water - snow surfaces and atmosphere. Long-lasting field spectroscopy campaigns based on manual measurements are extremely resource-demanding and do not ensure repeatability of the acquisition conditions as the instrument setup is initialized each day. To overcome such limitations a few research groups have initiated automatic tower-based spectral reflectance measurements using different devices. With such setups - non-imaging spectrometers are installed in the field and are operated automatically for long periods (i.e. months to years) and different networks of hyperspectral instruments are now becoming operational (e.g. RadCal Net).\rField spectroscopy can be also used to predict optimum spectral bands - viewing configuration - spectral calibration and time to perform a particular remote sensing task but also to develop - refine and test models relating biophysical attributes to remotely-sensed data. In this context - ground reflectance measurements are therefore mainly used as input in simulation study for sensor design - calibration/validation data for remote sensing sensors - for spectral mixture analysis and for the development of relationships between field data and radiometric variables.\rSince spectroscopy is the study of matter using electromagnetic radiation -  point or imaging field spectrometers are instruments which allow the measurements of reflected or emitted electromagnetic radiation. In particular - portable or hand-held spectroradiometers are small instruments that spectrally measure the radiation reflected or emitted by a target and they are useful in obtaining accurate spectral data over different surfaces. In remote sensing - they generally cover the 400-2500 nm spectral range and operate with a full width at half-maximum of about 1.5/3 nm - so that they can collect radiation in a continuous way across the spectrum. The final output is therefore the hyperspectral signature of reflectance of the surfaces versus the considered wavelength.,REMOTE SENSING721,PS2-3-2,Terrestrial Laser Scanning,Terrestrial Laser Scanning (TLS) is a ground-based - active imaging method that rapidly acquires accurate - dense 3D point clouds of object surfaces by laser range finding.\rA terrestrial laser scanning (TLS) system is a stationary highly accurate ranging device for geodetic surveying. More specifically - TLS systems provide dense and accurate 3D point cloud data for the local environment and they may also reliably measure distances of several tens of meters. Due to these capabilities - such TLS systems are commonly used for applications such as city modeling - construction surveying - scene interpretation - urban accessibility analysis - or the digitization of cultural heritage objects. When using a TLS system - each captured TLS scan is represented in the form of a 3D point cloud consisting of a large number of scanned 3D points and - optionally - additional attributes for each 3D point such as color or intensity information. However - a TLS system represents a line-of-sight instrument and hence occlusions resulting from objects in the scene may be expected as well as a significant variation in point density between close and distant object surfaces. Thus - a single scan might not be sufficient in order to obtain a dense and (almost) complete 3D acquisition of interesting parts of a scene and - consequently - multiple scans have to be acquired from different locations.,NONE722,PS2-3,Ground platforms and systems,Platforms and systems that acquire data from the level of earth's surface. A wide variety of ground based platforms are used in remote sensing. The acquired data are used for detailed in-situ measurements - e.g. - Leaf Area Index (LAI) - and for calibration/validation campaigns.,REMOTE SENSING723,PS2,Types of remote sensing platforms and systems,Remote sensing platforms and systems can be static (ground-based platforms) or moving (e.g. airborne or spaceborne platforms - UAVs). A remote sensing platform or system carry a remote sensing sensor. It can operate in near (few centimetres) or far (36 -000 kilometres) altitudes ranges.,REMOTE SENSING724,PS3-1,History of remote sensing data carriers,The development of remote sensing data carriers has followed the evolution of the photography - remote sensing sensors and computer platforms. The first remote sensed data was stored using the photography films (e.g. aerial photography - satellite Corona program) - which was later replaced by reel tapes - cartridge - and then removable and hard discs. In the era of big and fast growth of Earth observation data - and technological advancements in digital infrastructure - the satellite data are stored using cloud platforms providing different service models: Infrastructure as a Service - Platform/Software as a Service (e.g.  Copernicus DIAS - Google Earth Engine - open EO). The Cloud offers infrastructure to host - store and process the large amount of data efficiently. For example - the Copernicus Data Information Access Services (DIAS) is a comprehensive cloud-based hosting and processing system for the EO data in particularly for the Sentinels data - the Google’s Earth Engine (GEE) provides access to various satellite and offers processing power with a web-based programming interface - the Amazon Web Services (AWS) has dedicated cloud called ‘Earth on AWS’ - the Microsoft’s cloud called Azure facility the use of AI tools to address environmental challenges. Public solutions - as well as private ones - react with a variety of new and innovative tools - which have been recently developed (e.g. DIAS - ODC - EarthServer - EO Browser - GEE).,REMOTE SENSING725,PS3-2-1,Picture element (pixel),The picture elements are pixels and each pixel has a specific value (usually in grayscale). Image pixels are normally square and represent a certain area on an image. It is important to distinguish between pixel size and spatial resolution - they are not interchangeable. If a sensor has a spatial resolution of 20 metres and an image from that sensor is displayed at full resolution - each pixel represents an area of 20m x 20m on the ground. In this case the pixel size and resolution are the same.,NONE726,PS3-2-2,Image as a matrix (digital number DN),An image is an array - or a matrix - of square pixels (picture elements) arranged in columns and rows. In a (8-bit) greyscale image each picture element has an assigned intensity that ranges from 0 to 255.,NONE727,PS3-2-3,Data cubes,In data manipulation contexts - a data cube is a multi-dimensional array of values. A data cube can be visualized as the multidimensional extension of two-dimensional table. It can be viewed as a collection of identical 2-D tables stacked upon one another. Data cubes are used to represent data that is too complex to be described by a traditional table of columns and rows. Typically - the data cube is applied in conditions where these arrays are massively larger than the hosting computer’s main memory - for example multi-terabyte data warehouses o time series of image data.,NONE728,PS3-2-4,Earth Observation Big Data,Term Big data refers to any collection of data sets so large and complex that it becomes difficult to process using on-hand data management tools or traditional data processing applications. In the field of Earth Observation (EO) is usually refers to large time series of image data which size on disk is much greater than hosting computer’s main memory. EO Big Data offers solution that allows not only storing these data on disk but also efficiently process them.,NONE729,PS3-2,Digital image terminology,Most remote sensing data exist as digital images - and appropriate image processing allows the emphasis of certain aspect and subsequent extraction of information for specific applications.\rA digital image is a representation of the reality as a grid of picture elements. It can be considered as an array of numbers that can be stored and handled by a digital computer. The picture elements are pixels and each pixel has a specific value (usually in grayscale). This value is a digital number (DN) - which usually represents the amount of energy recorded by the sensor at this pixel position or any other characteristic recorded by the sensor - e.g. elevation. \rEach row of the image grid - or matrix - corresponds to one scan line. Each pixel is characterized by its row r and column c position in the image - as well as by its value. Additional geographical information is needed in order to assign a geographic location to a pixel. The digital number are integers usually compressed in one byte (= 8 bit) representation - i.e. each pixel can take 256 values.\rDigital images are raster data - as opposite to vector data. Whereas vector data can be points - lines or polygones - raster data always consist of pixels. A pixel is the smallest element in which an image can be divided into. The pixel size varies depending of the instrument and of the sampling used. Large pixel may contain information about several objects of the recorded scene. However - they only have one value. These are called mixed-pixel - as e.g. several land cover classes are represented within one pixel and they cannot be distinguished from another. \rIn multispectral imagery - each region of the electromagnetic spectrum is recorded in an independent image (band). Therefore - at a specific array position (r -c) - there exist several pixels - each with a specific value corresponding to the energy recorded for the considered band. This result in a three-dimensional matrix. The bands of a multispectral image can be displayed three at a time in the computer using for each band one of the three primary colors red - green and blue (RGB). This is called a color composite image. If the color composite represents a combination of the visible red - green and blue bands in their respective color - the combination is called natural or true color composite - as it corresponds to what the human eye sees naturally. Any other combination - for example considering bands of wavelengths that are not visible for the human eye is called a false color composite. It is often used to highlight the spectral differences and particular image features in order to extract information.,REMOTE SENSING730,PS3-3-1,Band interleaved by line (BIL),Band interleaved by line (BIL) is one of three primary methods for encoding image data for multiband raster images in the geospatial domain - such as images obtained from satellites. BIL is not in itself an image format - but is a scheme for storing the actual pixel values of an image in a file band by band for each line - or row - of the image. For example - given a three-band image - all three bands of data are written for row one - all three bands of data are written for row two - and so on. The BIL encoding is a compromise format - allowing fairly easy access to both spatial and spectral information. The BIL data organization can handle any number of bands - and thus accommodates black and white - grayscale - pseudocolor - true color - and multi-spectral image data.,NONE731,PS3-3-2,Band interleaved by pixel (BIP),Band interleaved by pixel (BIP) is one of three primary methods for encoding image data for multiband raster images in the geospatial domain - such as images obtained from satellites. BIP is not in itself an image format - but is a method for encoding the actual pixel values of an image in a file. Images stored in BIP format have the first pixel for all bands in sequential order - followed by the second pixel for all bands - followed by the third pixel for all bands - etc. - interleaved up to the number of pixels. The BIP data organization can handle any number of bands - and thus accommodates black and white - grayscale - pseudocolor - true color - and multi-spectral image data.,NONE732,PS3-3-3,Band sequential (BSQ),A binary raster file format for aerial photography - satellite imagery - and spectral data. The BSQ data organization can handle any number of bands - and thus accommodates black and white - grayscale - pseudocolor - true color - and multi-spectral image data. Additional information is needed to interpret the image data - such as the numbers of rows - columns - and bands - if there is a color map - and latitude and longitude to relate the image to geospatial locations.,NONE733,PS3-3,Data storage,In order to properly process remotely sensed data - the	analyst must know how	the data is organized and stored. Data storage consists of methods of organizing image data for multiband images.,NONE734,PS3-4-1,Spectral resolution,Spectral resolution describes the ability of a sensor to define fine wavelength intervals. The narrowest spectral interval that can be resolved by an instrument. Spectral resolution (spectral capability) also refers to the number of wavebands within the EM spectrum that an optical sensor is taking measurements over.,NONE735,PS3-4-2,Spatial resolution,The spatial resolution of an image corresponds to the size of the minimum area that can be resolved by the sensor. \rDue to the different techniques of acquisition of passive and active sensors - the spatial resolution is determined for both sensor types differently. \rFor passive sensors - the spatial resolution depends on their instantaneous field of view (IFOV) - which determines the area of the Earth’s surface that is viewed at one particular moment in time by one detector element. The size of this area is called resolution cell and characterizes the spatial resolution of the sensor. Depending on the spatial resolution - whole features of the Earth’s surface can be detected homogeneously in one or several resolution cells. For features smaller than the spatial resolution - the average reflected radiation of all features within a resolution cell is recorded - leading to so-called mixed-pixels.\rFor imaging active systems - the spatial resolution is dependent of both the length of the transmitted pulse in looking direction and the width of the radiation beam or the antenna width in flight direction.\rIn all cases - the spatial resolution indicates the level of detail observable in an image. Usually - one distinguishes between coarse (low) - moderate (medium) and fine (high and very high) resolution - whereby the use of this denomination is often context-dependent. Sensors with coarse resolution can only detect large features - but they usually cover a much larger area than high-resolution sensors - which can provide detailed information on small objects such as individual buildings - trees or cars - but for much smaller areas. Coarse spatial resolution mean in general a resolution cell larger than 250 m and a scene extent of several thousands of kilometers (>1000 km). Moderate resolution sensors have a spatial resolution of 30 m to 80 m - and a coverage of approximately 200 km in a single acquisition. Sensors showing spatial resolutions from 5 m or 6 m are high-resolution sensors - with a spatial coverage up to approximately 20 km. Sensors with a resolution cell’s width of less than 1 m are considered as very-high-resolution sensors.\rLow resolution sensors are appropriate for the analysis of broad-scale phenomena such as ocean color or cloud patterns. Medium resolution sensors are rather used for regional analysis such as land cover change and phenological response of vegetation. High-resolution sensors are particularly useful for object detection.,NONE736,PS3-4-3,Radiometric resolution,Radiometric resolution can be defined as the ability of an imaging system to record many levels of brightness. Radiometric resolution is defined as the sensitivity of a remote sensing detector to differences in signal strength as it records the radiant flux reflected - emitted - or back-scattered from the terrain. Radiometric resolution refers to the range in brightness levels that can be applied to an individual pixel within an image - determined on a grayscale. E.g. - Sentinel-2 sensor MSI is a 12 bit sensor imaging with 4.096 levels.,REMOTE SENSING737,PS3-4-4,Temporal resolution,Temporal resolution - also referred to as the revisit cycle - is defined as the amount of time it takes for a satellite to return to collect data from exactly the same location on the Earth. Imageing of the exact same area at the same viewing angle a second time is temporal resolution.,NONE738,PS3-4,Properties of digital imagery,A digital image begins as an analog signal. Through computer data processing - the image becomes digitized and is sampled multiple times. The critical characteristics of a digital image are spatial resolution - spectral resolution - radiometric resolution - contrast resolution - noise - and dose efficiency. These depends upon satellite orbit configuration and sensor design. Different sensors have different resolutions.\rSpectral resolution describes the ability of a sensor to define fine wavelength intervals. The narrowest spectral interval that can be resolved by an instrument. Spectral resolution (spectral capability) also refers to the number of wavebands within the EM spectrum that an optical sensor is taking measurements over.\rRadiometric resolution can be defined as the ability of an imaging system to record many levels of brightness. Radiometric resolution refers to the range in brightness levels that can be applied to an individual pixel within an image - determined on a grayscale. E.g. - Sentinel-2 sensor MSI is a 12 bit sensor imaging with 4.096 levels.\rSpatial resolution of an image corresponds to the size of the minimum area that can be resolved by the sensor.\rTemporal resolution - also referred to as the revisit cycle - is defined as the amount of time it takes for a satellite to return to collect data from exactly the same location on the Earth. Imageing of the exact same area at the same viewing angle a second time is temporal resolution.,NONE739,PS3-5-1,Header file,A header file is a seperate file associated with an image file. The header file can be either a plain ASCII-file or a binary file. It contains information about the image file it is associated with. These information can comprise the number of pixels per row (x-direction in a two dimensional image) - also called number of columns - the number of lines or rows (y-direction in a two dimensional image) - the number of bands (corresponding to the z-direction) - pixel spacing and spatial resolution - geographic reference information - the byte order (e.g. big-endian or little-endian) - spectral information for each band - calibration constants and many more. The purpose of a header file is to provide basic information about the properties of the image data either to the user or to a software and enabling a software to correctly load and display the image content. In this way - information contained in a header file can also be called metadata - which is data about the data. The structure and the information contained in a header file of remote sensing imagery can be found in the so-called product information documents. There is also digital imagery used in remote sensing containing the information found in header files not in a separate file but as part of the digital image data itself. In this case this is called header information or a file header - which is usually found at the beginning of the image file. In some cases  - image files may contain several header sections - e.g. theESA Envisat ASAR SAR data imagery contains a Main Product Header and a Specific Product Header section. Header information as part of the image file itself may be stored in ASCII or in binary format - or in a mixed binary format - as it was used for the ESA Envisat SAR data.,REMOTE SENSING740,PS3-5,Image description files,The image data stored in a binary data format (BIL - BIP - BSQ) is accompanied by description files that contain a set of entries describing the image data - including acquisition time - image size - statistics - map projection - pixel digital numbers - product type - etc. This general image or product information is stored in a form of header embedded in the image file or provided in the separate file (.hdr) or metadata in XML. There are numerous image file formats - the more common are TIFF (GeoTIFF) - bitmap (.bmp) - JPEG (.jpg - .jpeg - JPEG2000) - HDF - Raw (.raw) - Extensible N-Dimensional Data Format (NDF).,NONE741,PS3-6,Data formats,Remote Sensing data formats in which the data are organized and stored. The data format for a remote sensing mission is usually chosen based on a number of considerations - including requirements of the sensing system - mission objective - the design and technology of data processing - archiving - and distribution systems - as well as community data standard.,REMOTE SENSING742,PS3-7-1-1,Radiometrically corrected,Depending on the sensor and the provider - remotely sensed imagery is made avalilable to the user at different processing levels. For Sentinel-2 - the lowest product level made available to the user is Level-1B. THe Level-1B product provides radiometrically corrected imagery in Top-Of-Atmosphere (TOA) radiance values and in sensor geometry. Radiometric corrections applied to the Level-1B are: dark signal - pixels response non uniformity - crosstalk correction - defective pixels interpolation - high spatial resolution bands restoration (deconvolution puls denoising) - binning (spatial filtering) for 60m bands.,NONE743,PS3-7-1-2,Geometrically corrected,Geometrically corrected products are of a higher processing level than radiometrically corrected products. For Sentinel-2 - the geometrically corrected product is the Level-1C product. The Level-1C product results from using a Digital Elevation Model (DEM) to project the image in cartographic coordinates. Per-pixel radiometric measurements are provided in Top Of Atmosphere (TOA) reflectances with all parameters to transform them into radiances. Level-1C products are resampled with a constant Ground Sampling Distance (GSD) of 10 - 20 and 60 m depending on the native resolution of the different spectral bands. Level-1C products will additionally include Land/Water - Cloud Masks and ECMWF data (total column of ozone - total column of water vapour and mean sea level pressure). (Sentinel-2 User Handbook - p.44),NONE744,PS3-7-1,Processing levels of optical data,The definition of processing levels for optical data depends on the considered sensor. Most common satellite optical imagery are available in three distinct processing levels - from level 0 to level 2. The most used processing levels are level 1 and level 2 - depending on the user and the application. \rIn Level 0 - the raw data are processed in a way that they are ready to be archived. Processing operations generally includes telemetry analysis - error detections and granule concatenation. Furthermore - relevant parameters such as acquisition date and geographical reference are annotated in the form of metadata - this information being necessary for processing higher levels. Additionally - a quicklook of the image is generated. No correction is performed at this level.\rLevel 1 is often divided in several sublevels. Generally - both radiometric correction and geometric refinement are performed at this level. The radiometric processing includes several radiometric corrections such as dark signal correction or spectral band binning. The radiometric correction allows the determination of physical variables (e.g. reflectance) from the digital numbers. The geometric processing includes tiles association and resampling grid computation - in order to link for each image band its native image geometry to the target geometry. The result of this processing steps is usually a geocoded - Top of Atmosphere product.\rLevel 2 data usually consist of atmospherically corrected Level 1 data - i.e. Bottom-of-Atmosphere data. These surface reflectance products may be accompanied by additional outputs - such as scene classification - water vapor or surface temperature maps.\rFor specific applications and sensors - Level 3 application ready data are available. These are derivated products such as burned area - dynamic surface water content and snow cover maps.\rDepending on the considered sensor and level - the name of the sublevels can differ: Sentinel 2 defines Level-1B as radiometrically corrected data. Level 1C are radiometrically and geometrically corrected data - i.e Top-Of-Atmosphere (TOA) orthoimage products. Landsat sensors distinguish between Terrain precision correction (L1TP) - systematic Terrain Correction (L1GT) and Geometric systematic Correction (L1GS) depending on the quality of the reference data for geometric correction. These are usually separated into Tier 1 and Tier 2 datasets.,NONE745,PS3-7-2-1,Single Look Complex (SLC),The Single Look Complex SAR format is a single look product of the focused signal. It means that the azimuth compression has been carried out using the full azimuth bandwidth and therefore contains the highest azimuth spatial resolution and at the same time - it suffers from maximum speckle. The data are in the radar geometry - i.e. - in slant range coordinates - not projected onto any reference surface. Each pixel of the SLC product is a complex number.  (i.e. - has a real and imaginary component) that represents the amplitude and phase.,NONE746,PS3-7-2-2,Multi-looked Detected (MLD),From the Single Look Complex (SLC) product the Multi-look Detected/Multi-looke (MLD/MLI) can be generated. It is produced by multi-looking - i.e. - averaging - over range and/or azimuth resolution cells.,NONE747,PS3-7-2-3,Precision Images (PRI),Precision Images (PRI) are the Multi-look Detected/Multi-looked Intensity (MLD/MLI) images that have been resampled into square pixels - rotated to account for the view direction of the instrument and warped by some predefined operation that the projected image pixels are georeferenced onto a specified geographical coordinate system.,NONE748,PS3-7-2-4,Groud Range Detected (GRD),Before performing multi-looking - the Single Look Complex (SLC) slant-range geometry is projected onto ground. This kind of product - i.e. - in ground range geometry - is known as a Ground Range Detected (GRD) - e.g. - product of the Sentinel-1 mission.,NONE749,PS3-7-2,Synthetic Aperture Radar (SAR) data,For SAR data - usually three processing levels are distinguished - ranging from level 0 (less processed) to level 2 (higher processed).\rLevel 0 products consist of compressed and unfocussed raw data and are the basis for the processing of higher level products. Level 0 data are principally used for research in the topic of signal processing. As for optical data - level 0 product are annotated with several metadata - such as calibration and orbit information - and acquisition time and date.\rLevel 1 data can be separated in two distinct product types - depending if the full complex information is used (amplitude and phase) or only the amplitude information. The product denomination depends on the sensor type; for Sentinel 1 the names Single Look Complex (SLC) and Ground range detected (GRD) are used - respectively. Both products can be generated from the Level 0 data. Level 1 data are the products that are used by most scientific users. The processing toward Level-1 data includes Doppler centroid estimation and data focusing. The Level 1 SLC product consists of the real and imaginary part of focused complex SAR data in slant range geometry - from which the phase and amplitude information can be retrieved. This is available for all acquired polarisations. Additional orbit information for georeferencing is provided with the data.  The Level 1 GRD data consist of focused and multi-looked SAR data that have been projected to ground range geometry. GRD data only contain amplitude information - therefore the phase information is lost. The multi-looking step is particular for GRD data and allows both speckle reduction and square pixel resolution. As for the SLC data - the GRD data are annotated with orbit information for georeferencing. The Level-1 products are not calibrated - they include however information about calibration constants - which are sensor dependent. Further processing is needed in order to obtain calibrated radar cross section information from the original data intensity values.\rLevel 2 products describe geolocated derivated geophysical products such as ocean wind field or surface radial velocity. Such products are for example available for download on the Sentinel-1 Copernicus Hub. Further Level- 2 data are for example differential interferograms or change maps - which can be processed on different online platforms (e.g. Hyp3) and provide information about surface deformation or more generally changes between several acquisitions.\rThe denomination of the product types on the different levels may differ from sensor to sensor - but the processing steps stay almost the same - depending additionally on the considered acquisition modes. For example - GRD products are also called for other sensors Multi-Looked Detected (MLD) products.,NONE750,PS3-7-7,Analysis Ready Data (ARD),Data that have been processed to allow direct data analysis. User processing effort is reduced to a minimum.,NONE751,PS3-7,Processing levels,Earth Observation data are usually made available in different processing levels. The processing level is a mean of describing how much the raw data have been processed toward an informational geophysical product. The degrees of data processing usually follow a numerical hierarchy and typically range from Level 0 (less processed) up to Level 4 (highly processed). They characterize the type of data processing that has been performed between the raw data and the current product.\rA first effort for providing standard definitions of different processing levels has been made in the 1980s by the Committee on Data Management and Computation (CODMAC) of the National Research Council (NRC). CODMAC identified eight levels of processing - applicable for all space science data. Starting with the raw data at level 1 - the degree of processing and complexity of the data increased at each new level. Level 2 describes edited data - corrected for obvious instrumentation errors and tagged with acquisition time and location; Level 3 stays for calibrated data where values are proportional to a specific physical unit. Level 4 represents resampled data - Level 5 derived data - where specific geophysical information has been retrieved and mapped based on the original data. Level 6 represents all ancillary data (i.e. instrument data) that are necessary for the previous steps of calibration and resampling. Level 7 describes so called correlative data: not directly belonging to the original data - those data represent all other science data that where necessary for the interpretation of the original spaceborne dataset. Finally - Level 8 are user description - i.e. documentation of the data.\rConcerning spaceborne image data - both optical and radar - an adaptation of these original levels has been made from NASA and NOAA that is used for the main current spaceborne missions - including the Copernicus program. Whereas specific adaptations may arise for specific sensors and sensor types - there are five principal processing levels. Level 0 represents the raw data that have just been edited for the correction of artifacts.  Level 1 data are Level 0 data with additional annotations regarding time and geolocation information - radiometric and geometric calibration coefficients (for example Top of Atmosphere data for optical imagery). Level 2 data are already radiometrically and geometrically calibrated and represent physical variables (for example Bottom of Atmosphere data for optical imagery).  Level 3 data correspond to derived variables and information (e.g. land cover) with completeness and consistency information - e.g. quality flags. Level 4 represent higher level data resulting from modelling or more complex analysis of the data with additional ancillary information.\rFor many applications and users - so called analysis ready data (ARD data) are required. These usually correspond to Level 2 data that have already been pre-processed in order to retrieve the physical information and can be further analyzed for the specific thematic application.,NONE752,PS3,Remote sensing data and imagery,Remotely collected data is available from multiple sources and data collection techniques. Data can be obtained from different levels of data acquisition: ground - air or space - as well as using different sensors and wavelengths. Remote sensing data provides the necessary information to help monitor the Earth's surface.,REMOTE SENSING753,PS4,Databases of satellite and airborne sensors and missions,The listed databases provide information on past - operational and future remote sensing platforms and sensors. Use the following links to get more information on the sensors and missions.,REMOTE SENSING754,SD,Spatial dependency,Based on Waldo Tobler`s first law of geography( Tobler - 1970) - this property is set on the principle that 'everything is related - but that which is closer is more closely related'.,NONE755,SH,Spatial heterogeneity,This principle - as set forth by Anselin - determines that 'expectations vary along the earth`s surface' which means that any spatial analysis is dependent explicitly on the borders of study fields - i.e. the tracing of (spatial) analysis units.,NONE756,TA,Thematic and application domains,This area of knowledge deals with the use of EO / GI techniques and data in different themes and areas of application. It includes the user community of EO services and applications - societal and environmental challenges - EO services and applications - and standard EO products that are made available to users.,NONE757,TA11-1-1,Users in agriculture,The EO/GI users in agriculture are active in Agricultural commodities/Trading - agricultural production / Horticulture - Agricultural services - Agriculture machinery - Agriculture and Rural Development Policy - Agro chemicals / Plants & Fertilizers - Animal production / Livestock. The EO/GI users also include agriculture and rural policy makers. \rThey benefit from EO information - for example - by managment support for their crop production through forecasting crop yield - assess risks of damage/loss because of storms - disease or other stress factors - and water monitoring. Use in agriculture: knowledge and information products to forge a viable strategy for farming operations. Understand the health of his crop - extent of infestation or stress damage - or potential yield and soil conditions,NONE758,TA11-1-2,Users in fishing,The users in fishing are active in Fish stock management - Fishing fleets - Fishery distribution logistics - Aquaculture / fish farms - Coastal management agencies. In addition - the users include Fisheries authorities / policy makers. \rThe marine environment in particular is relevant to fishing. Fishing fleets move to the fishing grounds to catch fish. Finding them is challenging. However - fish shoals can be directly visible from above. Navigating to the fishing grounds can be risky: Coastline and shallows may pose a risk to ships. Additionally - skippers may have to deal with challenging weather conditions at sea. Environmental threats to the fishing grounds are oil slicks and other types of pollution. A problem from an economical perspective and for adhering to catch quota is illegal fishing. Noumerous opportunities exist to support fishing with EO information.,NONE759,TA11-1-3,Users in forestry,The users in forestry are active in Forest management - Forest Services - Commodities - Logging industry - Wood - paper and pulp industry - Forest policy - Forest machinery. They also include Forest Policy makers.\rUse in forestry: Understand depletion due to natural causes (fires and infestations) or human activity (clear-cutting - burning - land conversion) - and monitoring of health and growth for effective commercial exploitation and conservation.\rForests are a resource that is harvested all over the Globe for different purposes like construction or heating. Additionally - the forests represent an ecosystem that provides various ecosystem services. Proper management is a key to a healthy forestry industry that has to be aligned well with global environmental management activities. There is a need to avoid deforestation and forest degradation - keep the environmental impact of forestry within bounds - be aware of changes in the carbon balance. Economically relevant is especially a good understading of forest types - forest damage due to storms or insects - as well as wildfires. A threat to the environment results from illegal forest activities.,NONE760,TA11-1,Users in managed living resources,Users in managed living resources refer to human activities exploiting natural organic resources. Knowledge and information products to forge a viable strategy for the user’s operations such as the assessment of the status of the resource due natural or human activity for effective commercial exploitation and conservation. This includes agriculture - fishing and forestry occupations for our society.,NONE761,TA11-2-1,Users in alternative energy,The users in alternative energy consist of Solar energy providers - Wind energy providers - Tidal energy providers - Hydroelectric energy providers - Energy and Carbon traders - Local and regional planners - and National policy makers. Energy providers need information about the state of the environment to make the most use out of natural resources. Planners and policy makers have to weigh up whether and which type of alternative energy is justifiable and sensible for a specific region.\rEO data can be used to build maps that show resource information. For solar energy - those maps contain information about solar radiation - but also shadowing effects. Forecast products for irradiance are available to be able to plan the energy production for the coming days. Tidal waves can be depicted by sea surface heights. As tidal currents are periodical - they can be predicted well by the initial state of sea surface heights. In addition - also the speed of tidal waves can be determined by EO measurements. In the wind energy sector EO data is analysed to plan and monitor wind farms. Maps can show areas - where winds are suitable for wind energy production. After the construction of a wind farm - wind strength and direction during operation can be monitored. Finally - for hydroelectric power stations EO is used to monitor water reservoirs. As well hydrometeorological data is used to forecast water-related events and to monitor drought or floods.,NONE762,TA11-2-2,Users in oil & gas,The EO/GI user community in oil & gas consists of offshore exploration and production - on-shore exploration and production - drilling and support services - oil and gas commodities trading - and energy planners. Due to their activities both on-shore and offshore their need for EO-derived information about the land - the ocean and the atmosphere. They need EO-derived information about geological features (for exploration) - for asset infrastructure monitoring - construction and buildings. Safe offshore operations (ocean&atmosphere: forecast and monitoring current movement and drift - monitor sea-ice and icebergs - detect and monitor hurricanes and typhoons; land: map and assess flooding - detect wildfires . A large set of information needs results from their need to adhere to environmental regulations. They have to assess and monitor their environmental impact - ocean quality and productivity - land ecosystems and biodiversity - groundwater and run-off \rMany problems faced by oil - gas - including the selection and development of exploration areas - detection and mapping of illegal mining activities - or monitoring dams - pipelines and terrain movements - can be efficiently addressed by extracting information from geospatial imagery. Remote Sensing based applications reduce the need for field work - minimize environmental impacts - and ultimately safe costs - to help achieve results faster during exploration - extraction - and remediation/reclamation stages.,REMOTE SENSING763,TA11-2-3,Users in minerals & mining,The EO/GI community in minerals and mining consists of mining and quarrying companies - exploration and survey specialists - commodities traders - exploration and extraction equipment suppliers - drilling - excavation and support services - and regional planners / policy makers.\rTypical spatial questions for the users in minerals and mining are concerned with prospecting - e.g. 'Where can we find the minerals that are worth exploitation?' - and operation of mining sites: 'How much material has already been excavated in the mine and how much material was deposited in dedicated dump areas?'. Additionally relevant are arising risks through mining activities - e.g. 'How do the mining activities affect settlements in the vicinity?' or 'How do the mining activities affect the environment?'. Concequently - the EO/GI users in minerals and mining benefit from EO information through mapping geological features - monitor mineral extraction - measure land use statistics - assessing environmental impact of human activities - detect and monitor ground movement - and monitor land pollution.,NONE764,TA11-2,Users in energy and mineral resources,Users in energy and mineral resources deal with the harvesting of energy from renewable resources and extractive industries including oil and gas and raw materials. EO information helps them in exploring locations where to build new mines or power plants - in identifying risks from infrastructure and in managing the environmental impact of their operations.\rUses that apply to the extractive industries: study of landforms - structures - and the subsurface - to understand physical processes creating and modifying the earth's crust. EO/GI should play a key role to transform data into information and knowledge about the potencial feasibility and viability of renewable resources - in particular solar and wind at the natural and urban ecosystems - and in particular to support Sustainable Development Goals SDG 7 Affordable and Clean Energy and SDG 11 Sustainable Cities and Communities.,NONE765,TA11-3-1,Users in construction,EO/GI users in construction include construction companies - civil engineering consultancies - architect and design companies - planning authorities - and national land agencies. \rThey benefit from EO through monitor building development - assess environmental impact of human activities - map and assess flooding - detect land movement - subsidence - heave - and monitor land-use statistics,NONE766,TA11-3-2,Users in utilities & supplies,Utilities (water - electricity - waste): Power station operators - Water plants operators - Survey companies - Hydroelectric suppliers - Regulatory Bodies - Distribution companies - Landfill and waste - Regional planners / policy makers.\rThe benefit from EO information that monitor pollution in rivers and lakes - assess changes in the carbon balance - assess environmental impact of human activities - monitor land pollution - assess changes to urban and rural areas - assess and monitor water quality - assess ground water and run-off.,NONE767,TA11-3-3,Users in communications & connectivity,Users of EO/GI in communications and connectivity are mostly mobile telecommunications providers and fixed telecommunication providers. Theire business is to connect people via telephone and internet. The assets for their services include the infrastructure of communication networks physically installed in the ground - the cellphone towers distributed over the land surface - particularly in higly populated areas - as well as other installations (e.g. company buildings) and equipment (communication satellites).\rSpecific spatial questions of these users are concerned with the reception quality that the network can provide in an area. The network coverage would neet to react to changes of the built environment. New settlement infrastructure may cause a new population distribution and subsequently the need to network adaptations to cover new areas or cover some areas with higher band widths because more people are living there. Additionaly - the coverage of cellphone antennas depends on the arrangement of environmental obstacles that degrade or block the radio signal. Any place where the built environment or the vegetation changes can change the reception quality within the covered area of an existing cellphone tower. \rThe benefit of EO information for the user group of communications and connectivity comes from monitoring building development - assessing changes to urban and rural areas - and mapping line of sight visibility (terrain height - land cover).,NONE768,TA11-3-4,Users in transport & logistics,EO/GI users in transport and logistics include road transport operators - haulage - road infrastructure operators - tolls - airport operators - rail operators - airlines and airline services - and transport engineers.,NONE769,TA11-3-5,Users in marine,EO/GI users in marine include ports & harbors administration - bulk cargo carriers - cruise liners operators - ferry operators - naval operations - and rescue and safety at sea.,NONE770,TA11-3-6,Users in travel & tourism,From a conceptual point of view travelling is crossing the space from one location to another. Tourism mostly requires a travel to the desired destination and typically also includes moving inside a specific area. Therefore both tourism and travel are highly dependent on spatial phenomena which are often captured using EO.All kinds of travelling are highly dependent on weather conditions which can be observed with meteorological satellites. Also the current traffic conditions like congestion - road condition and natural hazards can be discovered with EO.\r\rThe types of tourism which are outside of buildings require sufficient weather forecast. Especially outdoor tourism at the coast or in mountain areas have a need for specific information about the current and the near future conditions of the natural environment. Examples are avalanche reports and forecasts for wind or wave heights of water bodies. Local tour organizers can utilise this information in order to better plan offers for tourists and also ensure overall safety during their stay.\r\rTourism and travelling are import economic factors. Consequently both the public and the private sector are interested in ensuring safe and convenient travel conditions and furthermore in creating an attractive environment for travellers and touristic visitors. This includes recognising environmental pollution - since this discourages tourist from visiting an area. Not only incoming - but also outgoing tourism is an important factor in local economies. Travel agencies - for example - are highly dependent on retrieving accurate information about foreign regions which are typically obtained with earth observation technology.\r\rOf course tourism and travelling itself also can be observed from space - this is especially true for mass tourism and areas where traffic has increased a lot during the last time. Typical effects are the increase of settlement area and the additionally used space for roads - parking lots - airports and harbors. These changes to the earth surface can be quantified with the help of land cover change detection.In many cases local administrations and decion makers want to mitigate the negative consequences of mass tourism - the insights of the mentioned EO measurements provide a useful foundation for sustainable planning.,NONE771,TA11-3,Users in infrastructure & transport,Users in transport and infrastructure apply to all manufacturing and physical supply in land but also marine domains including transport & logistics - utilities - construction - communication & connectivity - and tourism.,NONE772,TA11-4-1,Users in insurance & real estate,EO/GI users in insurance and real estate include primary insurance companies - re-insurance sector - insurance brokers - insurance service suppliers - commercial banks - major projects -  and international financial institutions. \rProduction processes (including primary production like farming) - property and real estate are often insured against certain risks - e.g. from natural hazards. \rUsers benefit from EO information through applications that monitor building development - assess crop damage due to storms (including to forecast and map large waves) - assess damage from earthquakes - detect and monitor wildfires - map and assess flooding - detect land movement - subsidence - heave - forecast and assess landslides.,NONE773,TA11-4-2,Users in retail & geo-marketing,EO/GI users in retail and geo-marketing include Retail centres and Advertising and Marketing agencies. They use EO/GI data in the field of Navigation and LBS - Shopping chains or Logistics.,NONE774,TA11-4-3,Users in news & media,Users in news and media are Television companies - Broadcasting providers - News and Information agencies - Web service providers - and Entertainment software providers. They benefit from monitoring - forecasting and assessing of natural risks/disasters.,NONE775,TA11-4-4,Users in ICT - knowledge and digital interfaces,Users in ICT include fixed and mobile telecommunications providers. They can make use of EO/GI data by monitoring building development and changes to urban areas.,NONE776,TA11-4,Users in financial & digital services,Users in financial and digital services cover a broad area of activity that touches on many other market sectors such insurance & real estate - retail - news & media and digital interfaces. The categories included are identifiable as a “service” (tertiary sector: attention - advice - access - experience - and affective labour) and not part of the physical supply of goods.,NONE777,TA11-5-1,Users in smart cities,The users in smart cities include urban planners - architects - spatial planning offices - urban policy makers. The users benefit from EO information through map information about urban structures and related land use when managing land use - climate change adaptation - and urban green infrastructure. Typical use cases include Urban adaptation to climate change and Green infrastructure and its ecosystem services to increase quality of life of citizens (https://land.copernicus.eu/user-corner/land-use-cases),NONE778,TA11-5-2,Users in local & regional planning,The users in local and regional planning include spatial planning departments of municipalities - spatial planning offices - and spatial planning policy makers. Land use management in densely populated areas involves negotiation of conflicting land-use demands for settlement - production system (including agriculture and forestry) and infrastructure. The users benefit from EO information to manage the use of land and its impacts.,NONE779,TA11-5,Users in urban development,Users in urban development and users involved in the development of rural settlements perform tasks on local and regional scale (to the scale of nations). These users benefit from EO information to manage the use of land & its impacts. Users such as urban planners - architects - spatial planning offices - urban policy makers in public/private sectors in smart cities or generic urban local/regional planning belong to this category. EO/GI becomes a key data and information to support Sustainable Development Goals - SDG 11 Sustainable Cities and Communities in particular to set up at geospatial and temporal basis the evolution of urban environmental and socioeconomical factors for a better distribution and equality of resources - benefits and impacts (environmental urban justice maps),NONE780,TA11-6-1,Users in defense - security & military,Users in defense - security and military are border control organisations - police and rescue forces - military services - and intelligence services. Use of EO/GI data can be made in the field of detecting and monitoring high risk areas (natural and humanitarian) - monitoring border incursions - or monitoring maritime movements.,NONE781,TA11-6-2,Users in emergency & social protection,EO/GI users in emergency services are coast guards - ambulance services - fire services - police services - civil protection organisations - and rescue services. They benefit from monitoring - detecting and assessing natural risks/disasters.,NONE782,TA11-6-3,Users in humanitarian operations,The EO/GI users in humanitarian operations correspond to humanitarian aid organisations - humanitarian support organisations and overall humanitarian response such as border control organisations - police and rescue forces - coast guards - civil protection - military services - and intelligence services. They can use EO services to detect and monitor high risk areas produced naturally or by humans - monitor border incursions or maritime movements. They provide support to local populations that have experienced a crisis - e.g. they fled from a conflict or are affected by a natural disaster. The organisations therefore support the population's needs for sustenance. Consequently - any related risks are relevant as well. The users benefit from the EO capability to identify and monitor people in need - i.e. to assess pressures on populations and migration - and to monitor humanitarian movement and camps. They additionally benefit from EO through mapping disaster areas for situation awareness and detecting sensitive risk areas. Some examples of users at European level are DG RELEX - DG ECHO - DG ENV/ MIC. At UN - the users include OCHA - UNHCR - UNDPKO - UNDP - UNOPS - UNITAR - UNICEF - UNESCO - WFP. Further - international users  include IFRC - WHO - WB - and donor organizations. At the national level - the users include Civil Protection Agencies - Ministries of Internal Affairs / Civil Protection Department - Development and Aid agencies.,NONE783,TA11-6,Users in defense & security,Users in defence and security work in the field of military - emergency and social protection and define - collect - analyse information to provide intelligence & safety. Some examples are activities under humanitarian response such as border control organisations - police and rescue forces - coast guards - civil protection - military services - and intelligence services which can use EO services to detect and monitor high risk areas produced naturally or by humans - monitor border incursions or maritime movements.,NONE784,TA11-7-1,Users in environmental ecosystems & pollution,EO/GI users in environmental ecosystems & pollution include scientists - consultants - planners and policy makers with interest in environmental issues.,NONE785,TA11-7-2,Users in health care,Users in health care health-related services include services on site-specific field conditions as well as import phenological timing events - which helps to make predictions for monitoring air quality - forecasting epidemics and diseases - as well as forecasting sunlight exposure.,NONE786,TA11-7-3,Users in meteo & climate,EO/GI users in meteo and climate; use of satellite-based observations in addressing key climate science questions for user-centric climate change risk assessment applications or climate-related issues,NONE787,TA11-7,Users in environmental - climate & health,Users in the public administrations or private organizations using EO to assist environmental or climate change impact policy making decisions i.e - assisting in developing monitoring to evaluate and deliver policy goals - provide assessment of ecosystems - rapid response to major environmental risk events - or those associated health security & care events. These users are largely related with international treaties and hence a strong international collaboration. EO/GI becomes a key data and information to support Sustainable Development Goals (SDG) in particular in terms of environmental - climate and health towards SDG 11 - SDG 13 Climate Action; SDG 14 Life Below Water; or SDG 15 Life on Land.,NONE788,TA11-8-1,Users of consumer solutions,EO/GI users of customer solutions; easier for society to use and engage with EO services through mobile devices - social media platforms - apps. Enormous  potential to use citizen-driven observations in combination with EO data,NONE789,TA11-8-2,Users in leisure,EO/GI users in leisure; basic public understanding on EO Services,NONE790,TA11-8-3,Users in education - training & research,The community of users in education includes instructors (1) who are teaching or conducting research in some aspect of GIScience - such as coding - remote sensing - field methods - geodetic control - web mapping - spatial analysis - or related topics - or (2) who are using GIS as a teaching tool in a discipline - such as business - biology - economics - or health sciences.  By extension - this community includes students and supportive deans and other educational administrators.  The benefits that these users gain from EO information includes a set of best practices vetted by experts in the field that they can use to teach modern GIS workflows more effectively.  \rThe goals of this user community are focused on a deeper and a broader implementation of geotechnology - methods - and spatial data throughout the educational system—primary - secondary - university - and lifelong learning (libraries - museums - and other informal settings).   Deeper implementation implies embracing GIS as a platform - including its field data gathering tools and citizen science workflows - spatial analysis - building web maps and apps - communicating with multimedia maps derived from web GIS - systems configuration work - and the coding that is behind modern GIS infrastructure.   Broader implementation implies the use of GIS in a multitude of disciplines at all levels of education - formal and informal; occurring wherever changes over space and time are being examined.  \rAt all levels of education the challenge of sufficient bandwidth and the use of a professional systems-based tool such as GIS - along with devices capable of running web GIS tools - are barriers in many areas throughout the world.  However - educational and societal forces represent a stronger challenge than technological ones.  These educational and societal challenges that this user community faces include the lack of educational content standards at the primary and secondary level that support the use of geotechnologies in education - and at the university level - a lack of awareness of and access to modern SaaS GIS tools and open data portals.   \rThe risks that the community faces in not facing the challenge of the use of GIS in the education sector is a lack of geographic and spatial literacy among students and faculty.  This will translate to research that does not consider spatiotemporal implications of 21st Century challenges - a workforce ill-equipped to deal with them - and consequently an increasingly unstable and dysfunctional world.  To build a workforce that can meet global challenges in energy - biodiversity - climate - natural resources - natural hazards - human health - economic inequality - and others - a deep and wide implementation of GIS technology and methods must take place throughout the educational system.  The actions that society can take to face that challenge is to provide professional development opportunities for faculty - curricular resources - assessment instruments - relevant spatial data and open data portals - examples of best practices - and a network for educators and researchers in which to interact.  EO can provide all of these elements in partnership with educational institutions - government - nonprofits - and industry to meet this challenge.  In so doing - an increasingly sustainable - healthier - resilient world can be achieved from the community to the global level.,REMOTE SENSING791,TA11-8,Users among citizens & society,Citizens and society in general use and engage with EO services through mobile devices - social media platforms - apps. We do also categorize in this section the users in education - research and training providing knowledge and learning outcomes.\rActive and engaged citizens are one of the main driving forces of EO/GI. Nowadays - there is a growing amount of location-based contents generated by connected “produsers” - mainly equipped with smartphones. The exponential growth of ambient geographic information through social networks became the basic feature of a spatially enabled society - in which it  behaves as a vessel where millions of people share their current thoughts - observations and opinions - showing to provide more reliable and trustworthy information than traditional methods like questionnaires and other sources.\rA spatially enabled citizen is explained through his ability to express - formalize - equip (technologically and cognitively) - and (un)consciously activate an efficiently use of his spatial skills. Harvesting this ambient geospatial information provides a unique opportunity to gain valuable insight on information flow and social networking within a society - support a greater mapping - understand the human landscape and its evolution over time. With these insights - city planners can make use of the gathered affective data to detect positive or negative trends developing in the city - managing to take early countermeasures.\rNevertheless - assembling and analyzing EO/GI provide us with unparalleled insight on a broad variety of cultural - societal - and human factors - particularly as they relate to human and social dynamics - for example: 1) mapping the manner in which ideas and information propagate in a society - information that can be used to identify appropriate strategies for information dissemination during a crisis situation. 2) Mapping people’s opinions and reaction on specific topics and current events - thus improving our ability to collect precise cultural - political - economic and health data - and to do so at near real-time rates. 3) Identifying emerging socio-cultural hotspots.,NONE792,TA11,User community of EO services and applications,The EO/GI user community pools sub-communities (stakeholders) that share common needs for EO/GI information. From an economic perspective - market sectors represent user communities. Users of a community have a common interest in specific aspects of societal or economical benefits to be realized by the implementation of EO services. A user-led community is active at specific locations/regions or in specific environments on the Earth. Their activities are associated with particular features and objects of the environment and related processes that can be detected and monitored with EO satellites. EO information therefore is relevant to the user community's management of their assets - the risks to their assets - and the impact that their activities may have on other aspects of the environment. User objectives (use cases) with EO information include: Enforce regulations; Develop strategies and policies; Manage assets; Plan and design project implementations; Analyse and understand impact / consequences.\rUser communities can profit from EO services and applications in the field of managed living resources - energy and mineral resources - infrastructure and transport - financial and digital services - urban development - defense and security - environmental - climate and health - or citizens and society. EO/GI becomes a key data and information to support Sustainable Development Goals -SDG in particular in terms of users in managed livimgs resources towards SDG 2  Zero Hunger; SDG 8 Decent Work and Economic Growth; SDG 9 Industry - Innovation and Infrastructure; SDG 14 Life Below Water; or SDG 15 Life on Land,NONE793,TA12-1,EO for climate change mitigation & adaptation,Climate change observations show the warming of the climate system. The changes since the 1950s are unprecedented over decades to millennia.The atmosphere and ocean have warmed - the amounts of snow and ice have diminished - and sea level has risen. The anthropogenic emissions of greenhouse gases are the highest in history. Recent climate changes have had widespread impacts on human and natural systems. There is an urgant need for climate action through mitigation and adaptation. Mitigation actions prevent or reduce the emission of greenhuse gases into the atmoshpere with the objective to make the impacts of climate change less severe. Adapting to climate change increases our resilience to impacts like extreme weather events (e.g. hazards like floods and droughts) that get more frequent and intense in many regions. Current climate change will get worse in the future even if the reduction of emissions is effective with negative effects on ecosystems - economy - human health and well-being. There is extensive need for actions to adapt to the impacts of climate change.,NONE794,TA12-10,EO for sustainable urban development,'Sustainable urban development is a goal of the global society. It summarizes a specific set of problems that cities face all over the world. Cities want to provide a high quality of life to their residents. However - this goal is threatened by urban growth at the cost of urban green infrastructure’s accessibility by citizens etc.  Communities that address this: C40 (association of the largest cities of the globe) - CitiesIPCC - related SDGs of the UN - etc. Skills: Explain how the monitoring of urban areas contributes to sustainable urban development through its capability to provide regularly updated information about the benefit of urban green infrastructures and their ecosystem services to the quality of life in a city\r',NONE795,TA12-2,EO for biodiversity & ecosystems,Biodiversity describes the variety of ecosystems (natural capital) - species and genes in the world or in a particular habitat. Ecosystem services sustain our economies and societies and are essential to human wellbeing.,NONE796,TA12-3,EO for digital agenda & new skills,Worldwide countries follow a digital agenda for the economy and initiatives to foster new skills among the workforce to cope with transformation processes with massive impact on the labour market.,NONE797,TA12-4,EO for energy transition,Energy transition is a thematic area whose EO experts are proficient in relevant EO data and its processing methods and infrastructure to derive information for energy transition [and its regulatory context - etc.]. The expertise of each expert may be very specialized. In sum - the experts have:  The relevant domain knowledge (knowledge about type of monitored entities and their properties - e.g. reflectance properties of sea ice and related EO sensors for detecting them) - and The relevant workflow knowledge and processing skills for extracting and providing targeted information for energy transition. [may share strategic objectives… such as „gaining thorough understanding of Energy transition“ - „foster usage of EO information for energy transition“],NONE798,TA12-5,EO for sustainable agriculture & food production,Agricultural activity is sustained by good environmental conditions that allow farmers to harness natural resources - create their produce and earn a living. This fosters a sustainable rural economy while food produced by agriculture sustains society as a whole.,NONE799,TA12-6,EO for infrastructure & transport,This societal challenge aims to provide efficient - safe and environmentally friendly mobility solutions.,NONE800,TA12-7,EO for health surveillance,In recent decades - society has fought communicable diseases with success through treatment and prevention. The Covid-19 pandemic shows that communicable diseases are still a threat to the health of citizens. Spread can gappen very quickly from one country to another. Challenges lie in the (re-)emergence of infectious diseases - antimicobial resistance and vaccine hesitancy. Policies of states focus on surveillance - rapid detection and rapid response.,NONE801,TA12-8,EO for emergency - security & defense,There is a rising geostrategic competition and power pilitics challenging rule-based multilateralism. Further - there are armed confilct - civil wars and instability in the EU's broader neighbourhood. \rFurther - natural disasters pose a threat to society - where the Sendai Framework of disaster risk reduction focuses on.,NONE802,TA12-9,EO for water sustainability,Water is an essential resource for food production. Growing crops requires significant quantities of water. Without sufficient - good quality and easily accessible water - agri-food production is under threat.,NONE803,TA12,EO for societal and environmental challenges,EO provides timely - continuous and independent data for monitoring indicators of the progress of the society in various societal challenges.\rEO monitoring supports activities that address societal & environmental challenges. This happens indirectly along a chain: e.g. a regularly provided EO information product derived from EO data of a satellite is integrated as a parameter in a climate model / Earth system model. This climate model enables the development of regulations (and their enforcement through constant monitoring) to implement climate change mitigation measures. Thereby - the chain is characterized by seveal connected nodes: from societal challenges to use cases of users to EO applications to EO products to specific satellites and their sensors.\r[Communities that promote collaboration among diverse stakeholders from academia - industry - public administration as well as local residents]  \rScientific agendas address societal challenges and the EO/GI community can contribute to them. Consortia usually include experts from academia (researchers - developers - scientists) - EO companies - and members from the user community such as public authorities.,NONE804,TA13-1-1,Monitor the atmosphere,Monitor the atmosphere includes monitoring of the atmosphere composition and air quality - as well as forecasting of sunlight exposure. Timely - continuous - and independent data on the atmosphere is useful in various domains like health - agriculture - renewable energies - urban planning - climate sciences and biology.\rThe atmosphere composition includes greenhouse gases (GHG) like carbon dioxide - methane - NO2 and SO2. They are part of the Earth system and have a strong impact on the climate. To monitor changes in atmosphere composition enables modelling climate change and understanding the impact of human-induced emissions of GHG relative to natural sources. EO-derived products include inventory of emission data as an input to atmospheric chemistry transport models and forecast models. Inventories are based on a combination of existing data sets and new information - describing emissions from fossil fuel use - ships - volcanoes - and vegetation. This ensures good consistency between the emissions of greenhouse gases - reactive gases - and aerosol particles and their precursors.\rAir quality describes the composition of the atmosphere from gases and particles near the Earth's surface. Local emissions from different sources (e.g. energy production - industrial production - traffic) cause changes to the atmospheric composition that are highly variable in space and time. The quality of the air we breathe can significantly impact our health and the environment. Therefore - it is highly relevant to monitor air quality and emissions. EO satellites are capable of monitoring aerosols - tropospheric O3 - tropospheric NO2 - CO - HCHO - SO2 - and particulate matter (of the sizes PM 2.5 and PM 10). Products like air quality assessment reports - daily ozone forecasts - and UV-index forecast maps are produced that are applied in specific use cases - particularly related to health.\rThe amount of solar radiation that arrives at a location on the Earth surface depends on the atmosphere composition and varies over the day and the seasons. Information on solar radiation is useful in various domains. Applications of sunlight and ozone data are for example real-time UV radiation forecasting and risk assessment - skin health services - climate change studies - assessment of ozone protection policies effectiveness - plant growth and disease control - evaporation and irrigation models - power generation - solar heating systems planning and monitoring.,NONE805,TA13-1-2,Monitor the climate,Monitoring the climate includes monitoring climate forcing and the carbon balance and assessing climate change risks.\rClimate forcing describes the imbalance of the Earth’s energy budget due to natural or human-induced sources. This imbalance results in a change in the globally-averaged temperature. Amongst the contributors of positive climate forcing - that leads to an increase in the globally-averaged temperature - the increase of carbon dioxide in the atmospheric composition is considered to be the most important factor. Changes in the carbon dioxide concentration indicate that the exchanges between carbon sources and sinks are not balanced. It can be shown that human-induced emissions of carbon dioxide are responsible for the increase of the carbon dioxide since the industrialisation.\rWith EO - we can monitor changes in greenhouse gases (GHG) - aeorosols - albedo - and solar radiation. The dynamic nature of the climate makes it necessary to apply equally dynamic EO monitoring that allows to deliver key information on historical - seasonal forecast and projection periods for climate-related indicators.\rRelevant EO products include estimates of the climate forcing of aerosol - ozone and greenhouse gases. The dynamic nature of the climate makes it necessary to apply equally dynamic EO monitoring that allows to deliver key information on historical - seasonal forecast and projection periods for climate-related indicators. \rThe products are particularly relevant to the European energy sector in terms of electricity demand and the production of power from wind - solar and hydro sources. \rMoreover - water management uses EO-derived information about climate change to mitigate effects of changing precipitation patterns to adapt their strategies - and to prepare for climate variability and change in the water sector - e.g. because of changes in river discharge - droughts and floods.\rFinally - insurance uses climate change information for assessing the weather risks to insured assets that change with the climate-related increase in extreme weather conditions. This includes products like up-to-date catalogue of wind storms and their associated impacts on the ground.,NONE806,TA13-1-3,Forecast the weather,The weather is the state of the atmosphere measurable by its temperature - humidity - precipitation - and other atmospheric variables. To forecast the weather is a major branch in the field of meteorology. In comparison to climate - weather can only be predicted for a short period of time (minutes to month) - because it describes the state of the atmosphere for specific days at specific locations. For a reliable weather forecast - a good numerical prediction model with precise initial conditions is needed. Models are sensitive to changes in the initial condition - that is why at the moment weather predictions are only accurate for few days. However - both models and the determination of initial conditions are steadily improved. EO makes a significant contribution to improving the initial conditions by providing global information several times a day. As the quality of the EO products improves - the weather forecast also improves. \rSince decades - satellites are used to monitor and forecast weather. Therefore - it is one of the most established sectors of satellite data applications. There are geostationary and polar-orbiting weather satellites that measure all kinds of meteorologically relevant variables - e.g. cloud coverage - wind speed [...] via passive or active imagery. However - not only satellites are used to collect information - but also other remote sensing techniques that can be airborne or ground-based such as Lidar.\rWeather forecasts are used by citizens for decisions in everyday life - in agriculture for crop cultivation decisions and in the stock markets. Other domains of applications are hydrometeorology - aviation - maritime navigation - and the military and nuclear sectors.,REMOTE SENSING807,TA13-1,Monitor the atmosphere and climate,Monitor the atmosphere and climate includes all change-focused services/applications which assess - monitor - forecast and provide timely - continuous and independent data (e.g. temperature - humidity - emissions - greenhouse gases - solar UV radiation - aorosols -...). It closely monitors each of the Earth's different subsystems and - besides being the basis for weather forecasts - helps to better understand and evaluate the impact of the climate change.,NONE808,TA13-2-1,Monitor critical assets,Monitor critical information about offensive and defensive systems. This deserves a category in its own right since the nature of observations is quite different from many others.,NONE809,TA13-2-2,Monitor health,Monitoring health can be delivered indirectly by monitoring environmental changes that can cause endemic and chronic diseases. Typically monitored environmental factors are temperature - humidity - stagnant water - NDVI - land cover - or soil type.,NONE810,TA13-2-3,Food security monitoring,Monitoring food security includes the monitoring of food availability by environmental conditions (land cover - NDVI -...) - as well as  the monitoring of migration patterns. Risks that can lead to food insecurity are hazards or conflicts.,NONE811,TA13-2-4,Monitor borders,Monitoring borders includes monitoring the land and marine border incursions - monitoring transport routes - assessing pressures on poplulations - and monitoring humanitarian movement.,NONE812,TA13-2,Monitor security & safety,Monitor security and safety describes the collection and analysis of information to provide intelligence services & safety. The task is to give early warnings in case of emergencies - to monitor infrasturcture - transport routes (land and water) and borders - to surveil security and sovereignty.,NONE813,TA13-3-1,Map and assess flooding,EO is capable to repeatedly map flood extent directly after flooding - including further aspects (flood plain - extend mapping - frequency - rainfall - flash floods - vulnerability - inundation - risk-based mapping & management; flood spread and depth followed by automated insurance payouts). Modelling (hydrological modelling and monitoring focused on seasonal dynamics of water availability) based on EO data (digital elevation models) supports flood risk assessment.,NONE814,TA13-3-2,Detect and monitor wildfires,For the outbreak of forest fires - satellite remote sensing can be continuously track and monitor - in a timely manner to grasp the development of forest fires. Beyond - weather monitoring enables to forecast weather conditions where fires are likely - allowing authorities to prepare.,REMOTE SENSING815,TA13-3-3,Assess damage from earthquakes,Damages from earthquakes to infrastrcture can be detected directly - e.g. by mapping collapsed buildings in optical data to derive rapid response products. Use of SAR interferograms enables to identify geotectonic shifts. Modelling enables to identify hotspot areas.,NONE816,TA13-3-4,Forecast and assess landslides,Landslides are a natural hazard posing a threat to human life - property - infrastructure - and natural environment. Every year - slope instabilities have a significant impact on societies and economies. Consequently - landslide documentation is used for risk assessments - policy making and enforcing of construction regulations. Landslide monitoring is used to ensure safety of infrastructure operation. Rapid mapping of landslides and associated damages is done for response actions - e.g. of civil protection organizations. As ground surveys are very costly and time-consuming - satellite remote sensing is increasingly used to assess damage resulting from landslides.\rLandslides lead to local terrain changes after a downslope movement of material under the effect of gravity. They vary by type of movement (e.g. falling - toppling - gliding and flowing) - by size (from small rocks to entire mountain slopes) and velocity (from a couple of millimetres per year up to free-fall speed). Landslides can be triggered both by natural causes (like earthquakes or heavy rainfall events) and human causes - e.g. mining activities that lead to slope failures. Landslides can initiate other natural hazards - e.g. when a landslide blocks a river a lake can be formed which poses a risk for an outburst flood. \rLandslides are diverse in appearance - and therefore are challenging to detect. EO-based assessment methods aim for detecting changes to the land surface and surface displacements. \rEO satellites and airborne remote sensing use optical sensors for detecting landslides in post-event images and land cover changes caused by landslides - primarily indicated by the removal of vegetation and the exposure of bare soil - by comparing pre-event and post-event images. Typical resolutions of optical EO data for mapping rapid landslides are between 0.4 m and 30 m - depending on the size of landslides caused by the triggering event. Optical data from unmanned aerial vehicles are used in cases where single landslides or concise regions have to be covered. Additionally - synthetic aperture radar (SAR) sensors allow the detection of subtle changes in ground deformation caused by landslides. Therefore - time-series of radar images are used. Further - airborne laser scanning enables the generation of digital elevation models (DEMs) that allow identification of landslide surface structures and - in case of repeated coverage - detection of elevation changes. DEM generation for analysing landslides is also possible with photogrammetry on stereographic optical data and radargrammetry on SAR images.\rThe diversity of appearances of landslides leads to challenges for (semi-)automatic image processing and makes visual interpretation of EO data by a landslide expert a commonly used method for landslide mapping. However - visual interpretation is subjective and experts’ results can be very diverse. Additionally - it is a slow and time-consuming process. Semi-automated classification based on optical and DEM data using object-based image analysis (OBIA) can achieve detailed interpretations of landslides while reducing the analysis time. Interferometic SAR (InSAR) techniques - such as persistant scatterer interferometry (PSI) or Small Baseline Subset (SBAS) - are primarily used to identify and monitor slow-moving landslides and for quantifying movement rates. Integrated analysis of optical - DEM and SAR data allow to fully exploit the potential of EO data from different sensors for landslide mapping and assessment.,REMOTE SENSING817,TA13-3-5,Assess and monitor volcanic activities,In context of volcanic activities and volcanos - EO methods are capable to provide information about various aspects - including ground motion (seismic) - volcanic eruptions (pre-eruptive - sin-eruptive - atmospheric ash - dispersion) - Rapid damage estimation (prevention) - earthquake damage extent (loss adjuster dispatch). classification of land cover types,NONE818,TA13-3-6,Multi-hazard assessment,Multi-hazard assessment both focuses on regions prone to several geohazards and on the interrelationships between hazards - i.e. what happens if two disasters strike at the same time or what happens when one disaster is causing a cascade of disasters with a strongly amplified impact (e.g. a landslide causing a dammed river causing an outburstflood with a magnitude beyond the design of protective measures; or an earthquake in a coastal region that is followed by a tsunami). EO can provide imformation on the single disasters and - through integration and comprehensive impact assessment - enables multi-hazard assessment.,NONE819,TA13-3,Assess disasters & geohazards,Assess disasters and geohazards by EO includes alert & early warning - emergency mapping - and risk & recovery mapping. It relates to observations - controlling - assessments that are linked to natural and human made risks. Typical disasters that can be assessed by EO are in particular floods - droughts - forest fires - landslides - tsunamis - earthquakes - cyclonic storms and volcanic eruptions. Since with EO it is possible to quickly analyse the risk or damage it is used to effectively plan emergency response actions.\rThere are several measures to minimize or prevent the damage caused by disasters. Some of them have to be carried out in anticipation of a disaster - others after the occurrence of an event. The different phases that are needed to reduce or avoid the impact and to assure rapid response and recovery are described in the disaster management cycle. Depending on the cycle phase - EO has to meet different requirements. The Mitigation and Preparedness phase are passed through in anticipation of a disaster event. Thus - requirements to EO products may focus on high completeness of mapping or high accuracy of mapping. In contrast - Response and Recovery phase include rapid mapping - thus EO capabilities must meet near real-time delivery requirements. \rAs well - the nature of the disaster determines which EO products are used. Optical sensors are used throughout the different types; however - landslides are mostly assessed by radar sensors and thermal sensors are additionally used for forest fires.,NONE820,TA13-4-1,Monitor crops,To monitor crops and agriculture with EO-based methods is relevant for various applications - including to assess environmental impact of farming - assess crop damage due to storms - to detect ollegal or undesired crops - to monitor water use on crops and horticulture - and to monitor land degradation neutrality. EO mapping of crops happens on all scales with both optical and SAR sensors. Relevant EO products include degradation - agri-environment - ecosystem - damage estimation - warning-service - food-security - impact - crop health (disease and stress) - leaf area index - crop acreage and yield harvest (inventories / statistics) - crop types (extent - growth - health - stress) - land surface temperature - illicit crops - estimates - cultivation patterns - soil water index - surface soil moisture - run-off - land cover (land cover change) - land productivity (net primary productivity - NPP) - carbon stocks (soil organic carbon - SOC).,NONE821,TA13-4-2,Monitor the forest,Monitor the forest focuses on regular and periodic measurement of certain parameters of forests (physical - chemical - and biological) to determine baselines to detect and observe changes over time. Typical applications include to assess deforestation and forest degradation - assess forest damage due to storms or insects - to monitor forest resources - detect illegal forest activities - assess the environmental impact of forerstry - and to monitor the forest carbon content. Moderate resolution sensors have been used to map forests at large scales. Modern very high resolution optical sensors provide enough spatial and spectral detail to map individual trees. Further sensors for forest monitoring include SAR and LIDAR. Integration of optical sensors - LIDAR and in-situ measurements seems an accurate method to achieve third dimension forest mapping.,NONE822,TA13-4-3,Monitor bodies of water,EO provides the opportunity to monitor bodies of water - i.e. inland waters - and to assess ground water and run-off. For lakes - this includes products about water quality - pollution - turbidity - suspended sediment concentrations (quantitative - qualitative) - waterbody (temperature - extent - volume - quantity) - algal blooms - alkaline water - evaporation - surface temperature. For ground water and run-off - the products focus on water run-off (water quantity) - hydrological network and catchment areas (water catchment) - run-off season - groundwater. Various scales are addressed - from local catchments to the global water cycle. For inland water quality - sensors are optical medium resolution (300 meters) for achieving a (strongly cloud-cover dependent) update frequency of 10-20 times per year and high resolution (5 meters) for update frequency of 3-5 times per year.,NONE823,TA13-4-4,Monitor snow and ice,Monitoring of snow and ice focuses on glaciers and their retreat due to climate change (extent - mass balance) - the seasonal snow cover (its extent - depth - temperature and snow water equivalent) - and the ice on rivers and lakes (inland ice - thickness - freezing period - melting period - ice extent). Glacial monitoring in the mountainous regions around the globe - and of the Greenland and Antarctic ice shields uses optical EO data of high and very high resolution and SAR data. Satellite based daily snow covered area products can reliably be provided down to a spatial resolution of 500 meters. Global products are possible with weekly updates. Applications include - among others - climate change impact monitoring - relevant for modelling runoff patterns in catchments for etimating hydroelectric power generation potential.,NONE824,TA13-4-5,Monitor land ecosystems,EO is used to monitor land ecosystems and biodiversity - environmental impact of human activities - land pollution and vegetation encroachment. A tool for this is land cover mapping and mapping of land cover change about a wide set of categories - lincuding basic forest types - major agricultural surface types - conservation areas - settlements - infrastructure - primary roads - bare soil - water bodies - rivers - wetlands following standard classification schemes according to CORINE or FAO LCCS. Main source are optical EO data and associated pixel-based and object-based image classification methods. For discriminating vegetation classes - they often making use of various vegetation indices and biophysical parameters.,NONE825,TA13-4-6,Monitor land use,EO technologies (both optical and SAR) are capable to categorize bio-physical coverage of land to produce land cover maps like CORINE Land Cover (CLC). The EO method is objective and allows for frequent updates. EO-derived land cover is an excellent basis for mapping land use - the socioeconomic use that is made of land. Land use products are used in a wide range of applications (e.g. agriculture - forestry - spatial planning - determining and implementing environmental policy - land accounting). In a humanitarian context - land use mapping is applied to map refugee camps - population and pressures on population that cause migration.,NONE826,TA13-4-7,Monitor topography,EO is capable to monitor topography with various types of land surface elevation data (both digital terrain models and digital surface models) and also focus on land surface changes and ground deformation / movement due to e.g. soil erosion or  permafrost thawing - frost heaving. This includes also the mapping of stable zones where such changes do not happen. The main ways of creating a digital elevation model (DEM) from EO data are  deriving it from interferometric synthetic aperture radar (InSAR) - from stereoscopic pairs of optical images acquired from different viewing angles - and deriving them via laser scanning.,NONE827,TA13-4-8,Extract information about subsurface geology,EO is able to extract information about subsurface geology - including near surface features - lithology features - and linear disturbance features (faults & discontinuities). Concerning monitoring of mineral extraction EO supports by mapping ground surface - illegal activities - mine waste (erosion - land subsistence - biodiversity/habitat loss - destruction & disturbance of ecosystems). Disturbance of ecosystems may happen by carbon seeps from reservoirs or pipelines. Their detection can also be done with EO data.,NONE828,TA13-4,Monitor land,Services that monitor land cover all services/applications that are focused on monitoring - assessing - managing - planning and improving land areas - its ecosystems (land - soil and inland water monitoring/quality/availability & usage assessments) and evolution of the land surface (use - cover - seasonal and annual changes and monitors variables) even if it involves human intervention (environmental challenges - impact evaluation or suitability analysis).\rMonitoring is possible by deriving information from variables measured by EO in different domains - like vegetation - energy - water - and cryosphere. For vegetation - those variables are for example land cover - NDVI - burnt area - or surface soil moisture. In the energy domain - land surface temperature and surface albedo are known variables - for water it is water surface temperature or water quality. Finally - for the cryosphere lake ice and snow cover extent - and snow water equivalent are variables that are used for land monitoring services.,NONE829,TA13-5-1,Monitor urban areas,The full range of EO satellite sensors are capable of monitoring particular aspects of urban areas. The most relevant include  SAR satellites such as TerraSAR-X that distinguish between urban fabric and other land cover. Further - optical satellites in the resolution range HR and VHR are used to map imperviousness and soil sealing. Beyond such land cover classifications with low granularity - HR and VHR data are used for producing detailed land use and land cover classifications that distinguish different settlement densities or - in combination with additional data - different land use such as transport - residential etc. as defined in Classification schemes specialized on urban areas. Airborne laser scanning (and stereographic analysis) maps building and vegetation heights. InSAR methods allow to measure land subsidence that is highly relevant e.g. in coastal cities close to or below the sea surface elevation. Night-time optical data maps lights. Thermal sensors allow mapping the heat that is radiated from cities.  Typical applications include monitoring urban growth/sprawl - transport networks - urban heat islands - and generating city maps and 3D city models for urban planning that are relevant to users in smart cities and in local/regional planning.,NONE830,TA13-5-2,Monitor infrastructure,EO is capable of monitoring infrastrcture in general - i.e. buildings (and their construction) and transport networks (roads - rails). Additionally - infrastructure for renewable energy harvesting (solar and wind farms - hydroelectric powerplants) and identification of suitable sites (through mapping solar radiation - wind roses - speed and direction - hydrological network mapping). A basis is land surface mapping for deriving digital elevation models (DEMs) that is required for modelling renewable energy potential and for spatial planning and landscape visibility analysis (visual impact assessments for planned infrastructure). Further - EO is capable of assessing damage from industrial accidents. A wide range of EO technologies is used here - infrastrcture can be directly detected and mapped with optical and SAR sensors - where the resolution depends on the targeted assets. DEMs can be generated from SAR and stereographic optical data. Wind energy related parameters can be derived from satellites focused on atmosphere and weather monitoring. Further - there are various GI methods in use - too (in particular focused on spatial planning and impact assessment).,NONE831,TA13-5,Monitor the built environment,Monitoring the built environment provides information about urban structures - transport networks and particular infrastructure - e.g. dedicated to energy provision. It covers all urban and infrastructure related service/applications on site development information - planning support or suitability analysis.  As well - it includes pressure and threats analysis on the urban areas.,NONE832,TA13-6-1,Monitor the marine ecosystem,Oceanic waters cover approximately 70% of the Earth´s surface and play a key role in regulating Earth temperature and climate - support important marine ecosystems and provide food and transport. Ocean waters occupy large areas and involve highly dynamic processes with different temporal and spatial scales. In-situ measurements taken by ships and buoys can provide accurate information but only at specific locations - being limited to understand large-scale processes. To characterise the heterogeneity and dynamics of ocean waters - it would be required to perform exhaustive field campaigns with associated high costs and infrastructure challenges. EO is an efficient tool to monitor ocean waters and to complement ocean in-situ monitoring programmes as it can provide cost-effective information over vast areas at continuous temporal and spatial scales. \rSince the first EO satellite specifically designed to study the oceans (SeaSat) has been launch in the 1970s - many sensors and platforms have been developed. This variety of sensors have provided measurements of a broad range of ocean physical and biological variables to the present day. For example - satellite observations in the visible and near-infrared bands have provided information about ocean colour that can be used to estimate chlorophyll-a concentration for monitoring water quality - productivity and algal blooms. Thermal infrared (TIR) sensors have provided data of Sea Surface Temperature (SST) that is of importance for the study of currents and ocean warming. Microwave radiometers have registered sea surface salinity (SSS) - critical to determine the global water balance - understanding ocean currents and estimating evaporation rates. EO can also provide information about physical ocean features such as surface elevation and ocean currents - sea surface winds - ocean waves - vessels and pollutants such as oil spills. \rThe versatility of EO data have been proved in a broad range of applications - including the monitoring of water quality - climate change effects - hurricane tracking and prediction - monitor maritime traffic and pollution - harmful algal blooms and fisheries management. In recent years - the Copernicus programme has launched a series of satellite missions for water and land monitoring that guarantee the provision of long-term observations giving continuity to previous satellite missions. Within the Copernicus programme - especially the Sentinel-3 mission will have relevance for ocean observations. Currently - two satellites Sentinel-3A and Sentinel-3B - launched respectively in 2016 and 2018 - are providing near-real-time data on the state of the ocean surface - including sea surface temperature - marine ecosystems - water quality and pollution monitoring. New hyperspectral missions such as the Plankton - Aerosol - Cloud - ocean Ecosystem (PACE) developed by NASA - are currently under development. In the near future - they will complement the existing satellite missions and will register data in a high number of spectral bands. This information will be essential in diverse applications such as aquatic ecology and biochemistry. Ocean EO is still an evolving field that will need skilled professionals that exploit the data from the new and upcoming missions for the advancement of ocean knowledge and monitoring.,NONE833,TA13-6-2,Monitor coastal areas,In coastal areas - EO is capable to monitor water depth and shallow water bathymetry (charting) - coastal ecosystem parameters about water temperature - water transparency - oxygen - phytoplankton abundance - bathing water indicators - detection harmful algal blooms - sediment (qualitative - quantitative) - turbidity (quality - quantitative) - visibility - chlorophyll-a concentration - suspended sediment may be indicative of estuarine processes - re-suspension or pollution. Further - this includes coastline monitoring with a focus on shoreline and its change as well as coastal land cover (and terrain) and its change. A widse set of EO sensors and technologies is used to monitor coastal areas. Optical satellite imagery is analyzed to detect and map suspended sediment concentrations. Etc.,NONE834,TA13-6-3,Monitor weather impact on ocean surface,EO is capable to monitor weather impact on ocean surface and metocean features as a basis for forecasting furture ocean conditions. This includes ocean surface topography - ocean dynamics and circulation like tides and ocean current movements and drift - ocean winds - wave and climate conditions at ocean locations (meteocean). Further - this covers the mapping of extreme waves like tsunamis and the monitoring of hurricanes and typhoons. Involved EO technologies are for example satellite altimetry that maps ocean surface with 2 cm to 3 cm accuracy - mathematical forecast models. Repeated altimetry measurements allow mapping speed and direction of ocean's currents and tides. Available EO-based RADAR systems monitor wave height and direction - wind speed and sea-surface elevation. Near-realtime processing and delivery workflows enable the use of these parameters in weather forecasting - navigation and offshore installations protection.,NONE835,TA13-6-4,Monitor fisheries,To support an ecosystem-based approach for fisheries management - EO images with global and daily systematic coverage with high-resolution images can help in identifying potential fishing zones and to assess fish stocks. They help assessing and understanding changing abundancy and spatial distribution of exploited fish stocks. Therefore - they analyse various key environmental parameters that can be detected with satellite remote sensing. This includes sea surface temperatures (SSTs) - sea surface height anomalies - and sea surface colour revealing the abundance of chlorophyll a. This relates to phytoplacton production that is directly related to total fish landings. Additionally - EO can detect harmful algal bloom. A further threat to sustainable fish stocks management are illegal fishing. Where localization of licensed fishing vessels and fleet management services are supported by EO to avoid overexplotation and enable recovery of fish stocks. EO complements identification - detection and tracking of vessels with SAR and optical remote sensing.,REMOTE SENSING836,TA13-6-5,Detect and monitor ships,For shipping - navigation - and monitoring sea-traffic and pollution - remote sensing and satellite technologies allow detecting vessels in the wider ocean. EO can detect the vessels themselves - their wake trailing behind them - sandbanks and reefs that pose a threat for safe navigation. Additionally - EO can detect pollution from the ships - e.g. when illegal waste disposal happens. Ship detection and classification is possible with the use of optical and synthetic aperture radar (SAR) imagery. The methods complement each other.,REMOTE SENSING837,TA13-6-6,Monitor sea-ice and icebergs,Information on sea ice and icebergs is important for managing operation of ships or offshore platforms in hazardous sea ice conditions. EO technologies give the possibility to study sea ice and measure its thickness - spatial distribution - motion and ridges (as well as ice berg positions). Satellite imagery provides wide area - synoptic pictures of the ice conditions. Since the scale of ice fields is quite large - mainly moderate resolutions have to be accepted - down to around 10m in scale - while ensuring comprehensive coverage. Multispectral imagery can provide more information on ice-type but in the main - SAR imagery is used due to its all-weather and day/night capability. The data collected can be more accurate than in-situ measurements due to a higher and faster coverage of a whole area. Subsequent modelling that incorporates ocean weather (wind - waves - ocean current) provides expected drifting paths. Constant monitoring is most important to identify the risk and opportunities - for instance for ship routing - and safety of oil rigs.,NONE838,TA13-6,Monitor marine,Monitoring marine inlucdes monitoring of marine safety (e.g. marine operations - oil spill combat - ship routing - defence - search & rescue - ...) - marine resources (e.g. fish stock management - ...) - marine and coastal environment (e.g. water quality - pollution - coastal activities - ...) - and climate and seasonal forecasting (e.g. ice survey - seasonal forecasting - ...).,NONE839,TA13,EO services and applications,EO services and applications are organized according to thematic areas. EO is used for a wide set of services. There are many applications of EO that show how a service produces information for a particular client. EO service and applications are best described by the purpose they serve or by the need of the user. The main user needs to EO are to monitor - to map - to forecast - to assess - to detect - and to analyse. \rTo monitor means to watch and check a situation carefully for a period of time in order to discover something about it - i.e. keeping track of how the natural and manmade environment change (their status) over time. Typical alternative verbs are track - observe - record - follow - understand - or surveil. \rTo map means to represent an area of land in the form of a map - i.e. to feature and locate the way it is arranged or organized. Synonymous verbs are locate - identify - classify - trace - or record.\rTo forecast means to provide statements covering a range of different outcomes - to say what you expect to happen in the future; i.e. to predict future events based on specified assumptions (about information extracted from EO change and time series data) - where different sets of assumptions describe scenarios. Equivalent terms are predict - plan - model - estimate - or project.\rTo assess means to judge or decide the amount - value - quality or importance of something - i.e. to evaluate and measure the status of and changes in natural and manmade built environments. Alternative verbs are evaluate - measure - understand - review - or quantify.\rTo detect allows to notice something that is partly hidden or not clear - or to discover something - especially using a special method - i.e. to identify and locate the changes in the Earth’s environment. Similar terms are locate - warn - identify - highlight - or spot.\rTo analyse means to study or examine something in detail - in order to discover more about it - i.e. to detail the elements of a whole and critically examine and relate these component parts separately and/or in relation to the whole. Sometimes - the terms to process - to parse - or to detail are used in exchange for to analyse.,NONE840,TA14-1-1-1,Ocean colour,Ocean colour can be made visible in atmospherically corrected EO data. Specific spectral bands are necessary to derive physical and biologic parameters of the water from the EO data.,NONE841,TA14-1-1,Band combinations,Band combinations are pre-defined for (visually) analysing images for a dedicated purpose. Examples are dedicated band combinations for land us land cover classification - ocean colour - etc.,NONE842,TA14-1-2,EO parameters,The spectral and refractive information from optical and SAR data enables direct and indirect derivation of biophysical and geophysical EO parameters that are properties of the sensed land surface - ocean surface and atmosphere volume.,NONE843,TA14-1,Processing-related and preparatory products,Processing products are image products from raw data to all different processing stages. The transformation processes between the stages include operations such as atmospheric correction - cloud detection and radiometric calibration to provide data in a form suitable for subsequent analysis. Processing products consider a product as being an output of a process.They appear as 'intermediate products' along all steps of the processing chain.,NONE844,TA14-2-1-1,Point clouds,Point clouds represent a set of points with X - Y - Z coordinates and associated attributes. A source of acquisition is Light Detection and Ranging (LIDAR) - an airborne surveying technique that uses laser light to measure the distance to an object on the ground.,NONE845,TA14-2-1-2,Digital elevation models,Elevation data in the form of a digital elevation model (DEM) is an essential component of many analyses derived from EO. DEMs are used to represent every kind of surface - including terrain surface - vegetation canopy surface - sea surface - sea-ice surface - glacier surface etc. This description focuses on DEMs for representing terrain. A digital terrain model (DTM) describes the bare ground of the terrain - a digital surface models (DSM) described heights of vegetation (e.g. trees) and of man-made structures (e.g. buildings) reaching above the terrain. DEM is often used as an umbrella term for DTM and DSM. EO-derived DEMs are usually DSMs and require removal of vegetation and buildings in order to represent the terrain (DTM). DEMs are multi-purpose products used in various applications. They are available for global scale (SRTM - WorldDEMTM) - regional scale (ArcticDEM - Copernicus EU-DEM v1.1) or for national levels and local regions. Various techniques exist to generate DEMs from SAR data - stereographic optical EO (as well as airborne and drone) data and from airborne laser scanning.,NONE846,TA14-2-1-3,Elevation change maps,By comparing elevation models of different dates - the change in elevation and volume can be identified. Thereby - they measure surface deformation - land subsidence - ice shield loss due to melting - etc.,NONE847,TA14-2-1-4,Vector fields,Vector fields capture the movement directions of locations on a continuous surface - e.g. of the ocean - or in a 3D grid of locations - e.g. of the atmosphere. The atmosphere and the ocean are highly dynamic features. Vector fields are used to represent wind directions and current movement directions. Further vector fields derived from EO data include geoid undulation / gravity maps.,NONE848,TA14-2-1-5,Feature trajectories,When a moving feature (i.e. object) is detected in subsequent images - its trajectory of movement can be mapped. Such products map ship movements - sea ice movements - etc.,NONE849,TA14-2-1,Geometrically measured EO products,Geometrically measured EO products origin from EO-derived distance measurements - measurements of direction - tracking of moving objects - and changes of distance measurements. The used EO methods include for example SAR interferometry and stereographic analysis of optical data.,NONE850,TA14-2-2-1-1,Land cover maps,Land cover maps represent spatial information on different types (classes) of physical coverage of the Earth's surface - e.g. forests - grasslands - croplands - lakes - wetlands. An example is the European Copernicus product CORINE land cover (CLC) with 44 classes. Initiated in 1985 (reference year 1990) - updates followed in 2000 and every 6 years afterwards. Apart from CLC - the European Copernicus Land products also include the High Resolution Layers. They includes for example the imperviousness product that captures the percentage of soil sealing. Land cover classification products are multi-purpose products that are relevant for various applications. They are available on national levels - regional levels and global levels. They have different scales and granularity of their associated classification scheme. The products are updated on a regular basis. Update cycles can vary depending on the resolution (i.e. likelihood for observable change of the land surface) and the capability of production processes. An additional example on a global scale is the Global Urban Footprint. The products are provided by public organisations and private EO companies and based on various EO sensors.,NONE851,TA14-2-2-1-2,Land use maps,Land use documents how people are using the land. Getting from physical land type (land cover) to land use requires skill in interpretation and involves integration and consultation of ancillary data. Land use maps are multi-purpose products that are relevant for many applications. The products are updated on a regular basis (e.g. 6 years for Urban Atlas).,NONE852,TA14-2-2-1-3,Cloud mask,Cloud masks for optical EO data distingush cloudy pixels from cloud-free pixels. They may differentiate between serveral cloud types - i.e. opaque clouds and Cirrus clouds (that are transparent). Most land monitoring applications based on optical data require cloud-free images. Therefore - cloud masks are a product that is used early on in image processing for selecting suitable imagery for analysis (e.g. by screening images of an archive by the derived cloud cover percentage of the image). Therefore - cloud masks are made available as metadata by the EO data provider. Clouds are identified with threshoulding of reflectance values of the blue band and - to adapt for cloud/snow confusion - specific short-wave infrared (SWIR) bands.,NONE853,TA14-2-2-1-4,Detected features,Detected features are objects from one or more classes and are the result of a comprehensive (and mostly automatic or semi-automated) search of all locations in an image that decides whether such features are present and where they are located. Examples inculde man-made objects (e.g. vehicles - ships - buildings - etc.) with sharp boundaries and are independent from the background -  and landscape objects - such as land-use/land-cover (LULC) parcels that have vague boundaries and are part of the background environment. Only the latter type would locate features for all locations of an image.,NONE854,TA14-2-2-1,Thematic classifications and feature detection,Static EO derived thematic classification products and masks (e.g. land use land cover classifications). Additionally - static EO detected features (planes on apron of airports - dwellings) that consist of a set of point locations (or polygons) and do not end up in a comprehensive classification of all pixels of an image. Static EO derived thematic classification products and masks (e.g. land use land cover classifications). Additionally - static EO detected features (planes on apron of airports - dwellings) that consist of a set of point locations (or polygons) and do not end up in a comprehensive classification of all pixels of an image. Thematic classifications and feature detection identify a surface by a class label that represents a more or less persistent state. A good example product is the Copernicus Urban Atlas. The most recent available version is assumed to represent the 'current' state (Certainly - an update cycle is necessary for providing a product that remains up-to-date).,NONE855,TA14-2-2-2,Event maps and thematic change (evolution) maps,Event maps and thematic change (evolution) maps indicate that some process happened that changed the area at a location from one class to the other. For example - a burnt area map indicates locations where vegetation has been burnt by a fire and changed to bare ground. A typical mapping method is the use of pre- and post-event satellite images for detection of the areas affected by the process. Eventually burnt areas contain identifiable burn marks that allow direct identification in one single post-event satellite image. Nevertheless - it is the process that is central to the analysis. Similarly - the concepts aforestation and deforestation would fall under the heading 'Event maps.' They may come from a comparison of two status maps of different dates. Some processes benefit from analysis of more than two states. Such change evolution maps can be produced with time-series analysis. On land - more examples include landslide maps - flooded area maps and other land surface dynamics (e.g. aforestation and deforestation). Further - change detection maps are available for other domains (atmosphere - marine - land - climate - etc.),NONE856,TA14-2-2,Semantic labelling products,The semantic labelling products result from methods that assign labels to objects or locations in a field. The labels correspond to the categories of a classification or - in case of masks and detected features - to a single target class. Such labels may also identify classes of change or change evolution.,NONE857,TA14-2-3,EO-derived attribute products,EO-derived attribute products describe the state and evolution of specific attributes of a feature or at a field location. They describe for example air quality - soil moisture or water quality & quantity.,NONE858,TA14-2,Descriptive analytics products,Descriptive analytics products provide analytical results which describe the present (and past) situation as it is recorded in EO images. Therefore - it contains information that can directly be extracted from EO images or EO image time series. These products are diverse in various aspects: they capture static and dynamic information; they concern information about objects or fields; and they have qualitative (nominal scale) or quantitative (ordinal - interval - ratio scale) levels of measurement.,NONE859,TA14-3,Predictive modelling products,Providing analytical (modelling) results which predict the future situation (e.g. air pollution forecasts). [interpolation in space - i.e. not only prediction into the future - filling gaps in time series...]\rInformation that can be modelled based on descriptive analytics products. by extrapolating time series (forecasting/predicting) - by modelling of processes (e.g. flood risk maps - landslide susceptibility),NONE860,TA14-4,Prescriptive modelling products and services,Prescriptive modelling products and services focus on providing analytical results that are a guide to action. The often result from an impact assessment. One example is the identification of construction sites leading to sales opportunities.,NONE861,TA14-5-1,Textured 3D models,A textured 3D model uses a 3D model derived from elevation data. Additionally - each separate surface of the 3D model receives its own texture derived from optical image data. Typically used for visualisation purposes.,NONE862,TA14-5-2,Semantic 3D models,A semantic 3D model consists of a 3D model derived from elevation data with an integrated image classification. A classified object thereby consists of a 3D surface or a grouped set of 3D surfaces. A typical example is a 3D city model in the CityGML format.,NONE863,TA14-5,Aggregation and integration products,Combining the satellite data with other information sources. Resulting in an integration of several descriptive analytics products and processing products - e.g. a textured 3D model or a semantic 3D model.,NONE864,TA14-6-1,Satellite maps,Sentinel-2 cloud-free mosaics for display - satellite maps in books etc.,NONE865,TA14-6-2,Layouted digital maps,Layouted maps in a file (PDF - SVG - etc.) for printing or visualisation on screen - embedding in reports or as static displays on websites etc.,NONE866,TA14-6-3,Web visualisations in 2D and 3D,Digital layouted maps in an online map viewer; 3D visualisations on the screen / 3D screen and online map viewers with 3D capabilities etc.,NONE867,TA14-6-4,Analogue visualisation products,Printed maps - 3D plots of 3D models - hologram 3D maps etc.,NONE868,TA14-6-5,Time series map videos,A video is a structured file of 2D grids link by the time - is a regular file of values which has been processed to sensor units (e.g. calibrated). The result can be a single date acquisition or a combination of dates. For each point - the value represents a parameter imaged by the sensor. Videos of EO data present for example time series of satellite maps and other EO products (e.g. Arctic sea ice evolution in a time-series map video over the past 30 years).,NONE869,TA14-6,EO visualisation products,Visualisation products are used for presentation of EO information to the user. The user's interaction with the visualisations is predominantly viewing and interpretation of the informational content and arriving at decisions in the context of the user'S objective with the EO information. In addition - users of visualisation are all involved actors during image processing. For example - an EO analyst may use visualisations of EO data and preliminary EO products for getting a better understanding of the contained information and adapt his processing workflow to arrive ad improved results. Typical visualisation products include satellite maps - layouted digital maps - web visualisations in 2D and 3D - and analogue visualisation products.,NONE870,TA14-7,Distribution services,Users need access to EO products if they shall be able to benefit from them. Additionally - providers of value added products act as users of EO products earlier in the information processing value chain. Concequently - various distribution services provide access from raw data to processed information and processing infrastructure. Provision of access to raw data or processed information happens via direct download (FTP) - via application programming interfaces (API) or web services (e.g. Hubs). Further - access to processing infractructure happens via web services.,NONE871,TA14,Standard EO products,Products in relation to EO appear along the entire image processing value chain as inputs and outputs of processing steps. Ultimately - at the end of that chain - the output EO products represent information that supports actions. The standard EO products are categorized by the type of problems they help to solve or the type of question they help answering.,NONE872,WB,Web-based GI,This knowledge area is about Web Based Geographic Information management aspects and therefore it was given the name 'Web Based GI' or 'WBG' in short. It is implied by this name that the differentiating factor for this KA is the 'Web'. One must then be able to answer the questions like 'What functions do we delegate to the Web?' or 'how WBGI is different from the traditional GI?' Sticking to the functions of a GIS - which are inserting (adding) - storing - manipulating - analysing and presenting the data - there is not a single system for effecting all these tasks anymore but the Web itself. For instance - there is no single database and its known-to-its users-definition - anymore but many different stores and many different definitions. Similarly - many different manipulation - analysis and presentation options compared with the options offered by a single or limited number of systems of traditional GI. In general - Web provides the means of leveraging distributed 'resources' like data - information - or software. It is a 'collaboration medium'. A collaboration that enables rapid production or decision making. A collaboration that certainly introduces new dimensions to traditional GI handling. This is the justification of proposing this KA in addition to the KAs of the original BoK. For the mentioned collaboration to happen - data or any other type of a resource have to accessible on the Web. This means that it should have a Web 'address' and a 'definition' that is understandable either by 'human' or 'machine'. 'Machine understandable definitions' refers to the dimension of 'semantics' and 'ontologies' which are also included under this KA. When one talks about publishing resources then 'catalogue services' and more importantly 'discovery' dimension comes into the scene. On the other hand - 'Linked Data (LOD)' and 'Open Data' - highly popular recent trends and two of the above mentioned dimensions of Web GI have also been covered under this KA. Like the other dimensions of Web GI - both LD and OD aspects must be known to GI communities with differing degrees of expertise. The concepts of 'interoperability' and 'Spatial Data Infrastructure (SDI)' - hot topics of GI communities for many years - have been thought to be dealt with under this KA as well with the justification that 'Web GI' is a much broader concept than SDI - This is by the fact that SDI refers to a much narrower content and context of 'collaboration' then Web GI. Therefore - Geospatial data interoperability and some of the related concepts which were classified under KA - 'Geospatial data in the original BoK were moved under KA11 with the updated context. Another issue is the coverage of Spatial Analysis (SA) - data manipulation aspects of GI by KA11. The SA aspects are covered by other KAs like 'Geocomputation' and 'Analytical methods'. If the analysis operations - in an undertaking - would be handled by web services this is already covered by 'data processing' web services - application development unit and Web services composition under that unit. The important thing is to have the knowledge about a specific analysis operation; Employing it as a web service would require no more knowledge than using any other web service. SA is covered by KA11 in as much as it should have been.,NONE873,WB1-1,Fundamentals of web services,The basic principles on which web services build. The concept of Service Oriented Architecture and the importance of APIs,NONE874,WB1-2,SOAP web services,This concept will cover web services based on the Simple Object Access Protocol (SOAP),NONE875,WB1-3,REST web services,This concept will cover web services based on the representational state transfer (REST) protocol,NONE876,WB1-4,OGC web services,The Open Geospatial Consortium (OGC) defines standards and best practices for web services in the geospatial domain. OGC standards are developed using a consensus model allowing all stakeholder to participate in the process. As a result the OGC web services are widely implemented.,NONE877,WB1,Web services,In the most simplistic way a Web service may be defined as 'a Web accesable program code which performs a task of either processing or serving some data. Although there are many other definitions in the related literature - the one in W3C (2004) seems to be quite complete and refering to also lately popular REST style Web services. It states that ' We can identify two major classes of Web services: REST-compliant Web services - in which the primary purpose of the service is to manipulate XML representations of Web resources using a uniform set of 'stateless' operations; and arbitrary Web services - in which the service may expose an arbitrary set of operations.,NONE878,WB2-1,Languages for the definition of non-spatial data and services,To be able to discover and assess available data or services - these resources have to be documented. This concept describes the standardized languages used for these descriptions,NONE879,WB2-2,Definition of geospatial data,Different standardized ways to define geospatial data exist.  GML - GeoJSON - WKT and GeoSPARQL are examples. What are common points and differences,NONE880,WB2-3,Ontologies development reuse and patterns,Defining a common language is a crucial step for sharing or combining data. Vocabularies - taxonomies - ontologies are are tools to reach this goal.,NONE881,WB2,Resource Definition,A 'resource' could be 'anything' including data and services - identifiable over the Web. A resource should be defined in a language to be discoverable on the Web. Over the years - two major bodies W3C for non-spatial and OGC concerning spatial data have developed many specifications for defining data and services. On the W3C side - Resource Description Framework (RDF) has gained a great momentum in recent years in relation to the recent popularity of Linked Data as well. In the OGC front - the acceptance of GML was a major step concerning the long time effort of geospatial communities for having a standard for the definition of both geospatial features and geometry.,NONE882,WB3-1,Metadata and standards,Metadata is information about the data to be published. It helps the user to discover the data - allows the user to evaluate the fitness for use and it explains how and under which conditions the data can be retrieved and used. Metadata are a core component of data infrastructures and as such - standardization is a requirement for the correct exchange and interpretation of the metadata.,NONE883,WB3-2,Manual and automated forms of publishing,A resource can be added manually to a catalogue service by creating or uploading its metadata - but metadata can also be added by automated crawling of other catalogues.,NONE884,WB3-3,Catalogue services,Catalogue services allow to publish and search resources through their metadata,NONE885,WB3-4,Publishing open data,Open data is data that is free to use - re-use and share without limitations on who uses it or for what purpose. Publishing open data is making the data discoverable and accessible in a convenient way (technical openness).,NONE886,WB3-5,Publishing via a semantic definition of data,Adding semantic information to the data allows computers to understand the structure and meaning of data. This allows automatic searching - processing and integrating data with other semantic sources.,NONE887,WB3-6,Publishing linked open data,Linked (open) data provides structured data which is interlinked in a machine readable way. This allows to discover - access and combine data in an automatic way. This concept discusses the steps needed to make existing data available in a linked open way.,NONE888,WB3,Resource Publishing,'Publishing' means making a resource available for the use of others. A 'resource' could be 'anything' including data and services - identifiable over the Web. Publishing may be done on the basis of either the 'characteristics' of the data or the data itself. When only some 'characteristics' of a resource is published then some of the contents would naturally be left out. The 'characteristics' include metadata and some keywords. This kind of publishing may be named as 'limited contents' publishing or 'publishing by metadata'. One of the issues become then what characteristics to use to define the data. Or what what metadata definition to use. Another aspect of publish is 'manual entry' and 'automated collection'. In the former publisher enters metadata while in the latter some harvesting mechanism collects metadata in an automated fashion. On the contrary - there is 'unlimited contents publishing' where there is no limitation on the published contents. Open data publishing is in this class. In additon - some 'additional semantics' may be subject of this type publishing through new relationships in the ontologies of publishing - which have not been explicit in the exisiting data model but are inherent in the data. And this last type is covered under the topic - 'Publishing via a semantic definition of data.',NONE889,WB4-1,Syntactic discovery,Syntactic discovery is the discovery of resources based on the structure of the resources,NONE890,WB4-2,Semantic discovery,Semantic discovery is the discovery of resources based on the meaning of the data.,NONE891,WB4-3,Discovery over linked open data,Linked (open) data provides structured data which is interlinked in a machine readable way. This allows to discover - access and combine data in an automatic way.,NONE892,WB4,Resource Discovery,Resource discovery means the discovery of resources including data and services needed for an application. Syntactic discovery refers to the discovery on the basis of syntactic comparison operations. It is classified as 'keyword-based' and 'full-text-based' discovery. Semantic discovery on the other hand - refers to the discovery of resources on he basis of some semantic definition. Therefore - semantic discovery requires that a resource be published by a semantic definition as defined in the topic WB3-5.,NONE893,WB5-1,Integrating data from OGC web services,The workflow to integrate geospatial data in an application often relies on a combination of different OGC web services.  Searching and finding the data and the corresponding services - binding to these services to view - filtering and or downloading the data are different steps in this process,NONE894,WB5-2,Schema matching and ontology alignment,The alignment of data structures and vocabularies/ontologies used are important steps towards the data harmonisation needed for a combined use of datasets,NONE895,WB5-3,Data mash ups,A data mashup is a combination of data from different sources to produce new applications of new datasets,NONE896,WB5,Application development via Data Integration,The term 'application development' refers to the collection of activities or the 'workflow' through which the user reaches her final goal. Being one of these activities - 'data integration' means the transformation of data from one representation to another which might be of either the client`s one or some other representation. An example for data integration might be the case where the data is transfered from an OGC WFS and integrated into a client GIS.,NONE897,WB6-1,Manual Web Services Composition,Manual Web Service Composition is manually (by human) combining  the activities of discovery - composition and invocation to fulfil a certain task.,NONE898,WB6-2,Semi automated and Full-automated WSC,Providing standardized descriptions of the specifics of available webservices creates an environment where the composition of services to create a web application can be automated.,NONE899,WB6,Application development via Web services composition,Web Services Composition can be defined as bringing together a number of web services in a certain workflow to achieve a certain task that cannot be achieved by any of the composed services alone. In general - it involves first the discovery of the suitable services over the Web - and compose them in a certain workflow order and finally run the composed service which is the invocation stage. WSC has been a highly active research topic since the emergence of Web services in 2000s. 'Manual' WSC is the form that the activities of discovery - composition and invocation are all done manually (by human). In the 'Semi-automated' way - the discovery is done by the machine. In the 'full-automated' approach all the above activities are done by the machine. There are no tools at the moment that achieve full automated composition. Web API composition is like WSC - the only difference is the fact that instead of web services there are Web APIs in WAPIC. There is no doubt that One would run into the very same problems of WSC concerning full automated composition. In other words - WAPIC would in no way be easier than WSC. Nevertheless - as far as semi automated form can be achived - WAPIC is valuable because the number of Web APIs increase drastically from day to day. The site 'programmableWeb' lists 14 957 APIs at the moment. It is not easy to search for all those APIs manually for the discovery of suitable APIs for a given task.,NONE900,WB7-1,Hypertext markup scripting and styling,Hypertext markup scripting and styling are the base for each web page or application. Styling defines the look and feel while scripting is used to implement the behavior of the web application,NONE901,WB7-2,Web Map APIs and Libraries,Web map APIs allow developers to integrate resources made available by web services in their application or web sites.,NONE902,WB7-3,Web application Frameworks and Geoportal frameworks,A web application framework provides the generic and reusable building blocks needed to create web applications. Geoportal frameworks provide the functionality to build geospatial portals.,NONE903,WB7,Web Application development elements,Characteristic examples are included under this topic. The APIs - for instance other than the ones included under this unit - and libraries could have been included as well. However - since the important thing is to highlight the functionality then there is no need to include them all. By the inclusion of topic 'WB7-3'under this unit - the aim was to cover one of the very 'hot' topics of Web2.0 for both the main concepts about Web application frameworks and also how they are related to portal frameworks and geoportals. By the topic 'WB7-1 Building blocks' the core components of Web application development are covered. On top of this core - there comes a great variety of 'Web application frameworks for both enabling rapid web application development and ensuring scalable - high-performance applications. Finally - there are 'Web APIs and Libraries' certainly deserving being a separate topic for their current popularity. They also mean rapid application development for developers by code reuse and versatility for 'end users' in creating their 'end products'.,NONE